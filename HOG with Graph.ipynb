{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa3d6dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import optimizers\n",
    "import pywt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5742aca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "totalaccuracy = []\n",
    "totalprecision = []\n",
    "totalrecall = []\n",
    "totalf1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f1c6bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNNbuild(height, width, classes, channels):\n",
    "    model = Sequential()\n",
    "    \n",
    "    inputShape = (height, width, channels,)\n",
    "    chanDim = -1\n",
    "    \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        inputShape = (channels, height, width)\n",
    "    model.add(Conv2D(32, (3,3), activation = 'relu', input_shape = inputShape))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(512, activation = 'relu'))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(classes, activation = 'softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90a6bf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "penghuni = os.listdir(\"C:\\\\Users\\\\muham\\\\OneDrive\\\\Documents\\\\TA\\\\images\\\\train\\\\Penghuni\")\n",
    "bkn_penghuni = os.listdir(\"C:\\\\Users\\\\muham\\\\OneDrive\\\\Documents\\\\TA\\\\images\\\\train\\\\BukanPenghuni\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08d3ef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in penghuni:\n",
    "\n",
    "    image = cv2.imread(\"C:\\\\Users\\\\muham\\\\OneDrive\\\\Documents\\\\TA\\\\images\\\\train\\\\penghuni\\\\\"+i)\n",
    "    \n",
    "    image_array = Image.fromarray(image , 'RGB')\n",
    "    resize_img = image_array.resize((50 , 50))\n",
    "    \n",
    "    resize_img = np.float32(resize_img) / 255.0\n",
    "    \n",
    "    # Calculate gradient \n",
    "    gx = cv2.Sobel(resize_img, cv2.CV_32F, 1, 0, ksize=1)\n",
    "    gy = cv2.Sobel(resize_img, cv2.CV_32F, 0, 1, ksize=1)\n",
    "    mag, angle = cv2.cartToPolar(gx, gy, angleInDegrees=True)\n",
    "    \n",
    "    # image_array = Image.fromarray(image , 'RGB')\n",
    "    # resize_img = image_array.resize((50 , 50))\n",
    "    # coeffs1 = pywt.dwt2(resize_img, 'bior1.3')\n",
    "    # LL, (LH, HL, HH) = coeffs1\n",
    "    data.append(np.array(mag))\n",
    "    data.append(np.array(angle))\n",
    "    data.append(np.array(gx))\n",
    "    data.append(np.array(gy))\n",
    "    labels.append(0)\n",
    "    labels.append(0)\n",
    "    labels.append(0)\n",
    "    labels.append(0)\n",
    "\n",
    "for u in bkn_penghuni:\n",
    "    \n",
    "    image = cv2.imread(\"C:\\\\Users\\\\muham\\\\OneDrive\\\\Documents\\\\TA\\\\images\\\\train\\\\BukanPenghuni\\\\\"+u)\n",
    "    \n",
    "    # image = np.float32(image) / 255.0\n",
    "    Image_array = Image.fromarray(image , 'RGB')\n",
    "    resize_img = image_array.resize((50 , 50))\n",
    "    resize_img = np.float32(resize_img) / 255.0\n",
    "    # Calculate gradient \n",
    "    gx = cv2.Sobel(resize_img, cv2.CV_32F, 1, 0, ksize=1)\n",
    "    gy = cv2.Sobel(resize_img, cv2.CV_32F, 0, 1, ksize=1)\n",
    "    mag, angle = cv2.cartToPolar(gx, gy, angleInDegrees=True)\n",
    "    \n",
    "    # image_array = Image.fromarray(image , 'RGB')\n",
    "    # resize_img = image_array.resize((50 , 50))\n",
    "    # coeffs2 = pywt.dwt2(resize_img, 'bior1.3')\n",
    "    # LL, (LH, HL, HH) = coeffs2\n",
    "    data.append(np.array(mag))\n",
    "    data.append(np.array(angle))\n",
    "    data.append(np.array(gx))\n",
    "    data.append(np.array(gy))\n",
    "    labels.append(1)\n",
    "    labels.append(1)\n",
    "    labels.append(1)\n",
    "    labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f980c33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = np.array(data, dtype=object)\n",
    "labels = np.array(labels)\n",
    "\n",
    "np.save('Cells' , cells)\n",
    "np.save('Labels' , labels)\n",
    "\n",
    "n = np.arange(cells.shape[0])\n",
    "np.random.shuffle(n)\n",
    "cells = cells[n]\n",
    "labels = labels[n]\n",
    "\n",
    "cells = cells.astype(np.float32)\n",
    "labels = labels.astype(np.int32)\n",
    "cells = cells/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45f7912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:1, Train set: 1302, Test set:326\n",
      "====================\n",
      "Fold:  1\n",
      "====================\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 24, 24, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 24, 24, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 22, 22, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 11, 11, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 11, 11, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 11, 11, 32)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 9, 9, 32)          9248      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 4, 4, 32)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 4, 4, 32)          128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 4, 4, 32)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 286019 (1.09 MB)\n",
      "Trainable params: 284803 (1.09 MB)\n",
      "Non-trainable params: 1216 (4.75 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/75\n",
      "33/33 [==============================] - 6s 106ms/step - loss: 1.2722 - accuracy: 0.4928 - val_loss: 0.8391 - val_accuracy: 0.6308\n",
      "Epoch 2/75\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.8691 - accuracy: 0.6052 - val_loss: 0.7774 - val_accuracy: 0.6308\n",
      "Epoch 3/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.7792 - accuracy: 0.6129 - val_loss: 0.7539 - val_accuracy: 0.5538\n",
      "Epoch 4/75\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.7334 - accuracy: 0.6023 - val_loss: 0.7887 - val_accuracy: 0.5538\n",
      "Epoch 5/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.7563 - accuracy: 0.6081 - val_loss: 0.7120 - val_accuracy: 0.6308\n",
      "Epoch 6/75\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.6835 - accuracy: 0.6350 - val_loss: 0.7403 - val_accuracy: 0.6308\n",
      "Epoch 7/75\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.6612 - accuracy: 0.6129 - val_loss: 0.7444 - val_accuracy: 0.5462\n",
      "Epoch 8/75\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.6283 - accuracy: 0.6378 - val_loss: 0.7974 - val_accuracy: 0.6231\n",
      "Epoch 9/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.6463 - accuracy: 0.6138 - val_loss: 0.7370 - val_accuracy: 0.5308\n",
      "Epoch 10/75\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.6499 - accuracy: 0.5927 - val_loss: 0.7390 - val_accuracy: 0.4846\n",
      "Epoch 11/75\n",
      "33/33 [==============================] - 3s 93ms/step - loss: 0.6408 - accuracy: 0.6321 - val_loss: 0.7342 - val_accuracy: 0.6154\n",
      "Epoch 12/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.6114 - accuracy: 0.6330 - val_loss: 0.6249 - val_accuracy: 0.6154\n",
      "Epoch 13/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.6072 - accuracy: 0.6311 - val_loss: 0.6806 - val_accuracy: 0.6077\n",
      "Epoch 14/75\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.5661 - accuracy: 0.6657 - val_loss: 0.5899 - val_accuracy: 0.6308\n",
      "Epoch 15/75\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.5713 - accuracy: 0.6455 - val_loss: 0.5803 - val_accuracy: 0.6308\n",
      "Epoch 16/75\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.6078 - accuracy: 0.5927 - val_loss: 0.5601 - val_accuracy: 0.6308\n",
      "Epoch 17/75\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.5960 - accuracy: 0.6369 - val_loss: 0.5539 - val_accuracy: 0.6308\n",
      "Epoch 18/75\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.5791 - accuracy: 0.6206 - val_loss: 0.5525 - val_accuracy: 0.6308\n",
      "Epoch 19/75\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.5924 - accuracy: 0.6244 - val_loss: 0.5324 - val_accuracy: 0.6308\n",
      "Epoch 20/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.5739 - accuracy: 0.6263 - val_loss: 0.5263 - val_accuracy: 0.6154\n",
      "Epoch 21/75\n",
      "33/33 [==============================] - 3s 94ms/step - loss: 0.5655 - accuracy: 0.6292 - val_loss: 0.5495 - val_accuracy: 0.6308\n",
      "Epoch 22/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.5621 - accuracy: 0.6484 - val_loss: 0.5543 - val_accuracy: 0.6308\n",
      "Epoch 23/75\n",
      "33/33 [==============================] - 3s 92ms/step - loss: 0.5595 - accuracy: 0.6436 - val_loss: 0.5717 - val_accuracy: 0.6308\n",
      "Epoch 24/75\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.5653 - accuracy: 0.6359 - val_loss: 0.5658 - val_accuracy: 0.6308\n",
      "Epoch 25/75\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.5681 - accuracy: 0.6158 - val_loss: 0.5259 - val_accuracy: 0.6308\n",
      "Epoch 26/75\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.5530 - accuracy: 0.6369 - val_loss: 0.5507 - val_accuracy: 0.6308\n",
      "Epoch 27/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.5453 - accuracy: 0.6417 - val_loss: 0.5251 - val_accuracy: 0.6308\n",
      "Epoch 28/75\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.5667 - accuracy: 0.6148 - val_loss: 0.5339 - val_accuracy: 0.6308\n",
      "Epoch 29/75\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.5470 - accuracy: 0.6234 - val_loss: 0.5754 - val_accuracy: 0.6308\n",
      "Epoch 30/75\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.5601 - accuracy: 0.6350 - val_loss: 0.5386 - val_accuracy: 0.6154\n",
      "Epoch 31/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.5489 - accuracy: 0.6350 - val_loss: 0.5291 - val_accuracy: 0.6308\n",
      "Epoch 32/75\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.5357 - accuracy: 0.6398 - val_loss: 0.5247 - val_accuracy: 0.6308\n",
      "Epoch 33/75\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.5567 - accuracy: 0.6350 - val_loss: 0.5304 - val_accuracy: 0.6308\n",
      "Epoch 34/75\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.5596 - accuracy: 0.6282 - val_loss: 0.5305 - val_accuracy: 0.6308\n",
      "Epoch 35/75\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.5427 - accuracy: 0.6388 - val_loss: 0.5500 - val_accuracy: 0.6154\n",
      "Epoch 36/75\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.5391 - accuracy: 0.6465 - val_loss: 0.5254 - val_accuracy: 0.6308\n",
      "Epoch 37/75\n",
      "33/33 [==============================] - 3s 104ms/step - loss: 0.5665 - accuracy: 0.6004 - val_loss: 0.5599 - val_accuracy: 0.6308\n",
      "Epoch 38/75\n",
      "33/33 [==============================] - 3s 97ms/step - loss: 0.5500 - accuracy: 0.6138 - val_loss: 0.5279 - val_accuracy: 0.6308\n",
      "Epoch 39/75\n",
      "33/33 [==============================] - 3s 93ms/step - loss: 0.5465 - accuracy: 0.6398 - val_loss: 0.5244 - val_accuracy: 0.6308\n",
      "Epoch 40/75\n",
      "33/33 [==============================] - 3s 90ms/step - loss: 0.5403 - accuracy: 0.6302 - val_loss: 0.5413 - val_accuracy: 0.6308\n",
      "Epoch 41/75\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.5505 - accuracy: 0.6417 - val_loss: 0.5446 - val_accuracy: 0.6308\n",
      "Epoch 42/75\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.5667 - accuracy: 0.6417 - val_loss: 0.5499 - val_accuracy: 0.6308\n",
      "Epoch 43/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.5762 - accuracy: 0.6273 - val_loss: 0.5268 - val_accuracy: 0.6308\n",
      "Epoch 44/75\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.5381 - accuracy: 0.6590 - val_loss: 0.5240 - val_accuracy: 0.6308\n",
      "Epoch 45/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.5530 - accuracy: 0.6359 - val_loss: 0.5330 - val_accuracy: 0.6308\n",
      "Epoch 46/75\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.5416 - accuracy: 0.6503 - val_loss: 0.5253 - val_accuracy: 0.6308\n",
      "Epoch 47/75\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.5338 - accuracy: 0.6571 - val_loss: 0.5266 - val_accuracy: 0.6308\n",
      "Epoch 48/75\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.5400 - accuracy: 0.6388 - val_loss: 0.5685 - val_accuracy: 0.6308\n",
      "Epoch 49/75\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.5430 - accuracy: 0.6494 - val_loss: 0.5831 - val_accuracy: 0.6308\n",
      "Epoch 50/75\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.5450 - accuracy: 0.6427 - val_loss: 0.5385 - val_accuracy: 0.6308\n",
      "Epoch 51/75\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.5438 - accuracy: 0.6695 - val_loss: 0.5358 - val_accuracy: 0.6308\n",
      "Epoch 52/75\n",
      "33/33 [==============================] - 3s 97ms/step - loss: 0.5375 - accuracy: 0.6475 - val_loss: 0.5234 - val_accuracy: 0.6308\n",
      "Epoch 53/75\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.5495 - accuracy: 0.6475 - val_loss: 0.5657 - val_accuracy: 0.6154\n",
      "Epoch 54/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.5601 - accuracy: 0.6234 - val_loss: 0.5249 - val_accuracy: 0.6308\n",
      "Epoch 55/75\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.5447 - accuracy: 0.6311 - val_loss: 0.5375 - val_accuracy: 0.6308\n",
      "Epoch 56/75\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.5420 - accuracy: 0.6234 - val_loss: 0.5291 - val_accuracy: 0.6154\n",
      "Epoch 57/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.5343 - accuracy: 0.6417 - val_loss: 0.5700 - val_accuracy: 0.6308\n",
      "Epoch 58/75\n",
      "33/33 [==============================] - 3s 96ms/step - loss: 0.5671 - accuracy: 0.6254 - val_loss: 0.5303 - val_accuracy: 0.6308\n",
      "Epoch 59/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.5492 - accuracy: 0.6513 - val_loss: 0.5325 - val_accuracy: 0.6154\n",
      "Epoch 60/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.5517 - accuracy: 0.6129 - val_loss: 0.5677 - val_accuracy: 0.6308\n",
      "Epoch 61/75\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.5434 - accuracy: 0.6446 - val_loss: 0.5335 - val_accuracy: 0.6308\n",
      "Epoch 62/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.5334 - accuracy: 0.6580 - val_loss: 0.5268 - val_accuracy: 0.6308\n",
      "Epoch 63/75\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.5532 - accuracy: 0.6148 - val_loss: 0.5676 - val_accuracy: 0.6308\n",
      "Epoch 64/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.5550 - accuracy: 0.6206 - val_loss: 0.5246 - val_accuracy: 0.6308\n",
      "Epoch 65/75\n",
      "33/33 [==============================] - 3s 90ms/step - loss: 0.5408 - accuracy: 0.6206 - val_loss: 0.5958 - val_accuracy: 0.6308\n",
      "Epoch 66/75\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.5582 - accuracy: 0.6244 - val_loss: 0.5264 - val_accuracy: 0.6154\n",
      "Epoch 67/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.5473 - accuracy: 0.6186 - val_loss: 0.5804 - val_accuracy: 0.6308\n",
      "Epoch 68/75\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.5455 - accuracy: 0.6407 - val_loss: 0.5273 - val_accuracy: 0.6308\n",
      "Epoch 69/75\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.5369 - accuracy: 0.6609 - val_loss: 0.5249 - val_accuracy: 0.6308\n",
      "Epoch 70/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.5260 - accuracy: 0.6734 - val_loss: 0.5242 - val_accuracy: 0.6308\n",
      "Epoch 71/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.5467 - accuracy: 0.6302 - val_loss: 0.5515 - val_accuracy: 0.6308\n",
      "Epoch 72/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.5503 - accuracy: 0.6225 - val_loss: 0.5333 - val_accuracy: 0.6308\n",
      "Epoch 73/75\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.5280 - accuracy: 0.6638 - val_loss: 0.5620 - val_accuracy: 0.6308\n",
      "Epoch 74/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.5481 - accuracy: 0.6321 - val_loss: 0.5391 - val_accuracy: 0.6308\n",
      "Epoch 75/75\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.5363 - accuracy: 0.6388 - val_loss: 0.5253 - val_accuracy: 0.6154\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5452 - accuracy: 0.5649\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5253 - accuracy: 0.6154\n",
      "LOSS : 0.525340735912323\n",
      "ACCURACY : 0.6153846383094788\n",
      "LOSS : 0.5452069640159607\n",
      "ACCURACY : 0.5648854970932007\n",
      "5/5 [==============================] - 0s 20ms/step\n",
      "Accuracy: 0.564885\n",
      "Precision: 0.501449\n",
      "Recall: 0.406393\n",
      "F1 score: 0.343357\n",
      "Fold:2, Train set: 1302, Test set:326\n",
      "====================\n",
      "Fold:  2\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\muham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\muham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\muham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 24, 24, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 24, 24, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 22, 22, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 11, 11, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 11, 11, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 11, 11, 32)        0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 9, 9, 32)          9248      \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 4, 4, 32)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 4, 4, 32)          128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 4, 4, 32)          0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 286019 (1.09 MB)\n",
      "Trainable params: 284803 (1.09 MB)\n",
      "Non-trainable params: 1216 (4.75 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/75\n",
      "33/33 [==============================] - 5s 87ms/step - loss: 1.4995 - accuracy: 0.4467 - val_loss: 0.8530 - val_accuracy: 0.6462\n",
      "Epoch 2/75\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.9338 - accuracy: 0.5860 - val_loss: 0.9380 - val_accuracy: 0.5692\n",
      "Epoch 3/75\n",
      "33/33 [==============================] - 3s 93ms/step - loss: 0.8179 - accuracy: 0.5946 - val_loss: 1.1290 - val_accuracy: 0.5692\n",
      "Epoch 4/75\n",
      "33/33 [==============================] - 3s 92ms/step - loss: 0.7474 - accuracy: 0.6330 - val_loss: 1.1187 - val_accuracy: 0.5692\n",
      "Epoch 5/75\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.7240 - accuracy: 0.6129 - val_loss: 1.0635 - val_accuracy: 0.5692\n",
      "Epoch 6/75\n",
      "33/33 [==============================] - 3s 78ms/step - loss: 0.6681 - accuracy: 0.6206 - val_loss: 1.1072 - val_accuracy: 0.5692\n",
      "Epoch 7/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.6899 - accuracy: 0.5994 - val_loss: 1.0093 - val_accuracy: 0.5692\n",
      "Epoch 8/75\n",
      "33/33 [==============================] - 3s 79ms/step - loss: 0.6855 - accuracy: 0.5908 - val_loss: 0.9286 - val_accuracy: 0.5692\n",
      "Epoch 9/75\n",
      "33/33 [==============================] - 3s 96ms/step - loss: 0.6179 - accuracy: 0.6254 - val_loss: 0.9024 - val_accuracy: 0.5692\n",
      "Epoch 10/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.6468 - accuracy: 0.6061 - val_loss: 0.9039 - val_accuracy: 0.5692\n",
      "Epoch 11/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.6137 - accuracy: 0.6196 - val_loss: 0.8351 - val_accuracy: 0.5154\n",
      "Epoch 12/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.6118 - accuracy: 0.6263 - val_loss: 0.7841 - val_accuracy: 0.5154\n",
      "Epoch 13/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.6192 - accuracy: 0.6436 - val_loss: 0.7573 - val_accuracy: 0.5154\n",
      "Epoch 14/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.6153 - accuracy: 0.6090 - val_loss: 0.5990 - val_accuracy: 0.5923\n",
      "Epoch 15/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.6241 - accuracy: 0.6033 - val_loss: 0.5848 - val_accuracy: 0.5923\n",
      "Epoch 16/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.5896 - accuracy: 0.6302 - val_loss: 0.5503 - val_accuracy: 0.5923\n",
      "Epoch 17/75\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.5932 - accuracy: 0.6119 - val_loss: 0.5493 - val_accuracy: 0.6462\n",
      "Epoch 18/75\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.5849 - accuracy: 0.6071 - val_loss: 0.5442 - val_accuracy: 0.5923\n",
      "Epoch 19/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.5688 - accuracy: 0.6302 - val_loss: 0.5531 - val_accuracy: 0.5923\n",
      "Epoch 20/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.5764 - accuracy: 0.6129 - val_loss: 0.5348 - val_accuracy: 0.6462\n",
      "Epoch 21/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.5740 - accuracy: 0.6369 - val_loss: 0.5405 - val_accuracy: 0.6462\n",
      "Epoch 22/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.6028 - accuracy: 0.5965 - val_loss: 0.5334 - val_accuracy: 0.7231\n",
      "Epoch 23/75\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.5671 - accuracy: 0.6071 - val_loss: 0.5345 - val_accuracy: 0.6462\n",
      "Epoch 24/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.5688 - accuracy: 0.6138 - val_loss: 0.5363 - val_accuracy: 0.5923\n",
      "Epoch 25/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.5754 - accuracy: 0.6263 - val_loss: 0.5512 - val_accuracy: 0.6462\n",
      "Epoch 26/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.5677 - accuracy: 0.6196 - val_loss: 0.5298 - val_accuracy: 0.6462\n",
      "Epoch 27/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.5628 - accuracy: 0.6119 - val_loss: 0.5377 - val_accuracy: 0.5923\n",
      "Epoch 28/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.5472 - accuracy: 0.6475 - val_loss: 0.5290 - val_accuracy: 0.6077\n",
      "Epoch 29/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.5665 - accuracy: 0.6110 - val_loss: 0.5284 - val_accuracy: 0.7077\n",
      "Epoch 30/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.5878 - accuracy: 0.6148 - val_loss: 0.5285 - val_accuracy: 0.6462\n",
      "Epoch 31/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.5521 - accuracy: 0.6378 - val_loss: 0.5294 - val_accuracy: 0.6462\n",
      "Epoch 32/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.5551 - accuracy: 0.6580 - val_loss: 0.5294 - val_accuracy: 0.7308\n",
      "Epoch 33/75\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.5635 - accuracy: 0.6465 - val_loss: 0.5255 - val_accuracy: 0.6615\n",
      "Epoch 34/75\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.5189 - accuracy: 0.6916 - val_loss: 0.6112 - val_accuracy: 0.6462\n",
      "Epoch 35/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.5103 - accuracy: 0.7032 - val_loss: 0.5101 - val_accuracy: 0.6154\n",
      "Epoch 36/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.4160 - accuracy: 0.8002 - val_loss: 0.3929 - val_accuracy: 0.8154\n",
      "Epoch 37/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.3444 - accuracy: 0.8348 - val_loss: 1.6312 - val_accuracy: 0.5923\n",
      "Epoch 38/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.2469 - accuracy: 0.9030 - val_loss: 1.0056 - val_accuracy: 0.5846\n",
      "Epoch 39/75\n",
      "33/33 [==============================] - 3s 79ms/step - loss: 0.1993 - accuracy: 0.9203 - val_loss: 0.1346 - val_accuracy: 0.9385\n",
      "Epoch 40/75\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.1367 - accuracy: 0.9491 - val_loss: 0.1554 - val_accuracy: 0.9308\n",
      "Epoch 41/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.1133 - accuracy: 0.9654 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
      "Epoch 42/75\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.0946 - accuracy: 0.9645 - val_loss: 0.1599 - val_accuracy: 0.9385\n",
      "Epoch 43/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.0809 - accuracy: 0.9779 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 44/75\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.0911 - accuracy: 0.9683 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 45/75\n",
      "33/33 [==============================] - 3s 90ms/step - loss: 0.1034 - accuracy: 0.9625 - val_loss: 1.0212 - val_accuracy: 0.6462\n",
      "Epoch 46/75\n",
      "33/33 [==============================] - 3s 90ms/step - loss: 0.0616 - accuracy: 0.9789 - val_loss: 0.0675 - val_accuracy: 0.9692\n",
      "Epoch 47/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.0884 - accuracy: 0.9721 - val_loss: 0.0113 - val_accuracy: 0.9923\n",
      "Epoch 48/75\n",
      "33/33 [==============================] - 3s 78ms/step - loss: 0.0763 - accuracy: 0.9769 - val_loss: 0.2664 - val_accuracy: 0.8538\n",
      "Epoch 49/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.0655 - accuracy: 0.9837 - val_loss: 0.4493 - val_accuracy: 0.6462\n",
      "Epoch 50/75\n",
      "33/33 [==============================] - 3s 79ms/step - loss: 0.0715 - accuracy: 0.9779 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 51/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.0577 - accuracy: 0.9894 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 52/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.0669 - accuracy: 0.9779 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 53/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.0596 - accuracy: 0.9875 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 54/75\n",
      "33/33 [==============================] - 3s 77ms/step - loss: 0.0511 - accuracy: 0.9875 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
      "Epoch 55/75\n",
      "33/33 [==============================] - 3s 76ms/step - loss: 0.0521 - accuracy: 0.9923 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 56/75\n",
      "33/33 [==============================] - 3s 76ms/step - loss: 0.0476 - accuracy: 0.9923 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 57/75\n",
      "33/33 [==============================] - 3s 78ms/step - loss: 0.0421 - accuracy: 0.9875 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 58/75\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.0533 - accuracy: 0.9914 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 59/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.0646 - accuracy: 0.9846 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 60/75\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.0552 - accuracy: 0.9875 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 61/75\n",
      "33/33 [==============================] - 3s 79ms/step - loss: 0.0564 - accuracy: 0.9885 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 62/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.0432 - accuracy: 0.9914 - val_loss: 0.0394 - val_accuracy: 1.0000\n",
      "Epoch 63/75\n",
      "33/33 [==============================] - 3s 79ms/step - loss: 0.0513 - accuracy: 0.9827 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 64/75\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.0506 - accuracy: 0.9923 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 65/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.0456 - accuracy: 0.9933 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 66/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.0393 - accuracy: 0.9923 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 67/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.0436 - accuracy: 0.9952 - val_loss: 7.2130e-04 - val_accuracy: 1.0000\n",
      "Epoch 68/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.0393 - accuracy: 0.9933 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 69/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.0460 - accuracy: 0.9894 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 70/75\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.0427 - accuracy: 0.9923 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 71/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.0464 - accuracy: 0.9923 - val_loss: 6.5562e-04 - val_accuracy: 1.0000\n",
      "Epoch 72/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.0452 - accuracy: 0.9914 - val_loss: 7.2201e-04 - val_accuracy: 1.0000\n",
      "Epoch 73/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.0330 - accuracy: 0.9952 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 74/75\n",
      "33/33 [==============================] - 3s 79ms/step - loss: 0.0453 - accuracy: 0.9904 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 75/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.0482 - accuracy: 0.9894 - val_loss: 0.0367 - val_accuracy: 1.0000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0346 - accuracy: 1.0000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0367 - accuracy: 1.0000\n",
      "LOSS : 0.036685943603515625\n",
      "ACCURACY : 1.0\n",
      "LOSS : 0.03459054231643677\n",
      "ACCURACY : 1.0\n",
      "5/5 [==============================] - 0s 17ms/step\n",
      "Accuracy: 1.000000\n",
      "Precision: 0.666667\n",
      "Recall: 0.666667\n",
      "F1 score: 0.666667\n",
      "Fold:3, Train set: 1302, Test set:326\n",
      "====================\n",
      "Fold:  3\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\muham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\muham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\muham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (None, 24, 24, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 24, 24, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 22, 22, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 11, 11, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 11, 11, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 11, 11, 32)        0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 9, 9, 32)          9248      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 4, 4, 32)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 4, 4, 32)          128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 4, 4, 32)          0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 286019 (1.09 MB)\n",
      "Trainable params: 284803 (1.09 MB)\n",
      "Non-trainable params: 1216 (4.75 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/75\n",
      "33/33 [==============================] - 5s 84ms/step - loss: 1.3164 - accuracy: 0.5139 - val_loss: 0.8188 - val_accuracy: 0.4692\n",
      "Epoch 2/75\n",
      "33/33 [==============================] - 3s 76ms/step - loss: 0.9085 - accuracy: 0.5889 - val_loss: 0.7496 - val_accuracy: 0.5769\n",
      "Epoch 3/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.7613 - accuracy: 0.6254 - val_loss: 0.7096 - val_accuracy: 0.5769\n",
      "Epoch 4/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.7471 - accuracy: 0.6273 - val_loss: 0.7160 - val_accuracy: 0.4692\n",
      "Epoch 5/75\n",
      "33/33 [==============================] - 3s 79ms/step - loss: 0.7279 - accuracy: 0.6475 - val_loss: 0.6855 - val_accuracy: 0.5769\n",
      "Epoch 6/75\n",
      "33/33 [==============================] - 3s 78ms/step - loss: 0.7076 - accuracy: 0.6254 - val_loss: 0.6867 - val_accuracy: 0.5769\n",
      "Epoch 7/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.6578 - accuracy: 0.6446 - val_loss: 0.6476 - val_accuracy: 0.6538\n",
      "Epoch 8/75\n",
      "33/33 [==============================] - 3s 77ms/step - loss: 0.6529 - accuracy: 0.6321 - val_loss: 0.6371 - val_accuracy: 0.6538\n",
      "Epoch 9/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.6905 - accuracy: 0.6100 - val_loss: 0.6263 - val_accuracy: 0.6538\n",
      "Epoch 10/75\n",
      "33/33 [==============================] - 3s 79ms/step - loss: 0.6566 - accuracy: 0.6186 - val_loss: 0.7764 - val_accuracy: 0.6538\n",
      "Epoch 11/75\n",
      "33/33 [==============================] - 3s 79ms/step - loss: 0.6275 - accuracy: 0.6330 - val_loss: 0.6218 - val_accuracy: 0.6538\n",
      "Epoch 12/75\n",
      "33/33 [==============================] - 3s 78ms/step - loss: 0.6279 - accuracy: 0.6263 - val_loss: 0.6275 - val_accuracy: 0.5769\n",
      "Epoch 13/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.5876 - accuracy: 0.6388 - val_loss: 0.5795 - val_accuracy: 0.6538\n",
      "Epoch 14/75\n",
      "33/33 [==============================] - 3s 78ms/step - loss: 0.5913 - accuracy: 0.6234 - val_loss: 0.6057 - val_accuracy: 0.6538\n",
      "Epoch 15/75\n",
      "33/33 [==============================] - 3s 79ms/step - loss: 0.6027 - accuracy: 0.6148 - val_loss: 0.5656 - val_accuracy: 0.6538\n",
      "Epoch 16/75\n",
      "33/33 [==============================] - 3s 79ms/step - loss: 0.6196 - accuracy: 0.6206 - val_loss: 0.5751 - val_accuracy: 0.6538\n",
      "Epoch 17/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.5952 - accuracy: 0.6206 - val_loss: 0.5646 - val_accuracy: 0.6538\n",
      "Epoch 18/75\n",
      "33/33 [==============================] - 3s 79ms/step - loss: 0.6018 - accuracy: 0.6225 - val_loss: 0.5603 - val_accuracy: 0.6538\n",
      "Epoch 19/75\n",
      "33/33 [==============================] - 3s 78ms/step - loss: 0.5755 - accuracy: 0.6254 - val_loss: 0.5609 - val_accuracy: 0.6538\n",
      "Epoch 20/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.5708 - accuracy: 0.6398 - val_loss: 0.5583 - val_accuracy: 0.6538\n",
      "Epoch 21/75\n",
      "33/33 [==============================] - 3s 79ms/step - loss: 0.5628 - accuracy: 0.6321 - val_loss: 0.6093 - val_accuracy: 0.5462\n",
      "Epoch 22/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.5458 - accuracy: 0.6580 - val_loss: 0.5536 - val_accuracy: 0.6538\n",
      "Epoch 23/75\n",
      "33/33 [==============================] - 3s 79ms/step - loss: 0.5526 - accuracy: 0.6561 - val_loss: 0.5470 - val_accuracy: 0.6538\n",
      "Epoch 24/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.5572 - accuracy: 0.6619 - val_loss: 0.5853 - val_accuracy: 0.5462\n",
      "Epoch 25/75\n",
      "33/33 [==============================] - 3s 79ms/step - loss: 0.5416 - accuracy: 0.6657 - val_loss: 0.5396 - val_accuracy: 0.6538\n",
      "Epoch 26/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.4848 - accuracy: 0.7291 - val_loss: 0.4270 - val_accuracy: 0.8000\n",
      "Epoch 27/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.3530 - accuracy: 0.8425 - val_loss: 0.8120 - val_accuracy: 0.6538\n",
      "Epoch 28/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.2437 - accuracy: 0.9097 - val_loss: 0.1271 - val_accuracy: 0.9769\n",
      "Epoch 29/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.1849 - accuracy: 0.9270 - val_loss: 0.1083 - val_accuracy: 0.9923\n",
      "Epoch 30/75\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.1425 - accuracy: 0.9481 - val_loss: 0.6359 - val_accuracy: 0.8385\n",
      "Epoch 31/75\n",
      "33/33 [==============================] - 3s 90ms/step - loss: 0.1179 - accuracy: 0.9539 - val_loss: 0.0581 - val_accuracy: 0.9923\n",
      "Epoch 32/75\n",
      "33/33 [==============================] - 3s 96ms/step - loss: 0.0850 - accuracy: 0.9769 - val_loss: 0.0524 - val_accuracy: 0.9846\n",
      "Epoch 33/75\n",
      "33/33 [==============================] - 3s 94ms/step - loss: 0.0751 - accuracy: 0.9808 - val_loss: 0.0493 - val_accuracy: 0.9923\n",
      "Epoch 34/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.0513 - accuracy: 0.9856 - val_loss: 0.0457 - val_accuracy: 0.9923\n",
      "Epoch 35/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.0747 - accuracy: 0.9721 - val_loss: 0.0774 - val_accuracy: 0.9923\n",
      "Epoch 36/75\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.0524 - accuracy: 0.9817 - val_loss: 0.0776 - val_accuracy: 0.9923\n",
      "Epoch 37/75\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.0533 - accuracy: 0.9856 - val_loss: 0.1649 - val_accuracy: 0.9923\n",
      "Epoch 38/75\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.0566 - accuracy: 0.9817 - val_loss: 0.2645 - val_accuracy: 0.7692\n",
      "Epoch 39/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.0319 - accuracy: 0.9904 - val_loss: 0.0381 - val_accuracy: 0.9923\n",
      "Epoch 40/75\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.0454 - accuracy: 0.9866 - val_loss: 0.0431 - val_accuracy: 0.9923\n",
      "Epoch 41/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.0363 - accuracy: 0.9923 - val_loss: 0.0581 - val_accuracy: 0.9923\n",
      "Epoch 42/75\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.0321 - accuracy: 0.9942 - val_loss: 0.0592 - val_accuracy: 0.9923\n",
      "Epoch 43/75\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.0383 - accuracy: 0.9894 - val_loss: 0.0606 - val_accuracy: 0.9923\n",
      "Epoch 44/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.0372 - accuracy: 0.9914 - val_loss: 0.0697 - val_accuracy: 0.9923\n",
      "Epoch 45/75\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.0278 - accuracy: 0.9952 - val_loss: 0.0564 - val_accuracy: 0.9923\n",
      "Epoch 46/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.0253 - accuracy: 0.9981 - val_loss: 0.0600 - val_accuracy: 0.9923\n",
      "Epoch 47/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.0574 - val_accuracy: 0.9923\n",
      "Epoch 48/75\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.0297 - accuracy: 0.9904 - val_loss: 0.0545 - val_accuracy: 0.9923\n",
      "Epoch 49/75\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.0156 - accuracy: 0.9952 - val_loss: 0.0679 - val_accuracy: 0.9923\n",
      "Epoch 50/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.0281 - accuracy: 0.9952 - val_loss: 0.0658 - val_accuracy: 0.9923\n",
      "Epoch 51/75\n",
      "33/33 [==============================] - 3s 90ms/step - loss: 0.0302 - accuracy: 0.9933 - val_loss: 0.0398 - val_accuracy: 0.9923\n",
      "Epoch 52/75\n",
      "33/33 [==============================] - 3s 94ms/step - loss: 0.0289 - accuracy: 0.9923 - val_loss: 0.0878 - val_accuracy: 0.9923\n",
      "Epoch 53/75\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.0185 - accuracy: 0.9952 - val_loss: 0.0786 - val_accuracy: 0.9923\n",
      "Epoch 54/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.0291 - accuracy: 0.9933 - val_loss: 0.0387 - val_accuracy: 0.9923\n",
      "Epoch 55/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.0286 - accuracy: 0.9933 - val_loss: 0.0520 - val_accuracy: 0.9923\n",
      "Epoch 56/75\n",
      "33/33 [==============================] - 3s 93ms/step - loss: 0.0237 - accuracy: 0.9962 - val_loss: 0.0616 - val_accuracy: 0.9923\n",
      "Epoch 57/75\n",
      "33/33 [==============================] - 3s 78ms/step - loss: 0.0314 - accuracy: 0.9933 - val_loss: 0.0398 - val_accuracy: 0.9923\n",
      "Epoch 58/75\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.0318 - accuracy: 0.9933 - val_loss: 0.0897 - val_accuracy: 0.9923\n",
      "Epoch 59/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.0265 - accuracy: 0.9952 - val_loss: 0.8821 - val_accuracy: 0.6538\n",
      "Epoch 60/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.0167 - accuracy: 0.9962 - val_loss: 0.0717 - val_accuracy: 0.9923\n",
      "Epoch 61/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.0143 - accuracy: 0.9971 - val_loss: 0.0557 - val_accuracy: 0.9923\n",
      "Epoch 62/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.0163 - accuracy: 0.9981 - val_loss: 0.0786 - val_accuracy: 0.9923\n",
      "Epoch 63/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.0131 - accuracy: 0.9971 - val_loss: 0.0787 - val_accuracy: 0.9923\n",
      "Epoch 64/75\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.0176 - accuracy: 0.9962 - val_loss: 0.2322 - val_accuracy: 0.8615\n",
      "Epoch 65/75\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.0251 - accuracy: 0.9914 - val_loss: 0.2280 - val_accuracy: 0.8769\n",
      "Epoch 66/75\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 0.0478 - val_accuracy: 0.9923\n",
      "Epoch 67/75\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.0173 - accuracy: 0.9962 - val_loss: 0.0564 - val_accuracy: 0.9923\n",
      "Epoch 68/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.0191 - accuracy: 0.9962 - val_loss: 0.0902 - val_accuracy: 0.9923\n",
      "Epoch 69/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.0237 - accuracy: 0.9933 - val_loss: 0.0612 - val_accuracy: 0.9923\n",
      "Epoch 70/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.0742 - val_accuracy: 0.9923\n",
      "Epoch 71/75\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.0191 - accuracy: 0.9962 - val_loss: 0.0836 - val_accuracy: 0.9923\n",
      "Epoch 72/75\n",
      "33/33 [==============================] - 3s 90ms/step - loss: 0.0185 - accuracy: 0.9962 - val_loss: 0.0625 - val_accuracy: 0.9923\n",
      "Epoch 73/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.0090 - accuracy: 0.9990 - val_loss: 0.0796 - val_accuracy: 0.9923\n",
      "Epoch 74/75\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 0.0773 - val_accuracy: 0.9923\n",
      "Epoch 75/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.0164 - accuracy: 0.9942 - val_loss: 0.0476 - val_accuracy: 0.9923\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.7952e-04 - accuracy: 1.0000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0476 - accuracy: 0.9923\n",
      "LOSS : 0.04764893278479576\n",
      "ACCURACY : 0.9923076629638672\n",
      "LOSS : 0.000879516126587987\n",
      "ACCURACY : 1.0\n",
      "5/5 [==============================] - 0s 16ms/step\n",
      "Accuracy: 1.000000\n",
      "Precision: 0.666667\n",
      "Recall: 0.666667\n",
      "F1 score: 0.666667\n",
      "Fold:4, Train set: 1303, Test set:325\n",
      "====================\n",
      "Fold:  4\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\muham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\muham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\muham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPooli  (None, 24, 24, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 24, 24, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 22, 22, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPooli  (None, 11, 11, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 11, 11, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 11, 11, 32)        0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 9, 9, 32)          9248      \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPooli  (None, 4, 4, 32)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 4, 4, 32)          128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 4, 4, 32)          0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 286019 (1.09 MB)\n",
      "Trainable params: 284803 (1.09 MB)\n",
      "Non-trainable params: 1216 (4.75 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/75\n",
      "33/33 [==============================] - 5s 92ms/step - loss: 1.2491 - accuracy: 0.5029 - val_loss: 0.8292 - val_accuracy: 0.5923\n",
      "Epoch 2/75\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.8411 - accuracy: 0.5902 - val_loss: 0.7702 - val_accuracy: 0.6077\n",
      "Epoch 3/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.7585 - accuracy: 0.6132 - val_loss: 0.8082 - val_accuracy: 0.4769\n",
      "Epoch 4/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.7671 - accuracy: 0.6161 - val_loss: 0.8486 - val_accuracy: 0.4692\n",
      "Epoch 5/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.6305 - accuracy: 0.6612 - val_loss: 0.8808 - val_accuracy: 0.5462\n",
      "Epoch 6/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.6825 - accuracy: 0.6305 - val_loss: 0.8529 - val_accuracy: 0.6077\n",
      "Epoch 7/75\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.6736 - accuracy: 0.6113 - val_loss: 0.6114 - val_accuracy: 0.6077\n",
      "Epoch 8/75\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.6283 - accuracy: 0.6382 - val_loss: 0.7296 - val_accuracy: 0.6077\n",
      "Epoch 9/75\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.6293 - accuracy: 0.6430 - val_loss: 0.7075 - val_accuracy: 0.6077\n",
      "Epoch 10/75\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.6327 - accuracy: 0.6200 - val_loss: 0.6675 - val_accuracy: 0.6077\n",
      "Epoch 11/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.6199 - accuracy: 0.6209 - val_loss: 0.5491 - val_accuracy: 0.6385\n",
      "Epoch 12/75\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.5871 - accuracy: 0.6497 - val_loss: 0.5405 - val_accuracy: 0.6385\n",
      "Epoch 13/75\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.6132 - accuracy: 0.6200 - val_loss: 0.5363 - val_accuracy: 0.6385\n",
      "Epoch 14/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.6211 - accuracy: 0.6084 - val_loss: 0.5364 - val_accuracy: 0.7385\n",
      "Epoch 15/75\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.5935 - accuracy: 0.6248 - val_loss: 0.5300 - val_accuracy: 0.6385\n",
      "Epoch 16/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.5847 - accuracy: 0.6440 - val_loss: 0.5581 - val_accuracy: 0.6385\n",
      "Epoch 17/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.5431 - accuracy: 0.6583 - val_loss: 0.5154 - val_accuracy: 0.6385\n",
      "Epoch 18/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.5092 - accuracy: 0.7207 - val_loss: 0.5589 - val_accuracy: 0.6077\n",
      "Epoch 19/75\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.4066 - accuracy: 0.7985 - val_loss: 0.3978 - val_accuracy: 0.7462\n",
      "Epoch 20/75\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.2786 - accuracy: 0.8791 - val_loss: 0.5934 - val_accuracy: 0.7462\n",
      "Epoch 21/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.1811 - accuracy: 0.9271 - val_loss: 0.2664 - val_accuracy: 0.7385\n",
      "Epoch 22/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.1849 - accuracy: 0.9251 - val_loss: 0.4130 - val_accuracy: 0.6385\n",
      "Epoch 23/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.0857 - accuracy: 0.9712 - val_loss: 0.0836 - val_accuracy: 0.9846\n",
      "Epoch 24/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.0781 - accuracy: 0.9693 - val_loss: 0.4676 - val_accuracy: 0.8769\n",
      "Epoch 25/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.0792 - accuracy: 0.9722 - val_loss: 0.1582 - val_accuracy: 0.9923\n",
      "Epoch 26/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.0690 - accuracy: 0.9798 - val_loss: 0.2680 - val_accuracy: 0.7538\n",
      "Epoch 27/75\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.0426 - accuracy: 0.9856 - val_loss: 0.0698 - val_accuracy: 0.9923\n",
      "Epoch 28/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.0519 - accuracy: 0.9866 - val_loss: 0.0620 - val_accuracy: 0.9923\n",
      "Epoch 29/75\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.0530 - accuracy: 0.9837 - val_loss: 0.0399 - val_accuracy: 0.9923\n",
      "Epoch 30/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.0698 - accuracy: 0.9798 - val_loss: 0.1448 - val_accuracy: 0.9615\n",
      "Epoch 31/75\n",
      "33/33 [==============================] - 3s 90ms/step - loss: 0.0692 - accuracy: 0.9798 - val_loss: 0.0386 - val_accuracy: 0.9923\n",
      "Epoch 32/75\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.0548 - accuracy: 0.9818 - val_loss: 0.0502 - val_accuracy: 0.9923\n",
      "Epoch 33/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.0360 - accuracy: 0.9904 - val_loss: 0.0852 - val_accuracy: 0.9923\n",
      "Epoch 34/75\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.0413 - accuracy: 0.9875 - val_loss: 0.0911 - val_accuracy: 0.9923\n",
      "Epoch 35/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.0405 - accuracy: 0.9904 - val_loss: 0.0365 - val_accuracy: 0.9923\n",
      "Epoch 36/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.0383 - accuracy: 0.9866 - val_loss: 0.0137 - val_accuracy: 0.9923\n",
      "Epoch 37/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.0413 - accuracy: 0.9875 - val_loss: 0.0179 - val_accuracy: 0.9923\n",
      "Epoch 38/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.0348 - accuracy: 0.9894 - val_loss: 0.0666 - val_accuracy: 0.9923\n",
      "Epoch 39/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.0365 - accuracy: 0.9914 - val_loss: 0.0137 - val_accuracy: 0.9923\n",
      "Epoch 40/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.0339 - accuracy: 0.9923 - val_loss: 0.0125 - val_accuracy: 0.9923\n",
      "Epoch 41/75\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.0319 - accuracy: 0.9923 - val_loss: 0.0149 - val_accuracy: 0.9923\n",
      "Epoch 42/75\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.0297 - accuracy: 0.9962 - val_loss: 0.0126 - val_accuracy: 0.9923\n",
      "Epoch 43/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.0508 - accuracy: 0.9875 - val_loss: 0.0585 - val_accuracy: 0.9846\n",
      "Epoch 44/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.0324 - accuracy: 0.9942 - val_loss: 0.0159 - val_accuracy: 0.9923\n",
      "Epoch 45/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.0239 - accuracy: 0.9952 - val_loss: 0.0077 - val_accuracy: 0.9923\n",
      "Epoch 46/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.0220 - accuracy: 0.9971 - val_loss: 0.0085 - val_accuracy: 0.9923\n",
      "Epoch 47/75\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.0280 - accuracy: 0.9904 - val_loss: 0.0089 - val_accuracy: 0.9923\n",
      "Epoch 48/75\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.0229 - accuracy: 0.9942 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 49/75\n",
      "33/33 [==============================] - 3s 90ms/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0142 - val_accuracy: 0.9923\n",
      "Epoch 50/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.0259 - accuracy: 0.9952 - val_loss: 0.0122 - val_accuracy: 0.9923\n",
      "Epoch 51/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.0246 - accuracy: 0.9952 - val_loss: 0.0209 - val_accuracy: 0.9923\n",
      "Epoch 52/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.0267 - accuracy: 0.9923 - val_loss: 0.0152 - val_accuracy: 0.9923\n",
      "Epoch 53/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.0249 - accuracy: 0.9952 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 54/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.0251 - accuracy: 0.9933 - val_loss: 0.0074 - val_accuracy: 0.9923\n",
      "Epoch 55/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.0323 - accuracy: 0.9942 - val_loss: 0.0227 - val_accuracy: 0.9923\n",
      "Epoch 56/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.0260 - accuracy: 0.9933 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
      "Epoch 57/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.0277 - accuracy: 0.9933 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 58/75\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.0194 - accuracy: 0.9962 - val_loss: 0.0155 - val_accuracy: 0.9923\n",
      "Epoch 59/75\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.0209 - accuracy: 0.9962 - val_loss: 0.0102 - val_accuracy: 0.9923\n",
      "Epoch 60/75\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.0350 - accuracy: 0.9894 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 61/75\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.0261 - accuracy: 0.9952 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 62/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.0287 - accuracy: 0.9971 - val_loss: 0.0086 - val_accuracy: 0.9923\n",
      "Epoch 63/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.0245 - accuracy: 0.9952 - val_loss: 0.0092 - val_accuracy: 0.9923\n",
      "Epoch 64/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.0254 - accuracy: 0.9971 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 65/75\n",
      "33/33 [==============================] - 3s 90ms/step - loss: 0.0265 - accuracy: 0.9981 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 66/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.0202 - accuracy: 0.9962 - val_loss: 0.0114 - val_accuracy: 0.9923\n",
      "Epoch 67/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.0169 - accuracy: 0.9971 - val_loss: 0.0177 - val_accuracy: 0.9923\n",
      "Epoch 68/75\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.0129 - accuracy: 0.9981 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 69/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.0291 - accuracy: 0.9942 - val_loss: 0.0071 - val_accuracy: 0.9923\n",
      "Epoch 70/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.0236 - accuracy: 0.9942 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 71/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.0257 - accuracy: 0.9971 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 72/75\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.0216 - accuracy: 0.9952 - val_loss: 0.0099 - val_accuracy: 0.9923\n",
      "Epoch 73/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.0271 - accuracy: 0.9971 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 74/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.0297 - accuracy: 0.9942 - val_loss: 0.0127 - val_accuracy: 0.9923\n",
      "Epoch 75/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.0258 - accuracy: 0.9962 - val_loss: 0.0092 - val_accuracy: 0.9923\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0823 - accuracy: 0.9924\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0092 - accuracy: 0.9923\n",
      "LOSS : 0.00920118112117052\n",
      "ACCURACY : 0.9923076629638672\n",
      "LOSS : 0.08229881525039673\n",
      "ACCURACY : 0.9923664331436157\n",
      "5/5 [==============================] - 0s 15ms/step\n",
      "Accuracy: 0.992366\n",
      "Precision: 0.661616\n",
      "Recall: 0.661616\n",
      "F1 score: 0.661578\n",
      "Fold:5, Train set: 1303, Test set:325\n",
      "====================\n",
      "Fold:  5\n",
      "====================\n",
      "Model: \"sequential_5\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\muham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\muham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\muham\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_15 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPooli  (None, 24, 24, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_20 (Ba  (None, 24, 24, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 22, 22, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPooli  (None, 11, 11, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_21 (Ba  (None, 11, 11, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 11, 11, 32)        0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 9, 9, 32)          9248      \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPooli  (None, 4, 4, 32)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_22 (Ba  (None, 4, 4, 32)          128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 4, 4, 32)          0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_23 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 286019 (1.09 MB)\n",
      "Trainable params: 284803 (1.09 MB)\n",
      "Non-trainable params: 1216 (4.75 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/75\n",
      "33/33 [==============================] - 5s 86ms/step - loss: 1.2861 - accuracy: 0.4750 - val_loss: 0.8478 - val_accuracy: 0.6000\n",
      "Epoch 2/75\n",
      "33/33 [==============================] - 3s 77ms/step - loss: 0.9159 - accuracy: 0.5825 - val_loss: 0.8310 - val_accuracy: 0.5308\n",
      "Epoch 3/75\n",
      "33/33 [==============================] - 3s 79ms/step - loss: 0.7454 - accuracy: 0.6209 - val_loss: 0.7546 - val_accuracy: 0.6000\n",
      "Epoch 4/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.7296 - accuracy: 0.6238 - val_loss: 0.7502 - val_accuracy: 0.4538\n",
      "Epoch 5/75\n",
      "33/33 [==============================] - 3s 79ms/step - loss: 0.7067 - accuracy: 0.6353 - val_loss: 0.7778 - val_accuracy: 0.5308\n",
      "Epoch 6/75\n",
      "33/33 [==============================] - 3s 93ms/step - loss: 0.7018 - accuracy: 0.6113 - val_loss: 0.7479 - val_accuracy: 0.6000\n",
      "Epoch 7/75\n",
      "33/33 [==============================] - 3s 92ms/step - loss: 0.6686 - accuracy: 0.6180 - val_loss: 0.7011 - val_accuracy: 0.4538\n",
      "Epoch 8/75\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.6427 - accuracy: 0.6411 - val_loss: 0.6749 - val_accuracy: 0.6000\n",
      "Epoch 9/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.6306 - accuracy: 0.6305 - val_loss: 0.7568 - val_accuracy: 0.6000\n",
      "Epoch 10/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.5911 - accuracy: 0.6555 - val_loss: 0.8082 - val_accuracy: 0.6000\n",
      "Epoch 11/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.6255 - accuracy: 0.6507 - val_loss: 0.6820 - val_accuracy: 0.6000\n",
      "Epoch 12/75\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.6326 - accuracy: 0.5998 - val_loss: 0.5478 - val_accuracy: 0.6000\n",
      "Epoch 13/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.5954 - accuracy: 0.6353 - val_loss: 0.5950 - val_accuracy: 0.6000\n",
      "Epoch 14/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.5807 - accuracy: 0.6392 - val_loss: 0.5285 - val_accuracy: 0.6000\n",
      "Epoch 15/75\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.5826 - accuracy: 0.6353 - val_loss: 0.5255 - val_accuracy: 0.6769\n",
      "Epoch 16/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.5933 - accuracy: 0.6296 - val_loss: 0.5730 - val_accuracy: 0.6000\n",
      "Epoch 17/75\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.5901 - accuracy: 0.6440 - val_loss: 0.5699 - val_accuracy: 0.6000\n",
      "Epoch 18/75\n",
      "33/33 [==============================] - 3s 98ms/step - loss: 0.5889 - accuracy: 0.6440 - val_loss: 0.5038 - val_accuracy: 0.6769\n",
      "Epoch 19/75\n",
      "33/33 [==============================] - 3s 104ms/step - loss: 0.5649 - accuracy: 0.6459 - val_loss: 0.5108 - val_accuracy: 0.6769\n",
      "Epoch 20/75\n",
      "33/33 [==============================] - 3s 92ms/step - loss: 0.5327 - accuracy: 0.7006 - val_loss: 0.4748 - val_accuracy: 0.6769\n",
      "Epoch 21/75\n",
      "33/33 [==============================] - 3s 96ms/step - loss: 0.4398 - accuracy: 0.7869 - val_loss: 0.4398 - val_accuracy: 0.8000\n",
      "Epoch 22/75\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.3021 - accuracy: 0.8599 - val_loss: 0.3902 - val_accuracy: 0.8769\n",
      "Epoch 23/75\n",
      "33/33 [==============================] - 3s 95ms/step - loss: 0.2100 - accuracy: 0.9107 - val_loss: 0.6206 - val_accuracy: 0.6769\n",
      "Epoch 24/75\n",
      "33/33 [==============================] - 3s 95ms/step - loss: 0.1601 - accuracy: 0.9443 - val_loss: 0.4045 - val_accuracy: 0.8000\n",
      "Epoch 25/75\n",
      "33/33 [==============================] - 3s 105ms/step - loss: 0.1152 - accuracy: 0.9616 - val_loss: 0.2520 - val_accuracy: 0.8538\n",
      "Epoch 26/75\n",
      "33/33 [==============================] - 3s 96ms/step - loss: 0.0991 - accuracy: 0.9712 - val_loss: 0.2861 - val_accuracy: 0.7692\n",
      "Epoch 27/75\n",
      "33/33 [==============================] - 3s 94ms/step - loss: 0.0769 - accuracy: 0.9779 - val_loss: 0.2663 - val_accuracy: 0.8000\n",
      "Epoch 28/75\n",
      "33/33 [==============================] - 3s 106ms/step - loss: 0.0908 - accuracy: 0.9702 - val_loss: 0.1404 - val_accuracy: 0.8538\n",
      "Epoch 29/75\n",
      "33/33 [==============================] - 4s 127ms/step - loss: 0.0469 - accuracy: 0.9866 - val_loss: 0.0770 - val_accuracy: 0.9769\n",
      "Epoch 30/75\n",
      "33/33 [==============================] - 3s 102ms/step - loss: 0.0737 - accuracy: 0.9731 - val_loss: 0.3908 - val_accuracy: 0.8538\n",
      "Epoch 31/75\n",
      "33/33 [==============================] - 3s 102ms/step - loss: 0.0455 - accuracy: 0.9904 - val_loss: 0.0622 - val_accuracy: 0.9923\n",
      "Epoch 32/75\n",
      "33/33 [==============================] - 3s 94ms/step - loss: 0.0445 - accuracy: 0.9904 - val_loss: 0.0861 - val_accuracy: 0.9769\n",
      "Epoch 33/75\n",
      "33/33 [==============================] - 3s 105ms/step - loss: 0.0536 - accuracy: 0.9856 - val_loss: 0.0928 - val_accuracy: 0.9769\n",
      "Epoch 34/75\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.0424 - accuracy: 0.9894 - val_loss: 0.0669 - val_accuracy: 0.9846\n",
      "Epoch 35/75\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.0286 - accuracy: 0.9933 - val_loss: 0.1615 - val_accuracy: 0.8692\n",
      "Epoch 36/75\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.0362 - accuracy: 0.9875 - val_loss: 0.1238 - val_accuracy: 0.9846\n",
      "Epoch 37/75\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.0257 - accuracy: 0.9952 - val_loss: 0.0899 - val_accuracy: 0.9769\n",
      "Epoch 38/75\n",
      "33/33 [==============================] - 3s 96ms/step - loss: 0.0370 - accuracy: 0.9942 - val_loss: 0.0546 - val_accuracy: 0.9923\n",
      "Epoch 39/75\n",
      "33/33 [==============================] - 3s 96ms/step - loss: 0.0370 - accuracy: 0.9923 - val_loss: 0.0843 - val_accuracy: 0.9846\n",
      "Epoch 40/75\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.0302 - accuracy: 0.9933 - val_loss: 0.0654 - val_accuracy: 0.9846\n",
      "Epoch 41/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.0243 - accuracy: 0.9962 - val_loss: 0.0388 - val_accuracy: 0.9923\n",
      "Epoch 42/75\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.0258 - accuracy: 0.9933 - val_loss: 0.0655 - val_accuracy: 0.9846\n",
      "Epoch 43/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.0427 - accuracy: 0.9875 - val_loss: 0.1198 - val_accuracy: 0.9923\n",
      "Epoch 44/75\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.0470 - accuracy: 0.9866 - val_loss: 0.0310 - val_accuracy: 0.9923\n",
      "Epoch 45/75\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.0263 - accuracy: 0.9952 - val_loss: 0.0640 - val_accuracy: 0.9923\n",
      "Epoch 46/75\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.0228 - accuracy: 0.9962 - val_loss: 0.0429 - val_accuracy: 0.9923\n",
      "Epoch 47/75\n",
      "33/33 [==============================] - 3s 94ms/step - loss: 0.0238 - accuracy: 0.9952 - val_loss: 0.0481 - val_accuracy: 0.9923\n",
      "Epoch 48/75\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.0316 - accuracy: 0.9923 - val_loss: 0.2763 - val_accuracy: 0.8692\n",
      "Epoch 49/75\n",
      "33/33 [==============================] - 4s 114ms/step - loss: 0.0387 - accuracy: 0.9885 - val_loss: 0.8608 - val_accuracy: 0.8692\n",
      "Epoch 50/75\n",
      "33/33 [==============================] - 3s 99ms/step - loss: 0.0342 - accuracy: 0.9942 - val_loss: 0.0482 - val_accuracy: 0.9923\n",
      "Epoch 51/75\n",
      "33/33 [==============================] - 3s 96ms/step - loss: 0.0230 - accuracy: 0.9971 - val_loss: 0.0630 - val_accuracy: 0.9846\n",
      "Epoch 52/75\n",
      "33/33 [==============================] - 3s 94ms/step - loss: 0.0164 - accuracy: 0.9962 - val_loss: 0.0352 - val_accuracy: 0.9923\n",
      "Epoch 53/75\n",
      "33/33 [==============================] - 3s 95ms/step - loss: 0.0261 - accuracy: 0.9933 - val_loss: 0.0495 - val_accuracy: 0.9923\n",
      "Epoch 54/75\n",
      "33/33 [==============================] - 3s 94ms/step - loss: 0.0242 - accuracy: 0.9933 - val_loss: 0.0376 - val_accuracy: 0.9923\n",
      "Epoch 55/75\n",
      "33/33 [==============================] - 3s 98ms/step - loss: 0.0253 - accuracy: 0.9962 - val_loss: 0.0414 - val_accuracy: 0.9923\n",
      "Epoch 56/75\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.0250 - accuracy: 0.9942 - val_loss: 0.0858 - val_accuracy: 0.9846\n",
      "Epoch 57/75\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.0223 - accuracy: 0.9971 - val_loss: 0.1034 - val_accuracy: 0.9846\n",
      "Epoch 58/75\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.0228 - accuracy: 0.9962 - val_loss: 0.1107 - val_accuracy: 0.9846\n",
      "Epoch 59/75\n",
      "33/33 [==============================] - 3s 97ms/step - loss: 0.0357 - accuracy: 0.9923 - val_loss: 0.0970 - val_accuracy: 0.9846\n",
      "Epoch 60/75\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.0199 - accuracy: 0.9952 - val_loss: 0.0690 - val_accuracy: 0.9923\n",
      "Epoch 61/75\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.0270 - accuracy: 0.9952 - val_loss: 0.1082 - val_accuracy: 0.9846\n",
      "Epoch 62/75\n",
      "33/33 [==============================] - 3s 92ms/step - loss: 0.0239 - accuracy: 0.9971 - val_loss: 0.1004 - val_accuracy: 0.9846\n",
      "Epoch 63/75\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.0338 - accuracy: 0.9933 - val_loss: 0.1315 - val_accuracy: 0.9769\n",
      "Epoch 64/75\n",
      "10/33 [========>.....................] - ETA: 2s - loss: 0.0449 - accuracy: 0.9969"
     ]
    }
   ],
   "source": [
    "kf =KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cnt = 1\n",
    "# split()  method generate indices to split data into training and test set.\n",
    "for train_index, test_index in kf.split(cells, labels):\n",
    "    print(f'Fold:{cnt}, Train set: {len(train_index)}, Test set:{len(test_index)}')\n",
    "    print(\"=\"*20)\n",
    "    print(\"Fold: \", cnt)\n",
    "    print(\"=\"*20)\n",
    "    cnt +=1\n",
    "    x_train , x , y_train , y = train_test_split(cells[train_index] , labels[train_index] , \n",
    "                                                test_size = 0.2 ,\n",
    "                                                random_state = 11)\n",
    "\n",
    "    x_eval ,x_test ,y_eval , y_test = train_test_split(x , y , \n",
    "                                                        test_size = 0.5 , \n",
    "                                                        random_state = 11)\n",
    "\n",
    "    y_train = to_categorical(y_train, num_classes = 3)\n",
    "    y_eval = to_categorical(y_eval, num_classes = 3)\n",
    "    y_test = to_categorical(y_test, num_classes = 3)\n",
    "\n",
    "    #instantiate the model\n",
    "    height = 50\n",
    "    width = 50\n",
    "    classes = 3\n",
    "    channels = 3\n",
    "    epoch = 75\n",
    "    model = CNNbuild(height = height, width = width, classes = classes, channels = channels)\n",
    "    model.summary()\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])\n",
    "\n",
    "    #fit the model onto the dataset\n",
    "    # x_train = np.array (x_train)\n",
    "\n",
    "    h = model.fit(x_train, y_train, epochs = epoch, batch_size = 32,validation_data=(x_eval,y_eval),shuffle=True)\n",
    "    namamodel = 'hog_model' + str(cnt) + '.pkl'\n",
    "    pickle.dump(model, open(namamodel, 'wb'))\n",
    "    pickled_model = pickle.load(open('hog_model2.pkl', 'rb'))\n",
    "\n",
    "    #evaluate the model on test data\n",
    "    predictions = model.evaluate(x_test, y_test)\n",
    "    evaluation = model.evaluate(x_eval, y_eval)\n",
    "\n",
    "    print(f'LOSS : {evaluation[0]}')\n",
    "    print(f'ACCURACY : {evaluation[1]}')\n",
    "    print(f'LOSS : {predictions[0]}')\n",
    "    print(f'ACCURACY : {predictions[1]}')\n",
    "\n",
    "    predict_x=model.predict(x_test) \n",
    "    yhat_classes=np.argmax(predict_x,axis=1)\n",
    "    yhat_classes = to_categorical(yhat_classes, num_classes = 3)\n",
    "#     print(\"Prediksi:\", yhat_classes)\n",
    "\n",
    "    # print(\"Precision Score : \",precision_score(y_test, y_pred, \n",
    "    #                                            pos_label='positive'\n",
    "    #                                            average='micro'))\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = accuracy_score(y_test, yhat_classes)\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "    totalaccuracy.append(accuracy)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(y_test, yhat_classes, average='macro')\n",
    "    print('Precision: %f' % precision)\n",
    "    totalprecision.append(precision)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(y_test, yhat_classes, average='macro')\n",
    "    print('Recall: %f' % recall)\n",
    "    totalrecall.append(recall)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(y_test, yhat_classes, average='macro')\n",
    "    print('F1 score: %f' % f1)\n",
    "    totalf1.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7722bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 20)\n",
    "print(\"rata-rata Akurasi: \",sum(totalaccuracy)/len(totalaccuracy))\n",
    "print(\"rata-rata Presisi: \",sum(totalprecision)/len(totalprecision))\n",
    "print(\"rata-rata Recall: \",sum(totalrecall)/len(totalrecall))\n",
    "print(\"rata-rata F1: \",sum(totalf1)/len(totalf1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4d22c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (18,8))\n",
    "plt.plot(range(epoch), h.history['loss'], label = 'Taining Loss')\n",
    "plt.plot(range(epoch), h.history['val_loss'], label = 'Validation Loss')\n",
    "plt.xlabel(\"Number of Epoch's\")\n",
    "plt.ylabel('Loss Value')\n",
    "plt.title('Training Training & Validation Loss')\n",
    "plt.legend(loc = \"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee81a54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (18,8))\n",
    "plt.plot(range(epoch), h.history['accuracy'], label = 'Taining Accuracy')\n",
    "plt.plot(range(epoch), h.history['val_accuracy'], label = 'Validation Accuracy')\n",
    "plt.xlabel(\"Number of Epoch's\")\n",
    "plt.ylabel('Accuracy Value')\n",
    "plt.title('Training Training & Validation Loss')\n",
    "plt.legend(loc = \"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe330b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd25224-eb39-4875-a2ec-3842b8b4f2ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
