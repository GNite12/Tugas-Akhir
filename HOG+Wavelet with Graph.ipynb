{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b7668d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from keras.utils import to_categorical\n",
    "import pywt\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d1d4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "penghuni = os.listdir(\"C:\\\\Users\\\\muham\\\\OneDrive\\\\Documents\\\\TA\\\\images\\\\train\\\\Penghuni\")\n",
    "temen1 = os.listdir(\"C:\\\\Users\\\\muham\\\\OneDrive\\\\Documents\\\\TA\\\\images\\\\train\\\\Temen1\")\n",
    "bkn_penghuni = os.listdir(\"C:\\\\Users\\\\muham\\\\OneDrive\\\\Documents\\\\TA\\\\images\\\\train\\\\BukanPenghuni\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77d69f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "totalaccuracy = []\n",
    "totalprecision = []\n",
    "totalrecall = []\n",
    "totalf1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03b5bfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNNbuild(height, width, classes, channels):\n",
    "    model = Sequential()\n",
    "    \n",
    "    inputShape = (height, width, channels,)\n",
    "    chanDim = -1\n",
    "    \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        inputShape = (channels, height, width)\n",
    "    model.add(Conv2D(32, (3,3), activation = 'relu', input_shape = inputShape))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(512, activation = 'relu'))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(classes, activation = 'softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a02a10e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalcFeatures(img, th):\n",
    "    sift = cv2.xfeatures2d.SIFT_create(th)\n",
    "    kp, des = sift.detectAndCompute(img, None)\n",
    "    return des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cfa7112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_features(features, centres, k = 500):\n",
    "    vec = np.zeros((1, k))\n",
    "    for i in range(features.shape[0]):\n",
    "        feat = features[i]\n",
    "        diff = np.tile(feat, (k, 1)) - centres\n",
    "        dist = pow(((pow(diff, 2)).sum(axis = 1)), 0.5)\n",
    "        idx_dist = dist.argsort()\n",
    "        idx = idx_dist[0]\n",
    "        vec[0][idx] += 1\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a80480b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 23)\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "labels = []\n",
    "features = []\n",
    "matrix_zero = np.zeros((81,23))\n",
    "print(matrix_zero.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b425dc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in penghuni:\n",
    "\n",
    "    image = cv2.imread(\"C:\\\\Users\\\\muham\\\\OneDrive\\\\Documents\\\\TA\\\\images\\\\train\\\\penghuni\\\\\"+i, 0)\n",
    "    \n",
    "    dim = (50, 50)\n",
    "    # image_array = Image.fromarray(image , 'RGB')\n",
    "    resize_img = cv2.resize(image, dim)\n",
    "    # resize_img = image_array.resize((50 , 50))\n",
    "\n",
    "    # Canny Edge Detection\n",
    "    edges = cv2.Canny(image=resize_img, threshold1=100, threshold2=200) # Canny Edge Detection\n",
    "    # resize_img = image_array.resize((50 , 50))\n",
    "    \n",
    "    resize_img = np.float32(resize_img) / 255.0\n",
    "    \n",
    "    # Calculate gradient \n",
    "    gx = cv2.Sobel(resize_img, cv2.CV_32F, 1, 0, ksize=1)\n",
    "    gy = cv2.Sobel(resize_img, cv2.CV_32F, 0, 1, ksize=1)\n",
    "    mag, angle = cv2.cartToPolar(gx, gy, angleInDegrees=True)\n",
    "\n",
    "    coeffs2 = pywt.dwt2(resize_img, 'bior1.3')\n",
    "    LL, (LH, HL, HH) = coeffs2\n",
    "    \n",
    "    # print(len(edges))\n",
    "\n",
    "    # a = np.array(edges)\n",
    "    b = np.array(mag)\n",
    "    # ab = np.concatenate((a, b), axis=0)\n",
    "    c = np.array(angle)\n",
    "    bc = np.concatenate((b, c), axis=0)\n",
    "    d = np.array(gx)\n",
    "    bcd = np.concatenate((bc, d), axis=0)\n",
    "    e = np.array(gy)\n",
    "    bcde = np.concatenate((bcd, e), axis=0)\n",
    "    v = np.array(LL)\n",
    "    w = np.array(LH)\n",
    "    vw = np.concatenate((v, w), axis=0)\n",
    "    x = np.array(HL)\n",
    "    vwx = np.concatenate((vw, x), axis=0)\n",
    "    z = np.array(HH)\n",
    "    vwxz = np.concatenate((vwx, z), axis=0)\n",
    "    vwxz_zero = np.concatenate((vwx, matrix_zero), axis=1)\n",
    "    # print(vwxz_zero.shape)\n",
    "    # print(len(abcde))\n",
    "    # data.append(np.array(edges))\n",
    "    all_feature = np.concatenate((bcde, vwxz_zero), axis=0)\n",
    "    # print(all_feature.shape)\n",
    "    data.append(np.array(all_feature))\n",
    "    labels.append(0)\n",
    "    # labels.append(0)\n",
    "\n",
    "#     print(len(descriptors))\n",
    "\n",
    "for u in bkn_penghuni:\n",
    "    \n",
    "    image = cv2.imread(\"C:\\\\Users\\\\muham\\\\OneDrive\\\\Documents\\\\TA\\\\images\\\\train\\\\BukanPenghuni\\\\\"+u, 0)\n",
    "    \n",
    "\n",
    "    dim = (50, 50)\n",
    "    # image_array = Image.fromarray(image , 'RGB')\n",
    "    resize_img = cv2.resize(image, dim)\n",
    "    # resize_img = image_array.resize((50 , 50))\n",
    "\n",
    "    # Canny Edge Detection\n",
    "    edges = cv2.Canny(image=resize_img, threshold1=100, threshold2=200) # Canny Edge Detection\n",
    "    # resize_img = image_array.resize((50 , 50))\n",
    "    \n",
    "    resize_img = np.float32(resize_img) / 255.0\n",
    "    \n",
    "    # Calculate gradient \n",
    "    gx = cv2.Sobel(resize_img, cv2.CV_32F, 1, 0, ksize=1)\n",
    "    gy = cv2.Sobel(resize_img, cv2.CV_32F, 0, 1, ksize=1)\n",
    "    mag, angle = cv2.cartToPolar(gx, gy, angleInDegrees=True)\n",
    "\n",
    "    coeffs2 = pywt.dwt2(resize_img, 'bior1.3')\n",
    "    LL, (LH, HL, HH) = coeffs2\n",
    "    # print(len(edges))\n",
    "    \n",
    "\n",
    "    # a = np.array(edges)\n",
    "    b = np.array(mag)\n",
    "    # ab = np.concatenate((a, b), axis=0)\n",
    "    c = np.array(angle)\n",
    "    bc = np.concatenate((b, c), axis=0)\n",
    "    d = np.array(gx)\n",
    "    bcd = np.concatenate((bc, d), axis=0)\n",
    "    e = np.array(gy)\n",
    "    bcde = np.concatenate((bcd, e), axis=0)\n",
    "    v = np.array(LL)\n",
    "    w = np.array(LH)\n",
    "    vw = np.concatenate((v, w), axis=0)\n",
    "    x = np.array(HL)\n",
    "    vwx = np.concatenate((vw, x), axis=0)\n",
    "    z = np.array(HH)\n",
    "    vwxz = np.concatenate((vwx, z), axis=0)\n",
    "    vwxz_zero = np.concatenate((vwx, matrix_zero), axis=1)\n",
    "    # print(vwxz_zero.shape)\n",
    "    # print(len(abcde))\n",
    "    # data.append(np.array(edges))\n",
    "    all_feature = np.concatenate((bcde, vwxz_zero), axis=0)\n",
    "    # print(all_feature.shape)\n",
    "    data.append(np.array(all_feature))\n",
    "    labels.append(1)\n",
    "    # labels.append(1)\n",
    "\n",
    "for j in temen1:\n",
    "    \n",
    "    image = cv2.imread(\"C:\\\\Users\\\\muham\\\\OneDrive\\\\Documents\\\\TA\\\\images\\\\train\\\\Temen1\\\\\"+j, 0)\n",
    "    \n",
    "\n",
    "    dim = (50, 50)\n",
    "    # image_array = Image.fromarray(image , 'RGB')\n",
    "    resize_img = cv2.resize(image, dim)\n",
    "    # resize_img = image_array.resize((50 , 50))\n",
    "\n",
    "    # Canny Edge Detection\n",
    "    edges = cv2.Canny(image=resize_img, threshold1=100, threshold2=200) # Canny Edge Detection\n",
    "    # resize_img = image_array.resize((50 , 50))\n",
    "    \n",
    "    resize_img = np.float32(resize_img) / 255.0\n",
    "    \n",
    "    # Calculate gradient \n",
    "    gx = cv2.Sobel(resize_img, cv2.CV_32F, 1, 0, ksize=1)\n",
    "    gy = cv2.Sobel(resize_img, cv2.CV_32F, 0, 1, ksize=1)\n",
    "    mag, angle = cv2.cartToPolar(gx, gy, angleInDegrees=True)\n",
    "\n",
    "    coeffs2 = pywt.dwt2(resize_img, 'bior1.3')\n",
    "    LL, (LH, HL, HH) = coeffs2\n",
    "    # print(len(edges))\n",
    "\n",
    "    # a = np.array(edges)\n",
    "    b = np.array(mag)\n",
    "    # ab = np.concatenate((a, b), axis=0)\n",
    "    c = np.array(angle)\n",
    "    bc = np.concatenate((b, c), axis=0)\n",
    "    d = np.array(gx)\n",
    "    bcd = np.concatenate((bc, d), axis=0)\n",
    "    e = np.array(gy)\n",
    "    bcde = np.concatenate((bcd, e), axis=0)\n",
    "    v = np.array(LL)\n",
    "    w = np.array(LH)\n",
    "    vw = np.concatenate((v, w), axis=0)\n",
    "    x = np.array(HL)\n",
    "    vwx = np.concatenate((vw, x), axis=0)\n",
    "    z = np.array(HH)\n",
    "    vwxz = np.concatenate((vwx, z), axis=0)\n",
    "    vwxz_zero = np.concatenate((vwx, matrix_zero), axis=1)\n",
    "    # print(vwxz_zero.shape)\n",
    "    # print(len(abcde))\n",
    "    # data.append(np.array(edges))\n",
    "    all_feature = np.concatenate((bcde, vwxz_zero), axis=0)\n",
    "    # print(all_feature.shape)\n",
    "    data.append(np.array(all_feature))\n",
    "    labels.append(2)\n",
    "    # labels.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b20a73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(461, 281, 50)\n"
     ]
    }
   ],
   "source": [
    "cells = np.array(data, dtype=object)\n",
    "labels = np.array(labels)\n",
    "\n",
    "np.save('Cells' , cells)\n",
    "np.save('Labels' , labels)\n",
    "\n",
    "n = np.arange(cells.shape[0])\n",
    "np.random.shuffle(n)\n",
    "cells = cells[n]\n",
    "labels = labels[n]\n",
    "\n",
    "cells = cells.astype(np.float32)\n",
    "# cells = np.reshape(cells, (461,15416,1,1))\n",
    "labels = labels.astype(np.int32)\n",
    "cells = cells/255\n",
    "print(cells.shape)\n",
    "# cells = np.reshape(cells, (250, 50, 50, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9e3dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:1, Train set: 368, Test set:93\n",
      "====================\n",
      "Fold:  1\n",
      "====================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 279, 48, 32)       320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 139, 24, 32)       0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 139, 24, 32)       128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 139, 24, 32)       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 137, 22, 32)       9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 68, 11, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 68, 11, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 68, 11, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 66, 9, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 33, 4, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 33, 4, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 33, 4, 32)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4224)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2163200   \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2185987 (8.34 MB)\n",
      "Trainable params: 2184771 (8.33 MB)\n",
      "Non-trainable params: 1216 (4.75 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - 10s 608ms/step - loss: 1.7680 - accuracy: 0.4150 - val_loss: 1.0480 - val_accuracy: 0.4054\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - 6s 549ms/step - loss: 1.2004 - accuracy: 0.5646 - val_loss: 1.0471 - val_accuracy: 0.4054\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - 6s 560ms/step - loss: 1.1910 - accuracy: 0.5884 - val_loss: 1.0189 - val_accuracy: 0.4054\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - 6s 556ms/step - loss: 1.0194 - accuracy: 0.6395 - val_loss: 0.9958 - val_accuracy: 0.4054\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - 6s 552ms/step - loss: 1.0807 - accuracy: 0.6361 - val_loss: 1.1570 - val_accuracy: 0.4054\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - 6s 557ms/step - loss: 0.8541 - accuracy: 0.6633 - val_loss: 1.3554 - val_accuracy: 0.4054\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - 6s 555ms/step - loss: 0.7499 - accuracy: 0.7211 - val_loss: 1.6919 - val_accuracy: 0.4054\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - 6s 557ms/step - loss: 0.8607 - accuracy: 0.6769 - val_loss: 1.7744 - val_accuracy: 0.4054\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - 6s 556ms/step - loss: 0.7127 - accuracy: 0.7177 - val_loss: 1.8444 - val_accuracy: 0.4054\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - 6s 559ms/step - loss: 0.7549 - accuracy: 0.7143 - val_loss: 2.0560 - val_accuracy: 0.4054\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - 6s 560ms/step - loss: 0.6809 - accuracy: 0.7245 - val_loss: 2.3298 - val_accuracy: 0.4054\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - 6s 549ms/step - loss: 0.5800 - accuracy: 0.7721 - val_loss: 2.3132 - val_accuracy: 0.4054\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - 6s 557ms/step - loss: 0.6370 - accuracy: 0.7653 - val_loss: 2.5645 - val_accuracy: 0.4054\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - 6s 556ms/step - loss: 0.5832 - accuracy: 0.7551 - val_loss: 2.6472 - val_accuracy: 0.4054\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - 6s 567ms/step - loss: 0.6281 - accuracy: 0.7551 - val_loss: 2.2359 - val_accuracy: 0.4054\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - 6s 556ms/step - loss: 0.4994 - accuracy: 0.8027 - val_loss: 2.1831 - val_accuracy: 0.4054\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - 6s 570ms/step - loss: 0.6537 - accuracy: 0.7449 - val_loss: 1.9846 - val_accuracy: 0.4054\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - 6s 558ms/step - loss: 0.4521 - accuracy: 0.8095 - val_loss: 2.1939 - val_accuracy: 0.4054\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - 6s 557ms/step - loss: 0.6343 - accuracy: 0.7347 - val_loss: 2.4938 - val_accuracy: 0.4054\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - 6s 550ms/step - loss: 0.4590 - accuracy: 0.7823 - val_loss: 2.7493 - val_accuracy: 0.4054\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - 6s 568ms/step - loss: 0.4660 - accuracy: 0.7891 - val_loss: 2.6274 - val_accuracy: 0.4054\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - 6s 587ms/step - loss: 0.4758 - accuracy: 0.7857 - val_loss: 2.1245 - val_accuracy: 0.4054\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - 6s 564ms/step - loss: 0.5250 - accuracy: 0.7721 - val_loss: 1.7645 - val_accuracy: 0.4054\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - 6s 565ms/step - loss: 0.3670 - accuracy: 0.8231 - val_loss: 1.6637 - val_accuracy: 0.4054\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - 6s 553ms/step - loss: 0.4040 - accuracy: 0.8197 - val_loss: 1.6178 - val_accuracy: 0.4054\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - 6s 590ms/step - loss: 0.3729 - accuracy: 0.8231 - val_loss: 1.6093 - val_accuracy: 0.4054\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - 6s 561ms/step - loss: 0.3198 - accuracy: 0.8571 - val_loss: 1.5444 - val_accuracy: 0.4054\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - 6s 554ms/step - loss: 0.3690 - accuracy: 0.8435 - val_loss: 1.5224 - val_accuracy: 0.4054\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - 6s 557ms/step - loss: 0.4049 - accuracy: 0.8163 - val_loss: 1.5469 - val_accuracy: 0.4054\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - 6s 556ms/step - loss: 0.3117 - accuracy: 0.8639 - val_loss: 1.3692 - val_accuracy: 0.4054\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - 6s 560ms/step - loss: 0.3752 - accuracy: 0.8299 - val_loss: 1.5601 - val_accuracy: 0.4054\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - 6s 555ms/step - loss: 0.3342 - accuracy: 0.8435 - val_loss: 1.7435 - val_accuracy: 0.4054\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - 6s 564ms/step - loss: 0.3494 - accuracy: 0.8265 - val_loss: 1.5544 - val_accuracy: 0.4054\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - 6s 555ms/step - loss: 0.3238 - accuracy: 0.8503 - val_loss: 1.4715 - val_accuracy: 0.4054\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - 6s 563ms/step - loss: 0.3268 - accuracy: 0.8367 - val_loss: 1.4552 - val_accuracy: 0.4054\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - 6s 549ms/step - loss: 0.3659 - accuracy: 0.8401 - val_loss: 1.2184 - val_accuracy: 0.4324\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - 6s 563ms/step - loss: 0.2560 - accuracy: 0.8844 - val_loss: 0.9819 - val_accuracy: 0.5135\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - 6s 548ms/step - loss: 0.2991 - accuracy: 0.8469 - val_loss: 1.1552 - val_accuracy: 0.4865\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - 6s 557ms/step - loss: 0.3087 - accuracy: 0.8503 - val_loss: 1.3006 - val_accuracy: 0.4865\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - 6s 566ms/step - loss: 0.3222 - accuracy: 0.8537 - val_loss: 1.2860 - val_accuracy: 0.4595\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - 6s 566ms/step - loss: 0.3447 - accuracy: 0.8299 - val_loss: 1.3183 - val_accuracy: 0.4865\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - 6s 553ms/step - loss: 0.2862 - accuracy: 0.8844 - val_loss: 1.2596 - val_accuracy: 0.5135\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - 6s 554ms/step - loss: 0.3390 - accuracy: 0.8333 - val_loss: 1.5447 - val_accuracy: 0.3243\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - 6s 559ms/step - loss: 0.2724 - accuracy: 0.8707 - val_loss: 1.2157 - val_accuracy: 0.4865\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - 6s 553ms/step - loss: 0.2238 - accuracy: 0.8912 - val_loss: 1.6668 - val_accuracy: 0.4054\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - 6s 556ms/step - loss: 0.2713 - accuracy: 0.8503 - val_loss: 1.1334 - val_accuracy: 0.4324\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - 6s 554ms/step - loss: 0.2571 - accuracy: 0.8741 - val_loss: 0.6395 - val_accuracy: 0.6757\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - 6s 560ms/step - loss: 0.3667 - accuracy: 0.8435 - val_loss: 0.6942 - val_accuracy: 0.5946\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - 6s 554ms/step - loss: 0.3055 - accuracy: 0.8673 - val_loss: 0.5479 - val_accuracy: 0.7297\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - 6s 563ms/step - loss: 0.2267 - accuracy: 0.9014 - val_loss: 0.6130 - val_accuracy: 0.7027\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - 6s 560ms/step - loss: 0.2558 - accuracy: 0.8707 - val_loss: 0.6747 - val_accuracy: 0.6486\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - 5s 548ms/step - loss: 0.2639 - accuracy: 0.8912 - val_loss: 0.5899 - val_accuracy: 0.7297\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - 6s 563ms/step - loss: 0.2673 - accuracy: 0.8707 - val_loss: 0.5520 - val_accuracy: 0.7297\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - 6s 561ms/step - loss: 0.2369 - accuracy: 0.8878 - val_loss: 0.5807 - val_accuracy: 0.7297\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - 6s 550ms/step - loss: 0.2860 - accuracy: 0.8537 - val_loss: 0.5510 - val_accuracy: 0.7838\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - 6s 565ms/step - loss: 0.2447 - accuracy: 0.8741 - val_loss: 0.6206 - val_accuracy: 0.7297\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - 6s 554ms/step - loss: 0.2957 - accuracy: 0.8639 - val_loss: 0.5835 - val_accuracy: 0.7027\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - 6s 559ms/step - loss: 0.2448 - accuracy: 0.8776 - val_loss: 0.5143 - val_accuracy: 0.7297\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - 6s 554ms/step - loss: 0.2679 - accuracy: 0.8571 - val_loss: 0.3974 - val_accuracy: 0.8108\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - 6s 554ms/step - loss: 0.3063 - accuracy: 0.8673 - val_loss: 0.4233 - val_accuracy: 0.8108\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - 6s 560ms/step - loss: 0.2300 - accuracy: 0.8776 - val_loss: 0.3902 - val_accuracy: 0.8649\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - 6s 559ms/step - loss: 0.3125 - accuracy: 0.8503 - val_loss: 0.3926 - val_accuracy: 0.8378\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - 6s 550ms/step - loss: 0.2495 - accuracy: 0.8707 - val_loss: 0.3618 - val_accuracy: 0.8378\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - 6s 552ms/step - loss: 0.2532 - accuracy: 0.8741 - val_loss: 0.6369 - val_accuracy: 0.6486\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - 6s 549ms/step - loss: 0.2243 - accuracy: 0.8810 - val_loss: 0.4278 - val_accuracy: 0.8108\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - 6s 555ms/step - loss: 0.2172 - accuracy: 0.8810 - val_loss: 0.3676 - val_accuracy: 0.8378\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - 6s 561ms/step - loss: 0.2085 - accuracy: 0.9014 - val_loss: 0.3767 - val_accuracy: 0.8378\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - 6s 558ms/step - loss: 0.2205 - accuracy: 0.9048 - val_loss: 0.3751 - val_accuracy: 0.8378\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - 6s 552ms/step - loss: 0.2459 - accuracy: 0.8946 - val_loss: 0.3805 - val_accuracy: 0.8378\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - 6s 561ms/step - loss: 0.2321 - accuracy: 0.8946 - val_loss: 0.3918 - val_accuracy: 0.8378\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - 6s 549ms/step - loss: 0.2468 - accuracy: 0.8946 - val_loss: 0.3691 - val_accuracy: 0.8378\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - 6s 554ms/step - loss: 0.2507 - accuracy: 0.8741 - val_loss: 0.4257 - val_accuracy: 0.8378\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - 6s 554ms/step - loss: 0.2176 - accuracy: 0.8776 - val_loss: 0.4088 - val_accuracy: 0.8919\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - 6s 556ms/step - loss: 0.1982 - accuracy: 0.9048 - val_loss: 0.3220 - val_accuracy: 0.8919\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - 6s 561ms/step - loss: 0.2189 - accuracy: 0.8878 - val_loss: 0.3880 - val_accuracy: 0.8108\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - 6s 569ms/step - loss: 0.2542 - accuracy: 0.8980 - val_loss: 0.3510 - val_accuracy: 0.8108\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - 6s 563ms/step - loss: 0.2482 - accuracy: 0.9014 - val_loss: 0.4076 - val_accuracy: 0.8378\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - 6s 558ms/step - loss: 0.2354 - accuracy: 0.8844 - val_loss: 0.4481 - val_accuracy: 0.8108\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - 6s 556ms/step - loss: 0.2304 - accuracy: 0.8912 - val_loss: 0.4288 - val_accuracy: 0.8108\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - 6s 554ms/step - loss: 0.2629 - accuracy: 0.8810 - val_loss: 0.4094 - val_accuracy: 0.7297\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - 6s 555ms/step - loss: 0.2222 - accuracy: 0.8946 - val_loss: 0.5961 - val_accuracy: 0.7568\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - 6s 558ms/step - loss: 0.2371 - accuracy: 0.8878 - val_loss: 0.4852 - val_accuracy: 0.7297\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - 5s 544ms/step - loss: 0.2199 - accuracy: 0.9150 - val_loss: 0.4644 - val_accuracy: 0.7297\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - 6s 549ms/step - loss: 0.2324 - accuracy: 0.8707 - val_loss: 0.5218 - val_accuracy: 0.7568\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - 6s 554ms/step - loss: 0.1981 - accuracy: 0.9184 - val_loss: 0.6434 - val_accuracy: 0.7297\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - 6s 555ms/step - loss: 0.2297 - accuracy: 0.8878 - val_loss: 0.5473 - val_accuracy: 0.7838\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - 6s 559ms/step - loss: 0.2760 - accuracy: 0.8605 - val_loss: 0.4301 - val_accuracy: 0.8108\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - 6s 557ms/step - loss: 0.2398 - accuracy: 0.8844 - val_loss: 0.4996 - val_accuracy: 0.7838\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - 6s 560ms/step - loss: 0.2415 - accuracy: 0.8537 - val_loss: 0.4869 - val_accuracy: 0.7838\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - 5s 547ms/step - loss: 0.2535 - accuracy: 0.8776 - val_loss: 0.5378 - val_accuracy: 0.8378\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - 6s 561ms/step - loss: 0.2407 - accuracy: 0.8878 - val_loss: 0.4590 - val_accuracy: 0.8378\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - 6s 560ms/step - loss: 0.2279 - accuracy: 0.8946 - val_loss: 0.3984 - val_accuracy: 0.8108\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - 6s 560ms/step - loss: 0.2090 - accuracy: 0.9082 - val_loss: 0.3730 - val_accuracy: 0.8108\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - 6s 552ms/step - loss: 0.2131 - accuracy: 0.9014 - val_loss: 0.3526 - val_accuracy: 0.8108\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - 5s 548ms/step - loss: 0.1976 - accuracy: 0.8980 - val_loss: 0.2934 - val_accuracy: 0.8378\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - 6s 560ms/step - loss: 0.1763 - accuracy: 0.9150 - val_loss: 0.3435 - val_accuracy: 0.8378\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - 6s 561ms/step - loss: 0.2100 - accuracy: 0.9014 - val_loss: 0.3437 - val_accuracy: 0.8378\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - 6s 561ms/step - loss: 0.2679 - accuracy: 0.8776 - val_loss: 0.3103 - val_accuracy: 0.8108\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - 6s 558ms/step - loss: 0.1895 - accuracy: 0.8980 - val_loss: 0.3332 - val_accuracy: 0.8649\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - 6s 549ms/step - loss: 0.2107 - accuracy: 0.9048 - val_loss: 0.3114 - val_accuracy: 0.8649\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - 5s 552ms/step - loss: 0.2085 - accuracy: 0.8810 - val_loss: 0.3684 - val_accuracy: 0.8108\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - 6s 577ms/step - loss: 0.2249 - accuracy: 0.8810 - val_loss: 0.3826 - val_accuracy: 0.8108\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - 5s 538ms/step - loss: 0.1918 - accuracy: 0.9116 - val_loss: 0.3115 - val_accuracy: 0.8649\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - 5s 547ms/step - loss: 0.2577 - accuracy: 0.8810 - val_loss: 0.3133 - val_accuracy: 0.8919\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - 6s 603ms/step - loss: 0.1902 - accuracy: 0.9082 - val_loss: 0.2798 - val_accuracy: 0.8919\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - 6s 576ms/step - loss: 0.1782 - accuracy: 0.9014 - val_loss: 0.3588 - val_accuracy: 0.8108\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - 6s 585ms/step - loss: 0.2383 - accuracy: 0.8844 - val_loss: 0.3876 - val_accuracy: 0.7838\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - 6s 560ms/step - loss: 0.2191 - accuracy: 0.8878 - val_loss: 0.4143 - val_accuracy: 0.7838\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - 6s 574ms/step - loss: 0.1814 - accuracy: 0.9048 - val_loss: 0.4385 - val_accuracy: 0.7838\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - 6s 588ms/step - loss: 0.2041 - accuracy: 0.8810 - val_loss: 0.4701 - val_accuracy: 0.7297\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - 6s 571ms/step - loss: 0.2230 - accuracy: 0.8946 - val_loss: 0.4722 - val_accuracy: 0.8108\n",
      "Epoch 112/150\n",
      "10/10 [==============================] - 6s 574ms/step - loss: 0.1883 - accuracy: 0.8878 - val_loss: 0.4628 - val_accuracy: 0.7838\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - 6s 586ms/step - loss: 0.2080 - accuracy: 0.8980 - val_loss: 0.4464 - val_accuracy: 0.8108\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - 6s 555ms/step - loss: 0.2020 - accuracy: 0.9014 - val_loss: 0.2317 - val_accuracy: 0.9730\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - 6s 556ms/step - loss: 0.1807 - accuracy: 0.9286 - val_loss: 0.3546 - val_accuracy: 0.8108\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - 5s 535ms/step - loss: 0.2104 - accuracy: 0.8946 - val_loss: 0.4242 - val_accuracy: 0.8378\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - 6s 551ms/step - loss: 0.1800 - accuracy: 0.9116 - val_loss: 0.3574 - val_accuracy: 0.8649\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - 6s 563ms/step - loss: 0.2206 - accuracy: 0.9048 - val_loss: 0.3174 - val_accuracy: 0.8378\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - 6s 567ms/step - loss: 0.2317 - accuracy: 0.8776 - val_loss: 0.4072 - val_accuracy: 0.7838\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - 5s 462ms/step - loss: 0.2000 - accuracy: 0.8980 - val_loss: 0.3830 - val_accuracy: 0.8108\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - 4s 423ms/step - loss: 0.1739 - accuracy: 0.9184 - val_loss: 0.4040 - val_accuracy: 0.8378\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - 4s 446ms/step - loss: 0.2375 - accuracy: 0.8776 - val_loss: 0.4452 - val_accuracy: 0.8108\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - 6s 621ms/step - loss: 0.1935 - accuracy: 0.9048 - val_loss: 0.5153 - val_accuracy: 0.8108\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - 5s 535ms/step - loss: 0.2259 - accuracy: 0.8878 - val_loss: 0.5242 - val_accuracy: 0.8108\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - 5s 489ms/step - loss: 0.2059 - accuracy: 0.9048 - val_loss: 0.5434 - val_accuracy: 0.8378\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - 5s 475ms/step - loss: 0.2102 - accuracy: 0.9014 - val_loss: 0.5707 - val_accuracy: 0.8108\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - 5s 467ms/step - loss: 0.2170 - accuracy: 0.9082 - val_loss: 0.5369 - val_accuracy: 0.8108\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - 5s 464ms/step - loss: 0.1925 - accuracy: 0.8980 - val_loss: 0.5096 - val_accuracy: 0.8108\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - 5s 481ms/step - loss: 0.1547 - accuracy: 0.9184 - val_loss: 0.5061 - val_accuracy: 0.8108\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - 4s 407ms/step - loss: 0.2132 - accuracy: 0.9014 - val_loss: 0.5673 - val_accuracy: 0.7838\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - 4s 368ms/step - loss: 0.2397 - accuracy: 0.8810 - val_loss: 0.7705 - val_accuracy: 0.7568\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - 4s 356ms/step - loss: 0.1899 - accuracy: 0.9150 - val_loss: 0.6470 - val_accuracy: 0.7838\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.2073 - accuracy: 0.9014 - val_loss: 0.4226 - val_accuracy: 0.7838\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - 5s 519ms/step - loss: 0.1813 - accuracy: 0.8980 - val_loss: 0.3711 - val_accuracy: 0.8108\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - 5s 507ms/step - loss: 0.2243 - accuracy: 0.8776 - val_loss: 0.4790 - val_accuracy: 0.8108\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - 4s 395ms/step - loss: 0.1598 - accuracy: 0.9422 - val_loss: 0.3733 - val_accuracy: 0.8108\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - 5s 466ms/step - loss: 0.2040 - accuracy: 0.9048 - val_loss: 0.3534 - val_accuracy: 0.8378\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - 5s 449ms/step - loss: 0.2007 - accuracy: 0.8946 - val_loss: 0.3453 - val_accuracy: 0.8378\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - 5s 440ms/step - loss: 0.1903 - accuracy: 0.9116 - val_loss: 0.3994 - val_accuracy: 0.8378\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - 4s 446ms/step - loss: 0.1806 - accuracy: 0.9048 - val_loss: 0.3545 - val_accuracy: 0.8378\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - 4s 451ms/step - loss: 0.1847 - accuracy: 0.9150 - val_loss: 0.3762 - val_accuracy: 0.8108\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - 4s 422ms/step - loss: 0.2165 - accuracy: 0.8946 - val_loss: 0.4164 - val_accuracy: 0.7838\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - 4s 434ms/step - loss: 0.2046 - accuracy: 0.8912 - val_loss: 0.4524 - val_accuracy: 0.7838\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - 4s 377ms/step - loss: 0.1890 - accuracy: 0.8980 - val_loss: 0.3579 - val_accuracy: 0.8649\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - 4s 381ms/step - loss: 0.1785 - accuracy: 0.8946 - val_loss: 0.4016 - val_accuracy: 0.8649\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.1923 - accuracy: 0.9014 - val_loss: 0.4397 - val_accuracy: 0.8378\n",
      "Epoch 147/150\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 0.2219 - accuracy: 0.8639 - val_loss: 0.3678 - val_accuracy: 0.8108\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - 4s 378ms/step - loss: 0.1826 - accuracy: 0.9116 - val_loss: 0.7949 - val_accuracy: 0.6216\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - 4s 384ms/step - loss: 0.2006 - accuracy: 0.8810 - val_loss: 1.0590 - val_accuracy: 0.7297\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - 4s 377ms/step - loss: 0.1706 - accuracy: 0.9184 - val_loss: 1.0501 - val_accuracy: 0.7568\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.8859 - accuracy: 0.7027\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0501 - accuracy: 0.7568\n",
      "LOSS : 1.050093412399292\n",
      "ACCURACY : 0.7567567825317383\n",
      "LOSS : 0.8858957290649414\n",
      "ACCURACY : 0.7027027010917664\n",
      "2/2 [==============================] - 0s 34ms/step\n",
      "Accuracy: 0.702703\n",
      "Precision: 0.608586\n",
      "Recall: 0.642857\n",
      "F1 score: 0.593902\n",
      "Fold:2, Train set: 369, Test set:92\n",
      "====================\n",
      "Fold:  2\n",
      "====================\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 279, 48, 32)       320       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 139, 24, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 139, 24, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 139, 24, 32)       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 137, 22, 32)       9248      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 68, 11, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 68, 11, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 68, 11, 32)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 66, 9, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 33, 4, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 33, 4, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 33, 4, 32)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 4224)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               2163200   \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2185987 (8.34 MB)\n",
      "Trainable params: 2184771 (8.33 MB)\n",
      "Non-trainable params: 1216 (4.75 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - 7s 428ms/step - loss: 1.6534 - accuracy: 0.4305 - val_loss: 1.1269 - val_accuracy: 0.1351\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - 4s 442ms/step - loss: 1.3677 - accuracy: 0.5322 - val_loss: 0.9894 - val_accuracy: 0.4595\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - 4s 389ms/step - loss: 1.1900 - accuracy: 0.5966 - val_loss: 0.9042 - val_accuracy: 0.4865\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 1.0343 - accuracy: 0.6305 - val_loss: 0.9186 - val_accuracy: 0.4865\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 1.0670 - accuracy: 0.6678 - val_loss: 0.9732 - val_accuracy: 0.7027\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - 4s 381ms/step - loss: 1.1440 - accuracy: 0.6610 - val_loss: 1.0007 - val_accuracy: 0.5946\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - 4s 379ms/step - loss: 1.1407 - accuracy: 0.6678 - val_loss: 0.9882 - val_accuracy: 0.5135\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - 4s 383ms/step - loss: 0.9037 - accuracy: 0.6814 - val_loss: 1.0013 - val_accuracy: 0.4324\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - 4s 382ms/step - loss: 0.9043 - accuracy: 0.6881 - val_loss: 1.0067 - val_accuracy: 0.4865\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - 4s 392ms/step - loss: 0.7411 - accuracy: 0.7390 - val_loss: 1.0059 - val_accuracy: 0.7568\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - 4s 407ms/step - loss: 0.7845 - accuracy: 0.6881 - val_loss: 1.1410 - val_accuracy: 0.4324\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - 4s 421ms/step - loss: 0.7203 - accuracy: 0.7356 - val_loss: 1.2113 - val_accuracy: 0.4324\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - 4s 405ms/step - loss: 0.6768 - accuracy: 0.7458 - val_loss: 1.3074 - val_accuracy: 0.4324\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - 4s 383ms/step - loss: 0.5901 - accuracy: 0.7763 - val_loss: 1.3498 - val_accuracy: 0.4324\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - 4s 394ms/step - loss: 0.6889 - accuracy: 0.7695 - val_loss: 1.3846 - val_accuracy: 0.4324\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - 4s 389ms/step - loss: 0.6031 - accuracy: 0.7458 - val_loss: 1.3933 - val_accuracy: 0.4324\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 0.4932 - accuracy: 0.8034 - val_loss: 1.2150 - val_accuracy: 0.4324\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.4373 - accuracy: 0.8068 - val_loss: 1.1233 - val_accuracy: 0.6486\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.4576 - accuracy: 0.7695 - val_loss: 1.1333 - val_accuracy: 0.5135\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.4545 - accuracy: 0.8203 - val_loss: 1.1494 - val_accuracy: 0.5135\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.5188 - accuracy: 0.7695 - val_loss: 1.1588 - val_accuracy: 0.4865\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.4573 - accuracy: 0.8068 - val_loss: 1.0885 - val_accuracy: 0.5135\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - 4s 382ms/step - loss: 0.5062 - accuracy: 0.7932 - val_loss: 0.9172 - val_accuracy: 0.6486\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.5939 - accuracy: 0.7831 - val_loss: 0.9431 - val_accuracy: 0.5405\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - 4s 376ms/step - loss: 0.4005 - accuracy: 0.8373 - val_loss: 1.0155 - val_accuracy: 0.5135\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.4117 - accuracy: 0.8305 - val_loss: 0.9098 - val_accuracy: 0.5405\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.3946 - accuracy: 0.8305 - val_loss: 1.7807 - val_accuracy: 0.4595\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - 4s 389ms/step - loss: 0.4182 - accuracy: 0.8203 - val_loss: 1.4094 - val_accuracy: 0.4595\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - 4s 378ms/step - loss: 0.3928 - accuracy: 0.8271 - val_loss: 1.3240 - val_accuracy: 0.4595\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.3489 - accuracy: 0.8712 - val_loss: 1.0856 - val_accuracy: 0.4595\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - 4s 394ms/step - loss: 0.4048 - accuracy: 0.8407 - val_loss: 0.9299 - val_accuracy: 0.6216\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - 4s 380ms/step - loss: 0.4579 - accuracy: 0.8102 - val_loss: 0.8586 - val_accuracy: 0.7027\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - 4s 377ms/step - loss: 0.3694 - accuracy: 0.8203 - val_loss: 0.8297 - val_accuracy: 0.7027\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.3217 - accuracy: 0.8542 - val_loss: 0.8181 - val_accuracy: 0.7568\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.3179 - accuracy: 0.8712 - val_loss: 0.8424 - val_accuracy: 0.7568\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - 4s 381ms/step - loss: 0.3682 - accuracy: 0.8203 - val_loss: 0.9196 - val_accuracy: 0.6757\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 0.3478 - accuracy: 0.8610 - val_loss: 0.9101 - val_accuracy: 0.7027\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - 4s 394ms/step - loss: 0.3312 - accuracy: 0.8610 - val_loss: 0.8636 - val_accuracy: 0.7027\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - 4s 380ms/step - loss: 0.2359 - accuracy: 0.9017 - val_loss: 0.8612 - val_accuracy: 0.6757\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 0.3009 - accuracy: 0.8678 - val_loss: 0.8370 - val_accuracy: 0.6757\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - 4s 391ms/step - loss: 0.2396 - accuracy: 0.8949 - val_loss: 0.8387 - val_accuracy: 0.7027\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.2982 - accuracy: 0.8610 - val_loss: 0.8264 - val_accuracy: 0.7297\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.3019 - accuracy: 0.8712 - val_loss: 0.8307 - val_accuracy: 0.6486\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.2606 - accuracy: 0.8712 - val_loss: 0.7494 - val_accuracy: 0.6216\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - 4s 384ms/step - loss: 0.2876 - accuracy: 0.8881 - val_loss: 0.7058 - val_accuracy: 0.7027\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.2825 - accuracy: 0.8814 - val_loss: 0.6937 - val_accuracy: 0.6757\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.2849 - accuracy: 0.8780 - val_loss: 1.0263 - val_accuracy: 0.5135\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - 4s 376ms/step - loss: 0.3568 - accuracy: 0.8475 - val_loss: 0.8621 - val_accuracy: 0.6216\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - 4s 389ms/step - loss: 0.2977 - accuracy: 0.8542 - val_loss: 0.7664 - val_accuracy: 0.6216\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - 4s 383ms/step - loss: 0.3511 - accuracy: 0.8508 - val_loss: 0.7685 - val_accuracy: 0.6757\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - 4s 379ms/step - loss: 0.2741 - accuracy: 0.8780 - val_loss: 0.7357 - val_accuracy: 0.6486\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - 4s 377ms/step - loss: 0.2927 - accuracy: 0.8644 - val_loss: 0.9163 - val_accuracy: 0.6486\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - 4s 383ms/step - loss: 0.2790 - accuracy: 0.8712 - val_loss: 0.9716 - val_accuracy: 0.6757\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.3110 - accuracy: 0.8441 - val_loss: 0.7901 - val_accuracy: 0.6486\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - 4s 381ms/step - loss: 0.2342 - accuracy: 0.9017 - val_loss: 0.7876 - val_accuracy: 0.6486\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 0.2949 - accuracy: 0.8576 - val_loss: 0.7123 - val_accuracy: 0.6216\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - 4s 392ms/step - loss: 0.2609 - accuracy: 0.8746 - val_loss: 0.7047 - val_accuracy: 0.6216\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - 4s 398ms/step - loss: 0.2342 - accuracy: 0.9051 - val_loss: 0.8948 - val_accuracy: 0.6486\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - 4s 383ms/step - loss: 0.2631 - accuracy: 0.8644 - val_loss: 1.0399 - val_accuracy: 0.6216\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.2643 - accuracy: 0.8542 - val_loss: 0.7985 - val_accuracy: 0.6216\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - 4s 382ms/step - loss: 0.2415 - accuracy: 0.8746 - val_loss: 0.7474 - val_accuracy: 0.7027\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.2659 - accuracy: 0.8915 - val_loss: 0.7913 - val_accuracy: 0.6757\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.2091 - accuracy: 0.8949 - val_loss: 0.8306 - val_accuracy: 0.6486\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - 4s 377ms/step - loss: 0.2999 - accuracy: 0.8644 - val_loss: 0.8165 - val_accuracy: 0.6216\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - 4s 406ms/step - loss: 0.2206 - accuracy: 0.8881 - val_loss: 0.7585 - val_accuracy: 0.6216\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - 4s 414ms/step - loss: 0.2181 - accuracy: 0.8983 - val_loss: 0.7216 - val_accuracy: 0.6486\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - 4s 410ms/step - loss: 0.1881 - accuracy: 0.9254 - val_loss: 0.7587 - val_accuracy: 0.6486\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.2677 - accuracy: 0.8712 - val_loss: 0.8414 - val_accuracy: 0.6757\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - 4s 383ms/step - loss: 0.1928 - accuracy: 0.9220 - val_loss: 1.0059 - val_accuracy: 0.6486\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - 4s 399ms/step - loss: 0.2556 - accuracy: 0.8881 - val_loss: 1.0069 - val_accuracy: 0.6486\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - 4s 415ms/step - loss: 0.2196 - accuracy: 0.8847 - val_loss: 1.1887 - val_accuracy: 0.6216\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - 4s 392ms/step - loss: 0.2672 - accuracy: 0.8780 - val_loss: 1.2266 - val_accuracy: 0.6486\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - 4s 380ms/step - loss: 0.2150 - accuracy: 0.8983 - val_loss: 1.0572 - val_accuracy: 0.6486\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - 4s 379ms/step - loss: 0.2382 - accuracy: 0.8983 - val_loss: 0.9671 - val_accuracy: 0.6486\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - 4s 392ms/step - loss: 0.2085 - accuracy: 0.8915 - val_loss: 0.9022 - val_accuracy: 0.6757\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - 4s 380ms/step - loss: 0.2230 - accuracy: 0.8881 - val_loss: 0.8105 - val_accuracy: 0.6486\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.2445 - accuracy: 0.8847 - val_loss: 0.7976 - val_accuracy: 0.6216\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 0.2107 - accuracy: 0.8915 - val_loss: 0.8082 - val_accuracy: 0.6216\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - 4s 395ms/step - loss: 0.2294 - accuracy: 0.8949 - val_loss: 1.8945 - val_accuracy: 0.3784\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - 4s 383ms/step - loss: 0.1862 - accuracy: 0.9017 - val_loss: 1.4658 - val_accuracy: 0.5135\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - 4s 395ms/step - loss: 0.2080 - accuracy: 0.9085 - val_loss: 1.2674 - val_accuracy: 0.6216\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.2127 - accuracy: 0.9051 - val_loss: 1.1478 - val_accuracy: 0.6486\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - 4s 382ms/step - loss: 0.1665 - accuracy: 0.9153 - val_loss: 0.9259 - val_accuracy: 0.6486\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.1959 - accuracy: 0.9051 - val_loss: 0.8596 - val_accuracy: 0.6216\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.2639 - accuracy: 0.8644 - val_loss: 0.8333 - val_accuracy: 0.6757\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.2015 - accuracy: 0.8881 - val_loss: 0.8436 - val_accuracy: 0.6486\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - 4s 381ms/step - loss: 0.1972 - accuracy: 0.9051 - val_loss: 0.9246 - val_accuracy: 0.6486\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - 4s 382ms/step - loss: 0.2113 - accuracy: 0.8915 - val_loss: 0.9100 - val_accuracy: 0.6486\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 0.1704 - accuracy: 0.9322 - val_loss: 0.8729 - val_accuracy: 0.6486\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - 4s 391ms/step - loss: 0.1820 - accuracy: 0.9017 - val_loss: 0.9709 - val_accuracy: 0.6757\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.2003 - accuracy: 0.8983 - val_loss: 0.9554 - val_accuracy: 0.6757\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.1849 - accuracy: 0.9017 - val_loss: 0.9634 - val_accuracy: 0.6486\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - 4s 396ms/step - loss: 0.1975 - accuracy: 0.9085 - val_loss: 0.8860 - val_accuracy: 0.6486\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.1872 - accuracy: 0.9017 - val_loss: 0.8580 - val_accuracy: 0.6486\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.1898 - accuracy: 0.9220 - val_loss: 0.8508 - val_accuracy: 0.6757\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - 4s 404ms/step - loss: 0.2034 - accuracy: 0.8949 - val_loss: 0.8960 - val_accuracy: 0.6757\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - 4s 396ms/step - loss: 0.2087 - accuracy: 0.8949 - val_loss: 0.8925 - val_accuracy: 0.7027\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - 4s 405ms/step - loss: 0.2099 - accuracy: 0.9186 - val_loss: 0.8791 - val_accuracy: 0.6486\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.1824 - accuracy: 0.9119 - val_loss: 0.9052 - val_accuracy: 0.6757\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - 4s 396ms/step - loss: 0.1970 - accuracy: 0.8983 - val_loss: 0.8269 - val_accuracy: 0.7027\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.1800 - accuracy: 0.9220 - val_loss: 5.3635 - val_accuracy: 0.2703\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.2486 - accuracy: 0.8881 - val_loss: 3.2568 - val_accuracy: 0.5676\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.2267 - accuracy: 0.8949 - val_loss: 1.7529 - val_accuracy: 0.5946\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.1915 - accuracy: 0.9186 - val_loss: 2.0323 - val_accuracy: 0.5946\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 0.2005 - accuracy: 0.8983 - val_loss: 1.3617 - val_accuracy: 0.6486\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - 4s 382ms/step - loss: 0.2306 - accuracy: 0.8847 - val_loss: 0.8856 - val_accuracy: 0.7027\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - 4s 397ms/step - loss: 0.1805 - accuracy: 0.9017 - val_loss: 0.7320 - val_accuracy: 0.7568\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - 4s 384ms/step - loss: 0.2315 - accuracy: 0.8949 - val_loss: 0.7045 - val_accuracy: 0.7297\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - 4s 394ms/step - loss: 0.1515 - accuracy: 0.9322 - val_loss: 0.7069 - val_accuracy: 0.7027\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - 4s 379ms/step - loss: 0.1882 - accuracy: 0.8949 - val_loss: 0.7696 - val_accuracy: 0.7027\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - 4s 392ms/step - loss: 0.2071 - accuracy: 0.8949 - val_loss: 0.7925 - val_accuracy: 0.6757\n",
      "Epoch 112/150\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.1975 - accuracy: 0.9017 - val_loss: 0.8521 - val_accuracy: 0.7027\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.2053 - accuracy: 0.9051 - val_loss: 0.8559 - val_accuracy: 0.7027\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.1664 - accuracy: 0.9085 - val_loss: 0.7611 - val_accuracy: 0.7027\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.1826 - accuracy: 0.9119 - val_loss: 0.7316 - val_accuracy: 0.7027\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - 4s 379ms/step - loss: 0.1735 - accuracy: 0.9153 - val_loss: 0.7550 - val_accuracy: 0.7027\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - 4s 392ms/step - loss: 0.1761 - accuracy: 0.9119 - val_loss: 0.7802 - val_accuracy: 0.6757\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - 4s 384ms/step - loss: 0.1756 - accuracy: 0.9119 - val_loss: 0.8658 - val_accuracy: 0.6486\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - 4s 376ms/step - loss: 0.1898 - accuracy: 0.9051 - val_loss: 0.8479 - val_accuracy: 0.6757\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.1674 - accuracy: 0.9153 - val_loss: 0.7933 - val_accuracy: 0.6757\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - 4s 395ms/step - loss: 0.1859 - accuracy: 0.9085 - val_loss: 0.7966 - val_accuracy: 0.6216\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - 4s 383ms/step - loss: 0.1792 - accuracy: 0.9119 - val_loss: 1.0408 - val_accuracy: 0.6486\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - 4s 377ms/step - loss: 0.1442 - accuracy: 0.9288 - val_loss: 1.3680 - val_accuracy: 0.5946\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - 4s 384ms/step - loss: 0.2104 - accuracy: 0.9017 - val_loss: 1.2551 - val_accuracy: 0.6757\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.2039 - accuracy: 0.9051 - val_loss: 1.1920 - val_accuracy: 0.7027\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - 4s 389ms/step - loss: 0.1726 - accuracy: 0.9085 - val_loss: 0.9697 - val_accuracy: 0.7027\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - 4s 384ms/step - loss: 0.1973 - accuracy: 0.9153 - val_loss: 0.8869 - val_accuracy: 0.6216\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - 4s 384ms/step - loss: 0.1561 - accuracy: 0.9186 - val_loss: 0.8464 - val_accuracy: 0.7027\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - 4s 397ms/step - loss: 0.1863 - accuracy: 0.9254 - val_loss: 0.8923 - val_accuracy: 0.7297\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.1684 - accuracy: 0.9153 - val_loss: 0.8818 - val_accuracy: 0.7297\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - 4s 379ms/step - loss: 0.1506 - accuracy: 0.9288 - val_loss: 0.8453 - val_accuracy: 0.7568\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - 4s 394ms/step - loss: 0.1949 - accuracy: 0.8949 - val_loss: 0.8290 - val_accuracy: 0.7297\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - 4s 383ms/step - loss: 0.1451 - accuracy: 0.9220 - val_loss: 0.8947 - val_accuracy: 0.7297\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.1675 - accuracy: 0.9153 - val_loss: 0.9580 - val_accuracy: 0.6757\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.1477 - accuracy: 0.9220 - val_loss: 1.1193 - val_accuracy: 0.7027\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - 4s 378ms/step - loss: 0.1779 - accuracy: 0.9085 - val_loss: 1.1508 - val_accuracy: 0.7027\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.1569 - accuracy: 0.9119 - val_loss: 1.0253 - val_accuracy: 0.7027\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - 4s 380ms/step - loss: 0.1875 - accuracy: 0.9119 - val_loss: 0.9298 - val_accuracy: 0.7027\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.1967 - accuracy: 0.9119 - val_loss: 0.8740 - val_accuracy: 0.6757\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.1650 - accuracy: 0.9153 - val_loss: 0.9383 - val_accuracy: 0.7027\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - 4s 381ms/step - loss: 0.1814 - accuracy: 0.9220 - val_loss: 1.0553 - val_accuracy: 0.6757\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - 4s 394ms/step - loss: 0.1821 - accuracy: 0.9085 - val_loss: 1.1254 - val_accuracy: 0.7027\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 0.1192 - accuracy: 0.9458 - val_loss: 1.1538 - val_accuracy: 0.7027\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.1647 - accuracy: 0.9288 - val_loss: 1.2334 - val_accuracy: 0.6757\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.1553 - accuracy: 0.9186 - val_loss: 1.2162 - val_accuracy: 0.7027\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.1407 - accuracy: 0.9288 - val_loss: 1.1606 - val_accuracy: 0.7027\n",
      "Epoch 147/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.1759 - accuracy: 0.9288 - val_loss: 1.1434 - val_accuracy: 0.7027\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.1759 - accuracy: 0.9085 - val_loss: 1.0485 - val_accuracy: 0.7297\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - 4s 396ms/step - loss: 0.1765 - accuracy: 0.9254 - val_loss: 0.9901 - val_accuracy: 0.7027\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - 4s 381ms/step - loss: 0.1782 - accuracy: 0.9119 - val_loss: 1.0406 - val_accuracy: 0.6757\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.7134 - accuracy: 0.7568\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.0406 - accuracy: 0.6757\n",
      "LOSS : 1.0406485795974731\n",
      "ACCURACY : 0.6756756901741028\n",
      "LOSS : 0.7133501172065735\n",
      "ACCURACY : 0.7567567825317383\n",
      "2/2 [==============================] - 0s 27ms/step\n",
      "Accuracy: 0.756757\n",
      "Precision: 0.753333\n",
      "Recall: 0.698593\n",
      "F1 score: 0.720053\n",
      "Fold:3, Train set: 369, Test set:92\n",
      "====================\n",
      "Fold:  3\n",
      "====================\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 279, 48, 32)       320       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 139, 24, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 139, 24, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 139, 24, 32)       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 137, 22, 32)       9248      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 68, 11, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 68, 11, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 68, 11, 32)        0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 66, 9, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 33, 4, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 33, 4, 32)         128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 33, 4, 32)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 4224)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               2163200   \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2185987 (8.34 MB)\n",
      "Trainable params: 2184771 (8.33 MB)\n",
      "Non-trainable params: 1216 (4.75 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - 6s 415ms/step - loss: 1.6875 - accuracy: 0.4102 - val_loss: 1.0129 - val_accuracy: 0.4865\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - 4s 411ms/step - loss: 1.2737 - accuracy: 0.5390 - val_loss: 1.0105 - val_accuracy: 0.4865\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 1.1129 - accuracy: 0.6068 - val_loss: 1.1131 - val_accuracy: 0.4865\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - 4s 378ms/step - loss: 1.1072 - accuracy: 0.5864 - val_loss: 0.9907 - val_accuracy: 0.4865\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.9345 - accuracy: 0.6847 - val_loss: 1.0042 - val_accuracy: 0.4865\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - 4s 383ms/step - loss: 0.9894 - accuracy: 0.6678 - val_loss: 0.9887 - val_accuracy: 0.4865\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - 4s 391ms/step - loss: 0.7883 - accuracy: 0.7085 - val_loss: 1.0450 - val_accuracy: 0.4865\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.9467 - accuracy: 0.7051 - val_loss: 1.1184 - val_accuracy: 0.4865\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - 4s 380ms/step - loss: 0.7863 - accuracy: 0.7390 - val_loss: 1.2692 - val_accuracy: 0.4865\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - 4s 399ms/step - loss: 0.8375 - accuracy: 0.7288 - val_loss: 1.4861 - val_accuracy: 0.4865\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.7975 - accuracy: 0.7322 - val_loss: 1.3517 - val_accuracy: 0.4865\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 0.6309 - accuracy: 0.7559 - val_loss: 1.2544 - val_accuracy: 0.4865\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - 4s 392ms/step - loss: 0.5299 - accuracy: 0.7831 - val_loss: 1.2841 - val_accuracy: 0.4865\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - 4s 379ms/step - loss: 0.5444 - accuracy: 0.7898 - val_loss: 1.3710 - val_accuracy: 0.4865\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.6138 - accuracy: 0.7593 - val_loss: 1.3210 - val_accuracy: 0.4865\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - 4s 418ms/step - loss: 0.5542 - accuracy: 0.7831 - val_loss: 1.3882 - val_accuracy: 0.4865\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - 4s 407ms/step - loss: 0.5136 - accuracy: 0.8034 - val_loss: 1.3951 - val_accuracy: 0.4865\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - 4s 404ms/step - loss: 0.4684 - accuracy: 0.8034 - val_loss: 1.2959 - val_accuracy: 0.4865\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - 4s 395ms/step - loss: 0.4953 - accuracy: 0.7932 - val_loss: 1.3002 - val_accuracy: 0.4865\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.4642 - accuracy: 0.8034 - val_loss: 1.3000 - val_accuracy: 0.4865\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - 4s 383ms/step - loss: 0.4030 - accuracy: 0.8237 - val_loss: 1.7213 - val_accuracy: 0.4865\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - 4s 384ms/step - loss: 0.4058 - accuracy: 0.8000 - val_loss: 1.9519 - val_accuracy: 0.4865\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - 4s 380ms/step - loss: 0.4306 - accuracy: 0.8034 - val_loss: 2.1606 - val_accuracy: 0.4865\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.3693 - accuracy: 0.8373 - val_loss: 2.0520 - val_accuracy: 0.4865\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - 4s 384ms/step - loss: 0.4218 - accuracy: 0.8271 - val_loss: 1.8911 - val_accuracy: 0.4865\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 0.3536 - accuracy: 0.8407 - val_loss: 2.4902 - val_accuracy: 0.4865\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - 4s 380ms/step - loss: 0.3592 - accuracy: 0.8475 - val_loss: 2.6551 - val_accuracy: 0.4865\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - 4s 384ms/step - loss: 0.3500 - accuracy: 0.8373 - val_loss: 2.4059 - val_accuracy: 0.4865\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.3311 - accuracy: 0.8610 - val_loss: 2.0319 - val_accuracy: 0.4865\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - 4s 379ms/step - loss: 0.3718 - accuracy: 0.8610 - val_loss: 2.0109 - val_accuracy: 0.4865\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.3209 - accuracy: 0.8644 - val_loss: 1.7976 - val_accuracy: 0.4865\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.3460 - accuracy: 0.8373 - val_loss: 1.6753 - val_accuracy: 0.4865\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - 4s 384ms/step - loss: 0.3107 - accuracy: 0.8644 - val_loss: 1.6533 - val_accuracy: 0.4865\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - 4s 376ms/step - loss: 0.3567 - accuracy: 0.8271 - val_loss: 1.6002 - val_accuracy: 0.4865\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.3214 - accuracy: 0.8576 - val_loss: 1.6723 - val_accuracy: 0.4865\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.2987 - accuracy: 0.8644 - val_loss: 1.5143 - val_accuracy: 0.4865\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - 4s 391ms/step - loss: 0.3516 - accuracy: 0.8373 - val_loss: 1.2543 - val_accuracy: 0.5135\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.2904 - accuracy: 0.8644 - val_loss: 1.1653 - val_accuracy: 0.5135\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - 4s 391ms/step - loss: 0.3887 - accuracy: 0.8305 - val_loss: 2.8556 - val_accuracy: 0.4865\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - 4s 379ms/step - loss: 0.3431 - accuracy: 0.8271 - val_loss: 1.4187 - val_accuracy: 0.4865\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - 4s 395ms/step - loss: 0.2637 - accuracy: 0.8847 - val_loss: 1.0225 - val_accuracy: 0.6216\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - 4s 382ms/step - loss: 0.3700 - accuracy: 0.8441 - val_loss: 1.0389 - val_accuracy: 0.6757\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - 4s 396ms/step - loss: 0.3220 - accuracy: 0.8373 - val_loss: 1.9036 - val_accuracy: 0.4865\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - 4s 428ms/step - loss: 0.3287 - accuracy: 0.8441 - val_loss: 2.1615 - val_accuracy: 0.4865\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - 4s 395ms/step - loss: 0.2342 - accuracy: 0.8881 - val_loss: 2.1551 - val_accuracy: 0.4865\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - 4s 402ms/step - loss: 0.2911 - accuracy: 0.8508 - val_loss: 1.4329 - val_accuracy: 0.5135\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - 4s 391ms/step - loss: 0.3041 - accuracy: 0.8475 - val_loss: 1.7260 - val_accuracy: 0.4865\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - 4s 414ms/step - loss: 0.2920 - accuracy: 0.8576 - val_loss: 1.6237 - val_accuracy: 0.5135\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - 4s 403ms/step - loss: 0.2671 - accuracy: 0.8847 - val_loss: 1.6871 - val_accuracy: 0.4865\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - 4s 395ms/step - loss: 0.2610 - accuracy: 0.8780 - val_loss: 1.6927 - val_accuracy: 0.4865\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - 4s 379ms/step - loss: 0.2997 - accuracy: 0.8678 - val_loss: 1.4865 - val_accuracy: 0.4865\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - 4s 389ms/step - loss: 0.2119 - accuracy: 0.9085 - val_loss: 1.5390 - val_accuracy: 0.5135\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - 4s 391ms/step - loss: 0.2937 - accuracy: 0.8542 - val_loss: 1.6913 - val_accuracy: 0.4865\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 0.2433 - accuracy: 0.8983 - val_loss: 2.0683 - val_accuracy: 0.4865\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - 4s 378ms/step - loss: 0.2527 - accuracy: 0.8746 - val_loss: 2.0444 - val_accuracy: 0.4865\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.2515 - accuracy: 0.8881 - val_loss: 1.9328 - val_accuracy: 0.4865\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 0.2503 - accuracy: 0.8847 - val_loss: 1.8099 - val_accuracy: 0.4865\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - 4s 391ms/step - loss: 0.2686 - accuracy: 0.8644 - val_loss: 1.3102 - val_accuracy: 0.5676\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - 4s 381ms/step - loss: 0.2993 - accuracy: 0.8678 - val_loss: 1.3533 - val_accuracy: 0.6216\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - 4s 413ms/step - loss: 0.2753 - accuracy: 0.8576 - val_loss: 1.3469 - val_accuracy: 0.5676\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - 4s 395ms/step - loss: 0.2774 - accuracy: 0.8475 - val_loss: 0.8194 - val_accuracy: 0.7297\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - 4s 397ms/step - loss: 0.2758 - accuracy: 0.8678 - val_loss: 0.8660 - val_accuracy: 0.7027\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.3126 - accuracy: 0.8644 - val_loss: 0.8435 - val_accuracy: 0.7297\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - 4s 379ms/step - loss: 0.2478 - accuracy: 0.8644 - val_loss: 0.9969 - val_accuracy: 0.6486\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.2350 - accuracy: 0.8814 - val_loss: 0.9887 - val_accuracy: 0.6757\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.2402 - accuracy: 0.8712 - val_loss: 1.5630 - val_accuracy: 0.5676\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.2201 - accuracy: 0.9017 - val_loss: 1.1224 - val_accuracy: 0.7297\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - 4s 382ms/step - loss: 0.2085 - accuracy: 0.9017 - val_loss: 0.9290 - val_accuracy: 0.7838\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - 4s 392ms/step - loss: 0.2300 - accuracy: 0.8712 - val_loss: 0.6234 - val_accuracy: 0.7838\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - 4s 391ms/step - loss: 0.2549 - accuracy: 0.8678 - val_loss: 0.5915 - val_accuracy: 0.7838\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.3071 - accuracy: 0.8644 - val_loss: 0.6402 - val_accuracy: 0.8108\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.2283 - accuracy: 0.8814 - val_loss: 0.8883 - val_accuracy: 0.8108\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - 4s 381ms/step - loss: 0.2601 - accuracy: 0.8644 - val_loss: 0.8417 - val_accuracy: 0.7568\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - 4s 384ms/step - loss: 0.2417 - accuracy: 0.8915 - val_loss: 0.6508 - val_accuracy: 0.7568\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - 4s 425ms/step - loss: 0.2476 - accuracy: 0.8915 - val_loss: 0.6393 - val_accuracy: 0.7027\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - 4s 399ms/step - loss: 0.2320 - accuracy: 0.8983 - val_loss: 0.5760 - val_accuracy: 0.7838\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - 4s 382ms/step - loss: 0.2741 - accuracy: 0.8678 - val_loss: 0.5156 - val_accuracy: 0.7568\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.2149 - accuracy: 0.8949 - val_loss: 0.5022 - val_accuracy: 0.7297\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.2088 - accuracy: 0.9322 - val_loss: 0.5613 - val_accuracy: 0.7297\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.2353 - accuracy: 0.8881 - val_loss: 0.5636 - val_accuracy: 0.7297\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - 4s 380ms/step - loss: 0.2359 - accuracy: 0.8847 - val_loss: 0.5705 - val_accuracy: 0.7297\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.1956 - accuracy: 0.9220 - val_loss: 0.6202 - val_accuracy: 0.7297\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - 4s 392ms/step - loss: 0.2155 - accuracy: 0.9017 - val_loss: 0.6397 - val_accuracy: 0.7297\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - 4s 379ms/step - loss: 0.1933 - accuracy: 0.9153 - val_loss: 0.5462 - val_accuracy: 0.7297\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.1870 - accuracy: 0.9153 - val_loss: 0.4719 - val_accuracy: 0.7838\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.2410 - accuracy: 0.8847 - val_loss: 0.4807 - val_accuracy: 0.8108\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - 4s 379ms/step - loss: 0.1761 - accuracy: 0.9119 - val_loss: 0.4660 - val_accuracy: 0.8108\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.1654 - accuracy: 0.9119 - val_loss: 0.4960 - val_accuracy: 0.7838\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.2068 - accuracy: 0.9186 - val_loss: 0.5050 - val_accuracy: 0.7838\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.2156 - accuracy: 0.8983 - val_loss: 0.4949 - val_accuracy: 0.7568\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - 4s 382ms/step - loss: 0.2121 - accuracy: 0.8780 - val_loss: 0.4398 - val_accuracy: 0.8108\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.2400 - accuracy: 0.8780 - val_loss: 0.5678 - val_accuracy: 0.8108\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.2316 - accuracy: 0.8644 - val_loss: 0.6163 - val_accuracy: 0.7568\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - 4s 391ms/step - loss: 0.2200 - accuracy: 0.8814 - val_loss: 0.6918 - val_accuracy: 0.7297\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.2263 - accuracy: 0.8915 - val_loss: 0.6671 - val_accuracy: 0.7297\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.2337 - accuracy: 0.8780 - val_loss: 2.4943 - val_accuracy: 0.5676\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - 4s 391ms/step - loss: 0.2007 - accuracy: 0.8949 - val_loss: 1.0780 - val_accuracy: 0.7568\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.2060 - accuracy: 0.9051 - val_loss: 0.8456 - val_accuracy: 0.7838\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - 4s 392ms/step - loss: 0.2481 - accuracy: 0.8915 - val_loss: 0.6117 - val_accuracy: 0.7568\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 0.2314 - accuracy: 0.8712 - val_loss: 0.5965 - val_accuracy: 0.7568\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.2359 - accuracy: 0.8814 - val_loss: 0.5570 - val_accuracy: 0.7568\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - 4s 382ms/step - loss: 0.2016 - accuracy: 0.8915 - val_loss: 0.4879 - val_accuracy: 0.7838\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.2202 - accuracy: 0.8847 - val_loss: 0.4539 - val_accuracy: 0.7838\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - 4s 392ms/step - loss: 0.1973 - accuracy: 0.8949 - val_loss: 0.3940 - val_accuracy: 0.8108\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.2117 - accuracy: 0.8915 - val_loss: 0.4356 - val_accuracy: 0.7568\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - 4s 384ms/step - loss: 0.2132 - accuracy: 0.8915 - val_loss: 0.4416 - val_accuracy: 0.8108\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - 4s 395ms/step - loss: 0.2294 - accuracy: 0.8814 - val_loss: 0.4531 - val_accuracy: 0.7838\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - 4s 389ms/step - loss: 0.1753 - accuracy: 0.9119 - val_loss: 0.4972 - val_accuracy: 0.7568\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.1774 - accuracy: 0.9119 - val_loss: 0.5662 - val_accuracy: 0.7568\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - 4s 395ms/step - loss: 0.2133 - accuracy: 0.8915 - val_loss: 0.6594 - val_accuracy: 0.7568\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - 4s 384ms/step - loss: 0.2074 - accuracy: 0.8983 - val_loss: 0.5067 - val_accuracy: 0.7838\n",
      "Epoch 112/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.2316 - accuracy: 0.8949 - val_loss: 0.4970 - val_accuracy: 0.7838\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.2462 - accuracy: 0.8712 - val_loss: 0.4428 - val_accuracy: 0.8108\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - 4s 382ms/step - loss: 0.1994 - accuracy: 0.9017 - val_loss: 0.4101 - val_accuracy: 0.8378\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - 4s 389ms/step - loss: 0.1723 - accuracy: 0.8983 - val_loss: 0.4408 - val_accuracy: 0.8108\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - 4s 379ms/step - loss: 0.1562 - accuracy: 0.9322 - val_loss: 0.4657 - val_accuracy: 0.8108\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - 4s 379ms/step - loss: 0.2177 - accuracy: 0.8949 - val_loss: 14.7606 - val_accuracy: 0.4054\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - 4s 397ms/step - loss: 0.2136 - accuracy: 0.8949 - val_loss: 0.5675 - val_accuracy: 0.7838\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.2381 - accuracy: 0.8780 - val_loss: 0.3988 - val_accuracy: 0.8108\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - 4s 383ms/step - loss: 0.1917 - accuracy: 0.8881 - val_loss: 0.4252 - val_accuracy: 0.7838\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - 4s 392ms/step - loss: 0.1969 - accuracy: 0.9119 - val_loss: 0.5768 - val_accuracy: 0.8378\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.1875 - accuracy: 0.9085 - val_loss: 0.4755 - val_accuracy: 0.8108\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - 4s 382ms/step - loss: 0.2146 - accuracy: 0.8915 - val_loss: 0.4396 - val_accuracy: 0.8108\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - 4s 394ms/step - loss: 0.2003 - accuracy: 0.8915 - val_loss: 0.4691 - val_accuracy: 0.8378\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.2342 - accuracy: 0.8915 - val_loss: 0.4695 - val_accuracy: 0.8378\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - 4s 395ms/step - loss: 0.1968 - accuracy: 0.8915 - val_loss: 0.5044 - val_accuracy: 0.8108\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 0.2219 - accuracy: 0.8814 - val_loss: 0.6181 - val_accuracy: 0.7568\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - 4s 389ms/step - loss: 0.1769 - accuracy: 0.8983 - val_loss: 0.7021 - val_accuracy: 0.7568\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.2063 - accuracy: 0.8949 - val_loss: 0.7488 - val_accuracy: 0.7568\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.1865 - accuracy: 0.9119 - val_loss: 0.6366 - val_accuracy: 0.7568\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - 4s 400ms/step - loss: 0.1949 - accuracy: 0.9051 - val_loss: 0.5403 - val_accuracy: 0.7568\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - 4s 383ms/step - loss: 0.1858 - accuracy: 0.9051 - val_loss: 0.4978 - val_accuracy: 0.8108\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - 4s 380ms/step - loss: 0.1964 - accuracy: 0.9017 - val_loss: 0.4918 - val_accuracy: 0.7568\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - 4s 392ms/step - loss: 0.2024 - accuracy: 0.9051 - val_loss: 0.5746 - val_accuracy: 0.7568\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - 4s 402ms/step - loss: 0.2105 - accuracy: 0.8814 - val_loss: 0.5348 - val_accuracy: 0.7297\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - 4s 391ms/step - loss: 0.2191 - accuracy: 0.8949 - val_loss: 0.5503 - val_accuracy: 0.7838\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - 4s 379ms/step - loss: 0.1988 - accuracy: 0.8983 - val_loss: 0.5868 - val_accuracy: 0.7568\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - 4s 391ms/step - loss: 0.1916 - accuracy: 0.9017 - val_loss: 0.6097 - val_accuracy: 0.7568\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - 4s 389ms/step - loss: 0.2033 - accuracy: 0.8881 - val_loss: 0.6917 - val_accuracy: 0.7568\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.1877 - accuracy: 0.9153 - val_loss: 0.5314 - val_accuracy: 0.7568\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - 4s 380ms/step - loss: 0.2033 - accuracy: 0.8983 - val_loss: 0.4862 - val_accuracy: 0.8108\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - 4s 396ms/step - loss: 0.2038 - accuracy: 0.9051 - val_loss: 0.5420 - val_accuracy: 0.7568\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - 4s 391ms/step - loss: 0.1836 - accuracy: 0.8983 - val_loss: 0.5371 - val_accuracy: 0.7568\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - 4s 391ms/step - loss: 0.2050 - accuracy: 0.8847 - val_loss: 0.6680 - val_accuracy: 0.7568\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - 4s 382ms/step - loss: 0.1843 - accuracy: 0.8915 - val_loss: 0.6098 - val_accuracy: 0.7297\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.1946 - accuracy: 0.8881 - val_loss: 0.6751 - val_accuracy: 0.7568\n",
      "Epoch 147/150\n",
      "10/10 [==============================] - 4s 392ms/step - loss: 0.2059 - accuracy: 0.8746 - val_loss: 0.9025 - val_accuracy: 0.7568\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.2094 - accuracy: 0.8814 - val_loss: 1.0440 - val_accuracy: 0.7297\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 0.1899 - accuracy: 0.8983 - val_loss: 0.9637 - val_accuracy: 0.7568\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.1897 - accuracy: 0.9186 - val_loss: 0.8425 - val_accuracy: 0.7297\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.4559 - accuracy: 0.5676\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8425 - accuracy: 0.7297\n",
      "LOSS : 0.8425459861755371\n",
      "ACCURACY : 0.7297297120094299\n",
      "LOSS : 1.4559125900268555\n",
      "ACCURACY : 0.5675675868988037\n",
      "2/2 [==============================] - 0s 22ms/step\n",
      "Accuracy: 0.567568\n",
      "Precision: 0.504094\n",
      "Recall: 0.538847\n",
      "F1 score: 0.487582\n",
      "Fold:4, Train set: 369, Test set:92\n",
      "====================\n",
      "Fold:  4\n",
      "====================\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 279, 48, 32)       320       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (None, 139, 24, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 139, 24, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 139, 24, 32)       0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 137, 22, 32)       9248      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 68, 11, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 68, 11, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 68, 11, 32)        0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 66, 9, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 33, 4, 32)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 33, 4, 32)         128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 33, 4, 32)         0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 4224)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               2163200   \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2185987 (8.34 MB)\n",
      "Trainable params: 2184771 (8.33 MB)\n",
      "Non-trainable params: 1216 (4.75 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - 7s 419ms/step - loss: 1.5646 - accuracy: 0.4475 - val_loss: 1.1210 - val_accuracy: 0.3243\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - 4s 384ms/step - loss: 1.1767 - accuracy: 0.5729 - val_loss: 1.1431 - val_accuracy: 0.3243\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 1.0048 - accuracy: 0.6271 - val_loss: 1.5303 - val_accuracy: 0.3243\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - 4s 406ms/step - loss: 0.9148 - accuracy: 0.6339 - val_loss: 1.9429 - val_accuracy: 0.3243\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.9448 - accuracy: 0.7085 - val_loss: 2.0830 - val_accuracy: 0.3243\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.9645 - accuracy: 0.6373 - val_loss: 2.3803 - val_accuracy: 0.3243\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - 4s 383ms/step - loss: 0.7323 - accuracy: 0.7661 - val_loss: 2.8377 - val_accuracy: 0.3243\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - 4s 403ms/step - loss: 0.7236 - accuracy: 0.7492 - val_loss: 3.1163 - val_accuracy: 0.3243\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - 4s 397ms/step - loss: 0.6846 - accuracy: 0.7661 - val_loss: 3.4415 - val_accuracy: 0.3243\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.6001 - accuracy: 0.7763 - val_loss: 4.1668 - val_accuracy: 0.3243\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - 4s 396ms/step - loss: 0.5294 - accuracy: 0.7898 - val_loss: 4.9109 - val_accuracy: 0.3243\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - 4s 394ms/step - loss: 0.5558 - accuracy: 0.7864 - val_loss: 4.4984 - val_accuracy: 0.3243\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 0.4409 - accuracy: 0.8136 - val_loss: 4.0313 - val_accuracy: 0.3243\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - 4s 395ms/step - loss: 0.4446 - accuracy: 0.8169 - val_loss: 4.2735 - val_accuracy: 0.3243\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - 4s 396ms/step - loss: 0.4637 - accuracy: 0.8305 - val_loss: 4.8249 - val_accuracy: 0.3243\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.4407 - accuracy: 0.8305 - val_loss: 4.8166 - val_accuracy: 0.3243\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - 4s 401ms/step - loss: 0.3653 - accuracy: 0.8475 - val_loss: 5.2172 - val_accuracy: 0.3243\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - 4s 405ms/step - loss: 0.3092 - accuracy: 0.8780 - val_loss: 5.3508 - val_accuracy: 0.3243\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - 4s 380ms/step - loss: 0.3322 - accuracy: 0.8576 - val_loss: 5.4289 - val_accuracy: 0.3243\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.3498 - accuracy: 0.8780 - val_loss: 5.5557 - val_accuracy: 0.3243\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 0.3791 - accuracy: 0.8508 - val_loss: 5.7369 - val_accuracy: 0.3243\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - 4s 399ms/step - loss: 0.2535 - accuracy: 0.8881 - val_loss: 5.6645 - val_accuracy: 0.3243\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.3627 - accuracy: 0.8576 - val_loss: 5.6301 - val_accuracy: 0.3243\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - 4s 389ms/step - loss: 0.3962 - accuracy: 0.8576 - val_loss: 5.2468 - val_accuracy: 0.3243\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - 4s 404ms/step - loss: 0.3540 - accuracy: 0.8610 - val_loss: 5.2955 - val_accuracy: 0.3243\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - 4s 407ms/step - loss: 0.3087 - accuracy: 0.8712 - val_loss: 5.3731 - val_accuracy: 0.3243\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - 4s 396ms/step - loss: 0.3065 - accuracy: 0.8881 - val_loss: 5.3428 - val_accuracy: 0.3243\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - 4s 398ms/step - loss: 0.3535 - accuracy: 0.8678 - val_loss: 5.2816 - val_accuracy: 0.3243\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - 4s 389ms/step - loss: 0.3229 - accuracy: 0.8610 - val_loss: 5.2768 - val_accuracy: 0.3243\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 0.2875 - accuracy: 0.8847 - val_loss: 5.8064 - val_accuracy: 0.3243\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - 4s 391ms/step - loss: 0.2493 - accuracy: 0.8814 - val_loss: 5.9457 - val_accuracy: 0.3243\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 0.2487 - accuracy: 0.9051 - val_loss: 5.7566 - val_accuracy: 0.3243\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - 4s 391ms/step - loss: 0.2756 - accuracy: 0.8780 - val_loss: 5.6966 - val_accuracy: 0.3243\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 0.2901 - accuracy: 0.8949 - val_loss: 5.5860 - val_accuracy: 0.3243\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - 4s 405ms/step - loss: 0.2104 - accuracy: 0.9186 - val_loss: 5.1949 - val_accuracy: 0.3243\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.2268 - accuracy: 0.9017 - val_loss: 5.2602 - val_accuracy: 0.3243\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.2912 - accuracy: 0.8678 - val_loss: 4.9745 - val_accuracy: 0.3243\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - 4s 406ms/step - loss: 0.2496 - accuracy: 0.9051 - val_loss: 5.1332 - val_accuracy: 0.3243\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - 4s 419ms/step - loss: 0.1982 - accuracy: 0.9119 - val_loss: 4.9821 - val_accuracy: 0.3243\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - 5s 493ms/step - loss: 0.2259 - accuracy: 0.8949 - val_loss: 4.4327 - val_accuracy: 0.3243\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - 5s 475ms/step - loss: 0.2408 - accuracy: 0.9017 - val_loss: 4.5688 - val_accuracy: 0.3243\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - 4s 441ms/step - loss: 0.2047 - accuracy: 0.9119 - val_loss: 4.4493 - val_accuracy: 0.3243\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.2482 - accuracy: 0.8881 - val_loss: 3.6970 - val_accuracy: 0.3243\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - 4s 399ms/step - loss: 0.1879 - accuracy: 0.9186 - val_loss: 3.8674 - val_accuracy: 0.3243\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - 4s 408ms/step - loss: 0.2385 - accuracy: 0.8983 - val_loss: 3.9130 - val_accuracy: 0.3243\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - 4s 389ms/step - loss: 0.2124 - accuracy: 0.9085 - val_loss: 3.8758 - val_accuracy: 0.3243\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - 4s 389ms/step - loss: 0.2064 - accuracy: 0.9017 - val_loss: 3.5854 - val_accuracy: 0.3243\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - 4s 418ms/step - loss: 0.1916 - accuracy: 0.9254 - val_loss: 3.7709 - val_accuracy: 0.3243\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - 4s 451ms/step - loss: 0.1968 - accuracy: 0.9186 - val_loss: 3.8536 - val_accuracy: 0.3243\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - 4s 433ms/step - loss: 0.2059 - accuracy: 0.9119 - val_loss: 3.6599 - val_accuracy: 0.3243\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - 4s 400ms/step - loss: 0.1386 - accuracy: 0.9458 - val_loss: 3.5319 - val_accuracy: 0.3243\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - 4s 396ms/step - loss: 0.2164 - accuracy: 0.8983 - val_loss: 3.4864 - val_accuracy: 0.3243\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - 4s 397ms/step - loss: 0.1614 - accuracy: 0.9254 - val_loss: 3.7907 - val_accuracy: 0.3243\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - 4s 392ms/step - loss: 0.1853 - accuracy: 0.9220 - val_loss: 3.8556 - val_accuracy: 0.3243\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 0.1978 - accuracy: 0.9288 - val_loss: 3.8335 - val_accuracy: 0.3243\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - 4s 407ms/step - loss: 0.2035 - accuracy: 0.9119 - val_loss: 3.5161 - val_accuracy: 0.3243\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - 4s 399ms/step - loss: 0.2163 - accuracy: 0.8847 - val_loss: 3.3028 - val_accuracy: 0.3243\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - 4s 383ms/step - loss: 0.1518 - accuracy: 0.9390 - val_loss: 2.8262 - val_accuracy: 0.3514\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - 4s 404ms/step - loss: 0.2665 - accuracy: 0.8949 - val_loss: 3.3824 - val_accuracy: 0.3243\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - 4s 396ms/step - loss: 0.2032 - accuracy: 0.9119 - val_loss: 3.1780 - val_accuracy: 0.3243\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - 4s 394ms/step - loss: 0.1636 - accuracy: 0.9322 - val_loss: 2.7642 - val_accuracy: 0.3514\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 0.1589 - accuracy: 0.9356 - val_loss: 2.2145 - val_accuracy: 0.4054\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - 4s 392ms/step - loss: 0.1601 - accuracy: 0.9186 - val_loss: 1.9591 - val_accuracy: 0.3784\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - 4s 398ms/step - loss: 0.1469 - accuracy: 0.9356 - val_loss: 2.0060 - val_accuracy: 0.4054\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - 4s 397ms/step - loss: 0.2143 - accuracy: 0.9051 - val_loss: 1.9665 - val_accuracy: 0.4324\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - 4s 391ms/step - loss: 0.1502 - accuracy: 0.9356 - val_loss: 1.8546 - val_accuracy: 0.4595\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - 4s 396ms/step - loss: 0.1941 - accuracy: 0.9186 - val_loss: 1.4202 - val_accuracy: 0.4865\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 0.1594 - accuracy: 0.9220 - val_loss: 1.2521 - val_accuracy: 0.4595\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - 4s 404ms/step - loss: 0.1792 - accuracy: 0.9254 - val_loss: 1.0129 - val_accuracy: 0.5676\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.1730 - accuracy: 0.9085 - val_loss: 0.8175 - val_accuracy: 0.6486\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.1702 - accuracy: 0.9220 - val_loss: 0.8439 - val_accuracy: 0.7297\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - 4s 414ms/step - loss: 0.2114 - accuracy: 0.8983 - val_loss: 0.9195 - val_accuracy: 0.7838\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - 4s 397ms/step - loss: 0.1765 - accuracy: 0.9254 - val_loss: 0.8868 - val_accuracy: 0.7027\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - 4s 391ms/step - loss: 0.1547 - accuracy: 0.9390 - val_loss: 0.9546 - val_accuracy: 0.6757\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - 4s 397ms/step - loss: 0.1754 - accuracy: 0.9322 - val_loss: 0.9981 - val_accuracy: 0.7838\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - 4s 396ms/step - loss: 0.1271 - accuracy: 0.9390 - val_loss: 0.8567 - val_accuracy: 0.6486\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - 4s 397ms/step - loss: 0.2366 - accuracy: 0.9085 - val_loss: 0.9067 - val_accuracy: 0.6757\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - 4s 402ms/step - loss: 0.1802 - accuracy: 0.9220 - val_loss: 1.0362 - val_accuracy: 0.7027\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.2013 - accuracy: 0.9254 - val_loss: 0.9661 - val_accuracy: 0.7027\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - 4s 399ms/step - loss: 0.1859 - accuracy: 0.9220 - val_loss: 0.9028 - val_accuracy: 0.6216\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - 4s 398ms/step - loss: 0.1748 - accuracy: 0.9322 - val_loss: 1.0156 - val_accuracy: 0.6216\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - 4s 400ms/step - loss: 0.1592 - accuracy: 0.9288 - val_loss: 1.0863 - val_accuracy: 0.6216\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.1476 - accuracy: 0.9322 - val_loss: 1.2900 - val_accuracy: 0.5946\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - 4s 400ms/step - loss: 0.1370 - accuracy: 0.9458 - val_loss: 1.2335 - val_accuracy: 0.5676\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - 4s 394ms/step - loss: 0.1428 - accuracy: 0.9254 - val_loss: 1.0436 - val_accuracy: 0.6216\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - 4s 394ms/step - loss: 0.1653 - accuracy: 0.9153 - val_loss: 1.0072 - val_accuracy: 0.6216\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - 4s 394ms/step - loss: 0.1528 - accuracy: 0.9424 - val_loss: 1.0903 - val_accuracy: 0.6216\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - 4s 391ms/step - loss: 0.1270 - accuracy: 0.9525 - val_loss: 1.7532 - val_accuracy: 0.5135\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - 4s 398ms/step - loss: 0.1447 - accuracy: 0.9220 - val_loss: 1.4940 - val_accuracy: 0.5405\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - 4s 411ms/step - loss: 0.1366 - accuracy: 0.9322 - val_loss: 1.2699 - val_accuracy: 0.5946\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.1493 - accuracy: 0.9390 - val_loss: 1.1315 - val_accuracy: 0.5946\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.1326 - accuracy: 0.9492 - val_loss: 0.9898 - val_accuracy: 0.6486\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - 4s 404ms/step - loss: 0.1719 - accuracy: 0.9220 - val_loss: 0.9645 - val_accuracy: 0.6486\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - 4s 413ms/step - loss: 0.1159 - accuracy: 0.9492 - val_loss: 1.2436 - val_accuracy: 0.7568\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - 4s 399ms/step - loss: 0.2124 - accuracy: 0.9186 - val_loss: 0.8820 - val_accuracy: 0.6757\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - 4s 397ms/step - loss: 0.1394 - accuracy: 0.9356 - val_loss: 0.8401 - val_accuracy: 0.6486\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 0.1627 - accuracy: 0.9288 - val_loss: 1.1492 - val_accuracy: 0.6216\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - 4s 398ms/step - loss: 0.1746 - accuracy: 0.9356 - val_loss: 1.1686 - val_accuracy: 0.7027\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - 4s 399ms/step - loss: 0.2352 - accuracy: 0.8983 - val_loss: 1.1614 - val_accuracy: 0.7838\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.1219 - accuracy: 0.9525 - val_loss: 0.9674 - val_accuracy: 0.6757\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - 4s 397ms/step - loss: 0.1748 - accuracy: 0.9322 - val_loss: 0.9564 - val_accuracy: 0.6757\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - 4s 407ms/step - loss: 0.1644 - accuracy: 0.9153 - val_loss: 1.0223 - val_accuracy: 0.6486\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - 4s 408ms/step - loss: 0.1210 - accuracy: 0.9593 - val_loss: 1.2054 - val_accuracy: 0.6216\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.1619 - accuracy: 0.9356 - val_loss: 1.1628 - val_accuracy: 0.6486\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - 4s 401ms/step - loss: 0.1543 - accuracy: 0.9322 - val_loss: 1.0456 - val_accuracy: 0.6486\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - 4s 404ms/step - loss: 0.1587 - accuracy: 0.9254 - val_loss: 0.9502 - val_accuracy: 0.7297\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - 4s 401ms/step - loss: 0.1619 - accuracy: 0.9254 - val_loss: 0.9092 - val_accuracy: 0.7027\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - 4s 408ms/step - loss: 0.1211 - accuracy: 0.9492 - val_loss: 1.0454 - val_accuracy: 0.7027\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - 4s 384ms/step - loss: 0.1508 - accuracy: 0.9254 - val_loss: 1.1321 - val_accuracy: 0.7027\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.1321 - accuracy: 0.9390 - val_loss: 1.0386 - val_accuracy: 0.6757\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - 4s 396ms/step - loss: 0.1422 - accuracy: 0.9356 - val_loss: 1.0466 - val_accuracy: 0.6486\n",
      "Epoch 112/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.1646 - accuracy: 0.9322 - val_loss: 1.0978 - val_accuracy: 0.6216\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - 4s 400ms/step - loss: 0.1293 - accuracy: 0.9424 - val_loss: 1.1590 - val_accuracy: 0.6216\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - 4s 379ms/step - loss: 0.1060 - accuracy: 0.9559 - val_loss: 1.2236 - val_accuracy: 0.6216\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.2173 - accuracy: 0.9017 - val_loss: 1.2381 - val_accuracy: 0.5676\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - 4s 401ms/step - loss: 0.1415 - accuracy: 0.9390 - val_loss: 1.0954 - val_accuracy: 0.5676\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.1531 - accuracy: 0.9254 - val_loss: 1.0505 - val_accuracy: 0.7027\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - 4s 404ms/step - loss: 0.1208 - accuracy: 0.9424 - val_loss: 1.0288 - val_accuracy: 0.6757\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - 4s 396ms/step - loss: 0.1459 - accuracy: 0.9390 - val_loss: 1.0538 - val_accuracy: 0.6486\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - 4s 400ms/step - loss: 0.1919 - accuracy: 0.9186 - val_loss: 1.0547 - val_accuracy: 0.6757\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - 4s 404ms/step - loss: 0.1703 - accuracy: 0.9254 - val_loss: 1.1390 - val_accuracy: 0.6486\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - 4s 414ms/step - loss: 0.1517 - accuracy: 0.9356 - val_loss: 1.0501 - val_accuracy: 0.6486\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - 4s 406ms/step - loss: 0.1553 - accuracy: 0.9220 - val_loss: 0.9509 - val_accuracy: 0.6757\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - 4s 421ms/step - loss: 0.1527 - accuracy: 0.9356 - val_loss: 0.9720 - val_accuracy: 0.6486\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - 4s 418ms/step - loss: 0.1576 - accuracy: 0.9356 - val_loss: 0.9659 - val_accuracy: 0.6216\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - 4s 397ms/step - loss: 0.1267 - accuracy: 0.9322 - val_loss: 0.9221 - val_accuracy: 0.6486\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - 4s 383ms/step - loss: 0.1453 - accuracy: 0.9424 - val_loss: 0.8683 - val_accuracy: 0.6757\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - 4s 392ms/step - loss: 0.1393 - accuracy: 0.9492 - val_loss: 0.9104 - val_accuracy: 0.6486\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - 4s 384ms/step - loss: 0.1509 - accuracy: 0.9492 - val_loss: 0.9037 - val_accuracy: 0.6757\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.1332 - accuracy: 0.9390 - val_loss: 0.9848 - val_accuracy: 0.6486\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - 4s 395ms/step - loss: 0.1788 - accuracy: 0.9220 - val_loss: 1.0430 - val_accuracy: 0.6757\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - 4s 389ms/step - loss: 0.1629 - accuracy: 0.9322 - val_loss: 1.1180 - val_accuracy: 0.6486\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - 4s 383ms/step - loss: 0.1401 - accuracy: 0.9458 - val_loss: 1.2348 - val_accuracy: 0.6216\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - 4s 400ms/step - loss: 0.1441 - accuracy: 0.9492 - val_loss: 1.1782 - val_accuracy: 0.6216\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.1342 - accuracy: 0.9458 - val_loss: 0.9969 - val_accuracy: 0.6757\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - 4s 383ms/step - loss: 0.1475 - accuracy: 0.9424 - val_loss: 0.8868 - val_accuracy: 0.7027\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - 4s 396ms/step - loss: 0.1539 - accuracy: 0.9254 - val_loss: 0.8875 - val_accuracy: 0.7027\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - 4s 391ms/step - loss: 0.1203 - accuracy: 0.9525 - val_loss: 0.9352 - val_accuracy: 0.6757\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.1228 - accuracy: 0.9356 - val_loss: 0.9379 - val_accuracy: 0.6757\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - 4s 391ms/step - loss: 0.1648 - accuracy: 0.9220 - val_loss: 0.9637 - val_accuracy: 0.7027\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.1515 - accuracy: 0.9390 - val_loss: 1.0007 - val_accuracy: 0.6486\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.1325 - accuracy: 0.9458 - val_loss: 0.9289 - val_accuracy: 0.6486\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - 4s 400ms/step - loss: 0.1927 - accuracy: 0.9288 - val_loss: 0.8883 - val_accuracy: 0.7027\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.1392 - accuracy: 0.9390 - val_loss: 0.9237 - val_accuracy: 0.7027\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - 4s 398ms/step - loss: 0.1496 - accuracy: 0.9220 - val_loss: 0.9164 - val_accuracy: 0.6757\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.1312 - accuracy: 0.9492 - val_loss: 0.8524 - val_accuracy: 0.6757\n",
      "Epoch 147/150\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.1387 - accuracy: 0.9322 - val_loss: 0.8165 - val_accuracy: 0.7027\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - 4s 398ms/step - loss: 0.0981 - accuracy: 0.9559 - val_loss: 0.7848 - val_accuracy: 0.7027\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - 4s 389ms/step - loss: 0.1275 - accuracy: 0.9458 - val_loss: 0.7921 - val_accuracy: 0.6757\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - 4s 398ms/step - loss: 0.1082 - accuracy: 0.9458 - val_loss: 0.8268 - val_accuracy: 0.6757\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.3045 - accuracy: 0.5946\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.8268 - accuracy: 0.6757\n",
      "LOSS : 0.8267633318901062\n",
      "ACCURACY : 0.6756756901741028\n",
      "LOSS : 1.3045042753219604\n",
      "ACCURACY : 0.5945945978164673\n",
      "2/2 [==============================] - 0s 28ms/step\n",
      "Accuracy: 0.594595\n",
      "Precision: 0.561172\n",
      "Recall: 0.621212\n",
      "F1 score: 0.552381\n",
      "Fold:5, Train set: 369, Test set:92\n",
      "====================\n",
      "Fold:  5\n",
      "====================\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 279, 48, 32)       320       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPooli  (None, 139, 24, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 139, 24, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 139, 24, 32)       0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 137, 22, 32)       9248      \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPooli  (None, 68, 11, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 68, 11, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 68, 11, 32)        0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 66, 9, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPooli  (None, 33, 4, 32)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 33, 4, 32)         128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 33, 4, 32)         0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 4224)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               2163200   \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2185987 (8.34 MB)\n",
      "Trainable params: 2184771 (8.33 MB)\n",
      "Non-trainable params: 1216 (4.75 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - 6s 417ms/step - loss: 1.7027 - accuracy: 0.3831 - val_loss: 1.0441 - val_accuracy: 0.5676\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 1.2639 - accuracy: 0.5390 - val_loss: 1.1312 - val_accuracy: 0.3243\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - 4s 392ms/step - loss: 1.2178 - accuracy: 0.5932 - val_loss: 1.2661 - val_accuracy: 0.3243\n",
      "Epoch 4/150\n",
      " 3/10 [========>.....................] - ETA: 2s - loss: 0.9205 - accuracy: 0.6562"
     ]
    }
   ],
   "source": [
    "kf =KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cnt = 1\n",
    "# split()  method generate indices to split data into training and test set.\n",
    "for train_index, test_index in kf.split(cells, labels):\n",
    "    print(f'Fold:{cnt}, Train set: {len(train_index)}, Test set:{len(test_index)}')\n",
    "    print(\"=\"*20)\n",
    "    print(\"Fold: \", cnt)\n",
    "    print(\"=\"*20)\n",
    "    cnt +=1\n",
    "\n",
    "    x_train , x , y_train , y = train_test_split(cells[train_index] , labels[train_index] , \n",
    "                                                test_size = 0.2 ,\n",
    "                                                random_state = 11)\n",
    "\n",
    "    x_eval ,x_test ,y_eval , y_test = train_test_split(x , y , \n",
    "                                                        test_size = 0.5 , \n",
    "                                                        random_state = 11)\n",
    "\n",
    "    y_train = to_categorical(y_train, num_classes = 3)\n",
    "    y_eval = to_categorical(y_eval, num_classes = 3)\n",
    "    y_test = to_categorical(y_test, num_classes = 3)\n",
    "\n",
    "    #instantiate the model\n",
    "    height = 281\n",
    "    width = 50\n",
    "    classes = 3\n",
    "    channels = 1\n",
    "    epoch = 150\n",
    "    model = CNNbuild(height = height, width = width, classes = classes, channels = channels)\n",
    "    model.summary()\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])\n",
    "\n",
    "    #fit the model onto the dataset\n",
    "    # x_train = np.array (x_train)\n",
    "\n",
    "    h = model.fit(x_train, y_train, epochs = epoch, batch_size = 32,validation_data=(x_eval,y_eval),shuffle=True)\n",
    "\n",
    "    #evaluate the model on test data\n",
    "    predictions = model.evaluate(x_test, y_test)\n",
    "    evaluation = model.evaluate(x_eval, y_eval)\n",
    "\n",
    "    print(f'LOSS : {evaluation[0]}')\n",
    "    print(f'ACCURACY : {evaluation[1]}')\n",
    "    print(f'LOSS : {predictions[0]}')\n",
    "    print(f'ACCURACY : {predictions[1]}')\n",
    "\n",
    "    predict_x=model.predict(x_test) \n",
    "    yhat_classes=np.argmax(predict_x,axis=1)\n",
    "    yhat_classes = to_categorical(yhat_classes, num_classes = 3)\n",
    "\n",
    "    # print(\"Precision Score : \",precision_score(y_test, y_pred, \n",
    "    #                                            pos_label='positive'\n",
    "    #                                            average='micro'))\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = accuracy_score(y_test, yhat_classes)\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "    totalaccuracy.append(accuracy)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(y_test, yhat_classes, average='macro')\n",
    "    print('Precision: %f' % precision)\n",
    "    totalprecision.append(precision)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(y_test, yhat_classes, average='macro')\n",
    "    print('Recall: %f' % recall)\n",
    "    totalrecall.append(recall)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(y_test, yhat_classes, average='macro')\n",
    "    print('F1 score: %f' % f1)\n",
    "    totalf1.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dfb098",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 20)\n",
    "print(\"rata-rata Akurasi: \",sum(totalaccuracy)/len(totalaccuracy))\n",
    "print(\"rata-rata Presisi: \",sum(totalprecision)/len(totalprecision))\n",
    "print(\"rata-rata Recall: \",sum(totalrecall)/len(totalrecall))\n",
    "print(\"rata-rata F1: \",sum(totalf1)/len(totalf1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afe1265",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (18,8))\n",
    "plt.plot(range(epoch), h.history['loss'], label = 'Taining Loss')\n",
    "plt.plot(range(epoch), h.history['val_loss'], label = 'Validation Loss')\n",
    "plt.xlabel(\"Number of Epoch's\")\n",
    "plt.ylabel('Loss Value')\n",
    "plt.title('Training Training & Validation Loss')\n",
    "plt.legend(loc = \"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea332d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (18,8))\n",
    "plt.plot(range(epoch), h.history['accuracy'], label = 'Taining Accuracy')\n",
    "plt.plot(range(epoch), h.history['val_accuracy'], label = 'Validation Accuracy')\n",
    "plt.xlabel(\"Number of Epoch's\")\n",
    "plt.ylabel('Loss Value')\n",
    "plt.title('Training Training & Validation Loss')\n",
    "plt.legend(loc = \"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b605ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
