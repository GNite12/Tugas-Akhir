{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5b7668d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from keras.utils import to_categorical\n",
    "import pywt\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a2d1d4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "penghuni = os.listdir(\"C:\\\\Users\\\\muham\\\\OneDrive\\\\Documents\\\\TA\\\\images\\\\train\\\\Penghuni\")\n",
    "temen1 = os.listdir(\"C:\\\\Users\\\\muham\\\\OneDrive\\\\Documents\\\\TA\\\\images\\\\train\\\\Temen1\")\n",
    "bkn_penghuni = os.listdir(\"C:\\\\Users\\\\muham\\\\OneDrive\\\\Documents\\\\TA\\\\images\\\\train\\\\BukanPenghuni\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "77d69f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "totalaccuracy = []\n",
    "totalprecision = []\n",
    "totalrecall = []\n",
    "totalf1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "03b5bfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNNbuild(height, width, classes, channels):\n",
    "    model = Sequential()\n",
    "    \n",
    "    inputShape = (height, width, channels,)\n",
    "    chanDim = -1\n",
    "    \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        inputShape = (channels, height, width)\n",
    "    model.add(Conv2D(32, (3,3), activation = 'relu', input_shape = inputShape))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(512, activation = 'relu'))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(classes, activation = 'softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a02a10e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalcFeatures(img, th):\n",
    "    sift = cv2.xfeatures2d.SIFT_create(th)\n",
    "    kp, des = sift.detectAndCompute(img, None)\n",
    "    return des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9cfa7112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_features(features, centres, k = 500):\n",
    "    vec = np.zeros((1, k))\n",
    "    for i in range(features.shape[0]):\n",
    "        feat = features[i]\n",
    "        diff = np.tile(feat, (k, 1)) - centres\n",
    "        dist = pow(((pow(diff, 2)).sum(axis = 1)), 0.5)\n",
    "        idx_dist = dist.argsort()\n",
    "        idx = idx_dist[0]\n",
    "        vec[0][idx] += 1\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a80480b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b425dc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in penghuni:\n",
    "\n",
    "    image = cv2.imread(\"C:\\\\Users\\\\muham\\\\OneDrive\\\\Documents\\\\TA\\\\images\\\\train\\\\penghuni\\\\\"+i, 0)\n",
    "    \n",
    "    dim = (50, 50)\n",
    "    # image_array = Image.fromarray(image , 'RGB')\n",
    "    resize_img = cv2.resize(image, dim)\n",
    "    # resize_img = image_array.resize((50 , 50))\n",
    "\n",
    "    # Canny Edge Detection\n",
    "    edges = cv2.Canny(image=resize_img, threshold1=100, threshold2=200) # Canny Edge Detection\n",
    "    # resize_img = image_array.resize((50 , 50))\n",
    "    \n",
    "    resize_img = np.float32(resize_img) / 255.0\n",
    "    \n",
    "    # Calculate gradient \n",
    "    gx = cv2.Sobel(resize_img, cv2.CV_32F, 1, 0, ksize=1)\n",
    "    gy = cv2.Sobel(resize_img, cv2.CV_32F, 0, 1, ksize=1)\n",
    "    mag, angle = cv2.cartToPolar(gx, gy, angleInDegrees=True)\n",
    "    \n",
    "    # print(len(edges))\n",
    "\n",
    "    a = np.array(edges)\n",
    "    b = np.array(mag)\n",
    "    ab = np.concatenate((a, b), axis=0)\n",
    "    c = np.array(angle)\n",
    "    abc = np.concatenate((ab, c), axis=0)\n",
    "    d = np.array(gx)\n",
    "    abcd = np.concatenate((abc, d), axis=0)\n",
    "    e = np.array(gy)\n",
    "    abcde = np.concatenate((abcd, e), axis=0)\n",
    "    # print(len(abcde))\n",
    "    # data.append(np.array(edges))\n",
    "    data.append(np.array(abcde))\n",
    "    labels.append(0)\n",
    "\n",
    "#     print(len(descriptors))\n",
    "\n",
    "for u in bkn_penghuni:\n",
    "    \n",
    "    image = cv2.imread(\"C:\\\\Users\\\\muham\\\\OneDrive\\\\Documents\\\\TA\\\\images\\\\train\\\\BukanPenghuni\\\\\"+u, 0)\n",
    "    \n",
    "\n",
    "    dim = (50, 50)\n",
    "    # image_array = Image.fromarray(image , 'RGB')\n",
    "    resize_img = cv2.resize(image, dim)\n",
    "    # resize_img = image_array.resize((50 , 50))\n",
    "\n",
    "    # Canny Edge Detection\n",
    "    edges = cv2.Canny(image=resize_img, threshold1=100, threshold2=200) # Canny Edge Detection\n",
    "    # resize_img = image_array.resize((50 , 50))\n",
    "    \n",
    "    resize_img = np.float32(resize_img) / 255.0\n",
    "    \n",
    "    # Calculate gradient \n",
    "    gx = cv2.Sobel(resize_img, cv2.CV_32F, 1, 0, ksize=1)\n",
    "    gy = cv2.Sobel(resize_img, cv2.CV_32F, 0, 1, ksize=1)\n",
    "    mag, angle = cv2.cartToPolar(gx, gy, angleInDegrees=True)\n",
    "    \n",
    "    # print(len(edges))\n",
    "\n",
    "    a = np.array(edges)\n",
    "    b = np.array(mag)\n",
    "    ab = np.concatenate((a, b), axis=0)\n",
    "    c = np.array(angle)\n",
    "    abc = np.concatenate((ab, c), axis=0)\n",
    "    d = np.array(gx)\n",
    "    abcd = np.concatenate((abc, d), axis=0)\n",
    "    e = np.array(gy)\n",
    "    abcde = np.concatenate((abcd, e), axis=0)\n",
    "    # print(len(abcde))\n",
    "    # data.append(np.array(edges))\n",
    "    data.append(np.array(abcde))\n",
    "    labels.append(1)\n",
    "\n",
    "for j in temen1:\n",
    "    \n",
    "    image = cv2.imread(\"C:\\\\Users\\\\muham\\\\OneDrive\\\\Documents\\\\TA\\\\images\\\\train\\\\Temen1\\\\\"+j, 0)\n",
    "    \n",
    "\n",
    "    dim = (50, 50)\n",
    "    # image_array = Image.fromarray(image , 'RGB')\n",
    "    resize_img = cv2.resize(image, dim)\n",
    "    # resize_img = image_array.resize((50 , 50))\n",
    "\n",
    "    # Canny Edge Detection\n",
    "    edges = cv2.Canny(image=resize_img, threshold1=100, threshold2=200) # Canny Edge Detection\n",
    "    # resize_img = image_array.resize((50 , 50))\n",
    "    \n",
    "    resize_img = np.float32(resize_img) / 255.0\n",
    "    \n",
    "    # Calculate gradient \n",
    "    gx = cv2.Sobel(resize_img, cv2.CV_32F, 1, 0, ksize=1)\n",
    "    gy = cv2.Sobel(resize_img, cv2.CV_32F, 0, 1, ksize=1)\n",
    "    mag, angle = cv2.cartToPolar(gx, gy, angleInDegrees=True)\n",
    "    \n",
    "    # print(len(edges))\n",
    "\n",
    "    a = np.array(edges)\n",
    "    b = np.array(mag)\n",
    "    ab = np.concatenate((a, b), axis=0)\n",
    "    c = np.array(angle)\n",
    "    abc = np.concatenate((ab, c), axis=0)\n",
    "    d = np.array(gx)\n",
    "    abcd = np.concatenate((abc, d), axis=0)\n",
    "    e = np.array(gy)\n",
    "    abcde = np.concatenate((abcd, e), axis=0)\n",
    "    # print(len(abcde))\n",
    "    # data.append(np.array(edges))\n",
    "    data.append(np.array(abcde))\n",
    "    labels.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2b20a73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = np.array(data, dtype=object)\n",
    "labels = np.array(labels)\n",
    "\n",
    "np.save('Cells' , cells)\n",
    "np.save('Labels' , labels)\n",
    "\n",
    "n = np.arange(cells.shape[0])\n",
    "np.random.shuffle(n)\n",
    "cells = cells[n]\n",
    "labels = labels[n]\n",
    "\n",
    "cells = cells.astype(np.float32)\n",
    "# cells = np.reshape(cells, (274,50,50,1))\n",
    "labels = labels.astype(np.int32)\n",
    "cells = cells/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9e3dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:1, Train set: 368, Test set:93\n",
      "====================\n",
      "Fold:  1\n",
      "====================\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_27 (Conv2D)          (None, 248, 48, 32)       320       \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPooli  (None, 124, 24, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_36 (Ba  (None, 124, 24, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 124, 24, 32)       0         \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 122, 22, 32)       9248      \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPooli  (None, 61, 11, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_37 (Ba  (None, 61, 11, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 61, 11, 32)        0         \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 59, 9, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPooli  (None, 29, 4, 32)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_38 (Ba  (None, 29, 4, 32)         128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 29, 4, 32)         0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 3712)              0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 512)               1901056   \n",
      "                                                                 \n",
      " batch_normalization_39 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1923843 (7.34 MB)\n",
      "Trainable params: 1922627 (7.33 MB)\n",
      "Non-trainable params: 1216 (4.75 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/75\n",
      "10/10 [==============================] - 6s 344ms/step - loss: 1.5170 - accuracy: 0.5272 - val_loss: 0.9603 - val_accuracy: 0.5135\n",
      "Epoch 2/75\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 1.1197 - accuracy: 0.6122 - val_loss: 1.1865 - val_accuracy: 0.5135\n",
      "Epoch 3/75\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.8412 - accuracy: 0.7041 - val_loss: 1.6063 - val_accuracy: 0.5135\n",
      "Epoch 4/75\n",
      "10/10 [==============================] - 3s 317ms/step - loss: 0.6790 - accuracy: 0.7449 - val_loss: 2.0263 - val_accuracy: 0.5135\n",
      "Epoch 5/75\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.6169 - accuracy: 0.7449 - val_loss: 2.5088 - val_accuracy: 0.5135\n",
      "Epoch 6/75\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.6048 - accuracy: 0.7483 - val_loss: 2.8315 - val_accuracy: 0.5135\n",
      "Epoch 7/75\n",
      "10/10 [==============================] - 3s 318ms/step - loss: 0.6794 - accuracy: 0.7823 - val_loss: 3.2879 - val_accuracy: 0.5135\n",
      "Epoch 8/75\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.5538 - accuracy: 0.7687 - val_loss: 3.6987 - val_accuracy: 0.5135\n",
      "Epoch 9/75\n",
      "10/10 [==============================] - 4s 356ms/step - loss: 0.6489 - accuracy: 0.7755 - val_loss: 3.8869 - val_accuracy: 0.5135\n",
      "Epoch 10/75\n",
      "10/10 [==============================] - 3s 336ms/step - loss: 0.5071 - accuracy: 0.8027 - val_loss: 3.8486 - val_accuracy: 0.5135\n",
      "Epoch 11/75\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.4386 - accuracy: 0.8367 - val_loss: 3.9466 - val_accuracy: 0.5135\n",
      "Epoch 12/75\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.3954 - accuracy: 0.8231 - val_loss: 4.3281 - val_accuracy: 0.5135\n",
      "Epoch 13/75\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.4612 - accuracy: 0.8197 - val_loss: 4.4924 - val_accuracy: 0.5135\n",
      "Epoch 14/75\n",
      "10/10 [==============================] - 4s 357ms/step - loss: 0.4321 - accuracy: 0.8197 - val_loss: 4.2312 - val_accuracy: 0.5135\n",
      "Epoch 15/75\n",
      "10/10 [==============================] - 4s 351ms/step - loss: 0.4385 - accuracy: 0.8299 - val_loss: 4.1290 - val_accuracy: 0.5135\n",
      "Epoch 16/75\n",
      "10/10 [==============================] - 4s 361ms/step - loss: 0.4067 - accuracy: 0.8605 - val_loss: 4.0818 - val_accuracy: 0.5135\n",
      "Epoch 17/75\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 0.3289 - accuracy: 0.8571 - val_loss: 3.9990 - val_accuracy: 0.5135\n",
      "Epoch 18/75\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 0.2905 - accuracy: 0.8878 - val_loss: 4.1068 - val_accuracy: 0.5135\n",
      "Epoch 19/75\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 0.3826 - accuracy: 0.8299 - val_loss: 4.1742 - val_accuracy: 0.5135\n",
      "Epoch 20/75\n",
      "10/10 [==============================] - 4s 362ms/step - loss: 0.3829 - accuracy: 0.8537 - val_loss: 4.3167 - val_accuracy: 0.5135\n",
      "Epoch 21/75\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.2549 - accuracy: 0.8878 - val_loss: 4.6619 - val_accuracy: 0.5135\n",
      "Epoch 22/75\n",
      "10/10 [==============================] - 3s 337ms/step - loss: 0.2940 - accuracy: 0.8946 - val_loss: 4.9919 - val_accuracy: 0.5135\n",
      "Epoch 23/75\n",
      "10/10 [==============================] - 3s 338ms/step - loss: 0.2873 - accuracy: 0.8844 - val_loss: 5.1523 - val_accuracy: 0.5135\n",
      "Epoch 24/75\n",
      "10/10 [==============================] - 4s 366ms/step - loss: 0.2542 - accuracy: 0.8912 - val_loss: 5.0347 - val_accuracy: 0.5135\n",
      "Epoch 25/75\n",
      "10/10 [==============================] - 3s 342ms/step - loss: 0.3376 - accuracy: 0.8673 - val_loss: 4.7537 - val_accuracy: 0.5135\n",
      "Epoch 26/75\n",
      "10/10 [==============================] - 4s 365ms/step - loss: 0.2722 - accuracy: 0.8810 - val_loss: 4.2406 - val_accuracy: 0.5135\n",
      "Epoch 27/75\n",
      "10/10 [==============================] - 3s 346ms/step - loss: 0.2724 - accuracy: 0.8810 - val_loss: 4.2316 - val_accuracy: 0.5135\n",
      "Epoch 28/75\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.2587 - accuracy: 0.9014 - val_loss: 3.8156 - val_accuracy: 0.5135\n",
      "Epoch 29/75\n",
      "10/10 [==============================] - 3s 341ms/step - loss: 0.2665 - accuracy: 0.8912 - val_loss: 3.7946 - val_accuracy: 0.5135\n",
      "Epoch 30/75\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.2919 - accuracy: 0.8741 - val_loss: 3.7410 - val_accuracy: 0.5135\n",
      "Epoch 31/75\n",
      "10/10 [==============================] - 3s 341ms/step - loss: 0.3314 - accuracy: 0.8741 - val_loss: 3.8470 - val_accuracy: 0.5135\n",
      "Epoch 32/75\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.2824 - accuracy: 0.8878 - val_loss: 3.8393 - val_accuracy: 0.5135\n",
      "Epoch 33/75\n",
      "10/10 [==============================] - 4s 355ms/step - loss: 0.2728 - accuracy: 0.8810 - val_loss: 3.5377 - val_accuracy: 0.5135\n",
      "Epoch 34/75\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.3108 - accuracy: 0.8844 - val_loss: 3.6532 - val_accuracy: 0.5135\n",
      "Epoch 35/75\n",
      "10/10 [==============================] - 4s 382ms/step - loss: 0.2871 - accuracy: 0.8946 - val_loss: 3.4325 - val_accuracy: 0.5135\n",
      "Epoch 36/75\n",
      "10/10 [==============================] - 4s 354ms/step - loss: 0.2070 - accuracy: 0.9082 - val_loss: 3.4094 - val_accuracy: 0.5135\n",
      "Epoch 37/75\n",
      "10/10 [==============================] - 3s 351ms/step - loss: 0.2297 - accuracy: 0.8946 - val_loss: 3.0815 - val_accuracy: 0.5135\n",
      "Epoch 38/75\n",
      "10/10 [==============================] - 4s 362ms/step - loss: 0.2276 - accuracy: 0.8980 - val_loss: 3.1214 - val_accuracy: 0.5135\n",
      "Epoch 39/75\n",
      "10/10 [==============================] - 4s 394ms/step - loss: 0.2099 - accuracy: 0.8980 - val_loss: 3.0567 - val_accuracy: 0.5135\n",
      "Epoch 40/75\n",
      "10/10 [==============================] - 4s 392ms/step - loss: 0.1787 - accuracy: 0.9252 - val_loss: 2.7989 - val_accuracy: 0.5135\n",
      "Epoch 41/75\n",
      "10/10 [==============================] - 4s 430ms/step - loss: 0.2029 - accuracy: 0.9150 - val_loss: 2.7924 - val_accuracy: 0.5135\n",
      "Epoch 42/75\n",
      "10/10 [==============================] - 4s 376ms/step - loss: 0.2239 - accuracy: 0.8844 - val_loss: 2.5816 - val_accuracy: 0.5135\n",
      "Epoch 43/75\n",
      "10/10 [==============================] - 5s 459ms/step - loss: 0.1681 - accuracy: 0.9252 - val_loss: 2.5527 - val_accuracy: 0.5135\n",
      "Epoch 44/75\n",
      "10/10 [==============================] - 4s 389ms/step - loss: 0.2191 - accuracy: 0.8980 - val_loss: 2.5249 - val_accuracy: 0.5135\n",
      "Epoch 45/75\n",
      "10/10 [==============================] - 4s 381ms/step - loss: 0.2141 - accuracy: 0.8912 - val_loss: 2.7791 - val_accuracy: 0.5135\n",
      "Epoch 46/75\n",
      "10/10 [==============================] - 4s 364ms/step - loss: 0.2107 - accuracy: 0.8912 - val_loss: 2.6734 - val_accuracy: 0.5135\n",
      "Epoch 47/75\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.2124 - accuracy: 0.9218 - val_loss: 2.5948 - val_accuracy: 0.5135\n",
      "Epoch 48/75\n",
      "10/10 [==============================] - 3s 345ms/step - loss: 0.2520 - accuracy: 0.8810 - val_loss: 3.3564 - val_accuracy: 0.5135\n",
      "Epoch 49/75\n",
      "10/10 [==============================] - 3s 337ms/step - loss: 0.2245 - accuracy: 0.9184 - val_loss: 4.1231 - val_accuracy: 0.5135\n",
      "Epoch 50/75\n",
      "10/10 [==============================] - 4s 416ms/step - loss: 0.2196 - accuracy: 0.9150 - val_loss: 5.1563 - val_accuracy: 0.5135\n",
      "Epoch 51/75\n",
      "10/10 [==============================] - 5s 458ms/step - loss: 0.2160 - accuracy: 0.9082 - val_loss: 4.2935 - val_accuracy: 0.5135\n",
      "Epoch 52/75\n",
      "10/10 [==============================] - 4s 425ms/step - loss: 0.1888 - accuracy: 0.9252 - val_loss: 3.4285 - val_accuracy: 0.5135\n",
      "Epoch 53/75\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 0.1644 - accuracy: 0.9320 - val_loss: 2.7089 - val_accuracy: 0.5135\n",
      "Epoch 54/75\n",
      "10/10 [==============================] - 4s 431ms/step - loss: 0.1817 - accuracy: 0.9082 - val_loss: 2.4144 - val_accuracy: 0.5405\n",
      "Epoch 55/75\n",
      "10/10 [==============================] - 4s 440ms/step - loss: 0.2027 - accuracy: 0.9048 - val_loss: 2.1416 - val_accuracy: 0.5135\n",
      "Epoch 56/75\n",
      "10/10 [==============================] - 5s 520ms/step - loss: 0.2246 - accuracy: 0.9150 - val_loss: 1.8893 - val_accuracy: 0.5405\n",
      "Epoch 57/75\n",
      "10/10 [==============================] - 5s 471ms/step - loss: 0.1905 - accuracy: 0.9150 - val_loss: 1.5312 - val_accuracy: 0.5946\n",
      "Epoch 58/75\n",
      "10/10 [==============================] - 5s 456ms/step - loss: 0.1980 - accuracy: 0.9082 - val_loss: 1.6501 - val_accuracy: 0.5405\n",
      "Epoch 59/75\n",
      "10/10 [==============================] - 4s 394ms/step - loss: 0.2066 - accuracy: 0.9116 - val_loss: 1.5474 - val_accuracy: 0.5676\n",
      "Epoch 60/75\n",
      "10/10 [==============================] - 4s 450ms/step - loss: 0.1744 - accuracy: 0.9320 - val_loss: 1.3700 - val_accuracy: 0.5946\n",
      "Epoch 61/75\n",
      "10/10 [==============================] - 5s 462ms/step - loss: 0.2547 - accuracy: 0.9014 - val_loss: 1.4606 - val_accuracy: 0.5676\n",
      "Epoch 62/75\n",
      "10/10 [==============================] - 4s 434ms/step - loss: 0.2047 - accuracy: 0.9014 - val_loss: 1.4906 - val_accuracy: 0.6216\n",
      "Epoch 63/75\n",
      "10/10 [==============================] - 4s 443ms/step - loss: 0.2026 - accuracy: 0.8946 - val_loss: 1.4298 - val_accuracy: 0.5946\n",
      "Epoch 64/75\n",
      "10/10 [==============================] - 5s 478ms/step - loss: 0.1556 - accuracy: 0.9422 - val_loss: 1.3647 - val_accuracy: 0.5946\n",
      "Epoch 65/75\n",
      "10/10 [==============================] - 4s 415ms/step - loss: 0.1914 - accuracy: 0.9048 - val_loss: 1.1785 - val_accuracy: 0.6216\n",
      "Epoch 66/75\n",
      "10/10 [==============================] - 4s 397ms/step - loss: 0.1639 - accuracy: 0.9116 - val_loss: 1.2521 - val_accuracy: 0.6216\n",
      "Epoch 67/75\n",
      "10/10 [==============================] - 4s 431ms/step - loss: 0.2081 - accuracy: 0.8980 - val_loss: 1.3479 - val_accuracy: 0.6486\n",
      "Epoch 68/75\n",
      "10/10 [==============================] - 4s 395ms/step - loss: 0.2279 - accuracy: 0.9048 - val_loss: 1.3146 - val_accuracy: 0.6486\n",
      "Epoch 69/75\n",
      "10/10 [==============================] - 4s 410ms/step - loss: 0.1693 - accuracy: 0.9116 - val_loss: 1.2748 - val_accuracy: 0.6216\n",
      "Epoch 70/75\n",
      "10/10 [==============================] - 4s 395ms/step - loss: 0.1593 - accuracy: 0.9116 - val_loss: 1.2930 - val_accuracy: 0.6216\n",
      "Epoch 71/75\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 0.1695 - accuracy: 0.9320 - val_loss: 1.3100 - val_accuracy: 0.6486\n",
      "Epoch 72/75\n",
      "10/10 [==============================] - 4s 395ms/step - loss: 0.1683 - accuracy: 0.9320 - val_loss: 1.2028 - val_accuracy: 0.7027\n",
      "Epoch 73/75\n",
      "10/10 [==============================] - 4s 400ms/step - loss: 0.1888 - accuracy: 0.9184 - val_loss: 1.3087 - val_accuracy: 0.6757\n",
      "Epoch 74/75\n",
      "10/10 [==============================] - 4s 423ms/step - loss: 0.1633 - accuracy: 0.9218 - val_loss: 1.3014 - val_accuracy: 0.6486\n",
      "Epoch 75/75\n",
      "10/10 [==============================] - 4s 406ms/step - loss: 0.1667 - accuracy: 0.9150 - val_loss: 1.2552 - val_accuracy: 0.6486\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.4409 - accuracy: 0.5946\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2552 - accuracy: 0.6486\n",
      "LOSS : 1.2552286386489868\n",
      "ACCURACY : 0.6486486196517944\n",
      "LOSS : 1.4409092664718628\n",
      "ACCURACY : 0.5945945978164673\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001E8CAEB24C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 26ms/step\n",
      "Accuracy: 0.594595\n",
      "Precision: 0.677778\n",
      "Recall: 0.599567\n",
      "F1 score: 0.605128\n",
      "Fold:2, Train set: 369, Test set:92\n",
      "====================\n",
      "Fold:  2\n",
      "====================\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_30 (Conv2D)          (None, 248, 48, 32)       320       \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPooli  (None, 124, 24, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_40 (Ba  (None, 124, 24, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 124, 24, 32)       0         \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 122, 22, 32)       9248      \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPooli  (None, 61, 11, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_41 (Ba  (None, 61, 11, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 61, 11, 32)        0         \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 59, 9, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPooli  (None, 29, 4, 32)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_42 (Ba  (None, 29, 4, 32)         128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 29, 4, 32)         0         \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 3712)              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 512)               1901056   \n",
      "                                                                 \n",
      " batch_normalization_43 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1923843 (7.34 MB)\n",
      "Trainable params: 1922627 (7.33 MB)\n",
      "Non-trainable params: 1216 (4.75 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/75\n",
      "10/10 [==============================] - 8s 497ms/step - loss: 1.5043 - accuracy: 0.4847 - val_loss: 1.0078 - val_accuracy: 0.5676\n",
      "Epoch 2/75\n",
      "10/10 [==============================] - 5s 505ms/step - loss: 1.0947 - accuracy: 0.5729 - val_loss: 0.9287 - val_accuracy: 0.5405\n",
      "Epoch 3/75\n",
      "10/10 [==============================] - 5s 467ms/step - loss: 1.0008 - accuracy: 0.6441 - val_loss: 1.0001 - val_accuracy: 0.5405\n",
      "Epoch 4/75\n",
      "10/10 [==============================] - 5s 462ms/step - loss: 0.7329 - accuracy: 0.7424 - val_loss: 1.0895 - val_accuracy: 0.5405\n",
      "Epoch 5/75\n",
      "10/10 [==============================] - 4s 439ms/step - loss: 0.6564 - accuracy: 0.7525 - val_loss: 1.1158 - val_accuracy: 0.5405\n",
      "Epoch 6/75\n",
      "10/10 [==============================] - 4s 408ms/step - loss: 0.6994 - accuracy: 0.7593 - val_loss: 1.0946 - val_accuracy: 0.5405\n",
      "Epoch 7/75\n",
      "10/10 [==============================] - 4s 411ms/step - loss: 0.5375 - accuracy: 0.7966 - val_loss: 1.1959 - val_accuracy: 0.5405\n",
      "Epoch 8/75\n",
      "10/10 [==============================] - 4s 404ms/step - loss: 0.5487 - accuracy: 0.8000 - val_loss: 1.4162 - val_accuracy: 0.5405\n",
      "Epoch 9/75\n",
      "10/10 [==============================] - 4s 404ms/step - loss: 0.4642 - accuracy: 0.8339 - val_loss: 1.8253 - val_accuracy: 0.5405\n",
      "Epoch 10/75\n",
      "10/10 [==============================] - 4s 401ms/step - loss: 0.4798 - accuracy: 0.8068 - val_loss: 1.9945 - val_accuracy: 0.5405\n",
      "Epoch 11/75\n",
      "10/10 [==============================] - 4s 401ms/step - loss: 0.5351 - accuracy: 0.8000 - val_loss: 2.1688 - val_accuracy: 0.5405\n",
      "Epoch 12/75\n",
      "10/10 [==============================] - 4s 410ms/step - loss: 0.4023 - accuracy: 0.8339 - val_loss: 2.1962 - val_accuracy: 0.5405\n",
      "Epoch 13/75\n",
      "10/10 [==============================] - 4s 407ms/step - loss: 0.4468 - accuracy: 0.8305 - val_loss: 1.8349 - val_accuracy: 0.5405\n",
      "Epoch 14/75\n",
      "10/10 [==============================] - 4s 410ms/step - loss: 0.3475 - accuracy: 0.8746 - val_loss: 1.3102 - val_accuracy: 0.5405\n",
      "Epoch 15/75\n",
      "10/10 [==============================] - 4s 397ms/step - loss: 0.4316 - accuracy: 0.8339 - val_loss: 1.0908 - val_accuracy: 0.5405\n",
      "Epoch 16/75\n",
      "10/10 [==============================] - 4s 411ms/step - loss: 0.3605 - accuracy: 0.8542 - val_loss: 0.9776 - val_accuracy: 0.5405\n",
      "Epoch 17/75\n",
      "10/10 [==============================] - 4s 416ms/step - loss: 0.3163 - accuracy: 0.8746 - val_loss: 1.0961 - val_accuracy: 0.5405\n",
      "Epoch 18/75\n",
      "10/10 [==============================] - 4s 409ms/step - loss: 0.4453 - accuracy: 0.8237 - val_loss: 0.9408 - val_accuracy: 0.5405\n",
      "Epoch 19/75\n",
      "10/10 [==============================] - 4s 429ms/step - loss: 0.4475 - accuracy: 0.8339 - val_loss: 0.9574 - val_accuracy: 0.5405\n",
      "Epoch 20/75\n",
      "10/10 [==============================] - 4s 436ms/step - loss: 0.3843 - accuracy: 0.8373 - val_loss: 0.9639 - val_accuracy: 0.5405\n",
      "Epoch 21/75\n",
      "10/10 [==============================] - 4s 402ms/step - loss: 0.3881 - accuracy: 0.8441 - val_loss: 0.9783 - val_accuracy: 0.5405\n",
      "Epoch 22/75\n",
      "10/10 [==============================] - 4s 413ms/step - loss: 0.3261 - accuracy: 0.8746 - val_loss: 1.2533 - val_accuracy: 0.5405\n",
      "Epoch 23/75\n",
      "10/10 [==============================] - 4s 408ms/step - loss: 0.3140 - accuracy: 0.8610 - val_loss: 0.9848 - val_accuracy: 0.5405\n",
      "Epoch 24/75\n",
      "10/10 [==============================] - 4s 417ms/step - loss: 0.2426 - accuracy: 0.8949 - val_loss: 0.9107 - val_accuracy: 0.5676\n",
      "Epoch 25/75\n",
      "10/10 [==============================] - 4s 426ms/step - loss: 0.3171 - accuracy: 0.8610 - val_loss: 0.8600 - val_accuracy: 0.7027\n",
      "Epoch 26/75\n",
      "10/10 [==============================] - 4s 404ms/step - loss: 0.2785 - accuracy: 0.8746 - val_loss: 0.9845 - val_accuracy: 0.7027\n",
      "Epoch 27/75\n",
      "10/10 [==============================] - 4s 407ms/step - loss: 0.3672 - accuracy: 0.8542 - val_loss: 1.0173 - val_accuracy: 0.7568\n",
      "Epoch 28/75\n",
      "10/10 [==============================] - 4s 411ms/step - loss: 0.2573 - accuracy: 0.8983 - val_loss: 1.0252 - val_accuracy: 0.7568\n",
      "Epoch 29/75\n",
      "10/10 [==============================] - 5s 465ms/step - loss: 0.1992 - accuracy: 0.9220 - val_loss: 1.0255 - val_accuracy: 0.7027\n",
      "Epoch 30/75\n",
      "10/10 [==============================] - 5s 489ms/step - loss: 0.2202 - accuracy: 0.9119 - val_loss: 1.0492 - val_accuracy: 0.7297\n",
      "Epoch 31/75\n",
      "10/10 [==============================] - 4s 417ms/step - loss: 0.2362 - accuracy: 0.8983 - val_loss: 0.9906 - val_accuracy: 0.7027\n",
      "Epoch 32/75\n",
      "10/10 [==============================] - 4s 407ms/step - loss: 0.2004 - accuracy: 0.9017 - val_loss: 0.8979 - val_accuracy: 0.7297\n",
      "Epoch 33/75\n",
      "10/10 [==============================] - 4s 401ms/step - loss: 0.2097 - accuracy: 0.8881 - val_loss: 0.8079 - val_accuracy: 0.7297\n",
      "Epoch 34/75\n",
      "10/10 [==============================] - 4s 404ms/step - loss: 0.2157 - accuracy: 0.8983 - val_loss: 0.7502 - val_accuracy: 0.7297\n",
      "Epoch 35/75\n",
      "10/10 [==============================] - 4s 413ms/step - loss: 0.2335 - accuracy: 0.9085 - val_loss: 0.7435 - val_accuracy: 0.7027\n",
      "Epoch 36/75\n",
      "10/10 [==============================] - 4s 430ms/step - loss: 0.1943 - accuracy: 0.9119 - val_loss: 0.8972 - val_accuracy: 0.6486\n",
      "Epoch 37/75\n",
      "10/10 [==============================] - 4s 415ms/step - loss: 0.3013 - accuracy: 0.8712 - val_loss: 0.7911 - val_accuracy: 0.7027\n",
      "Epoch 38/75\n",
      "10/10 [==============================] - 4s 406ms/step - loss: 0.2247 - accuracy: 0.9186 - val_loss: 0.7785 - val_accuracy: 0.7297\n",
      "Epoch 39/75\n",
      "10/10 [==============================] - 4s 405ms/step - loss: 0.2416 - accuracy: 0.8847 - val_loss: 0.7426 - val_accuracy: 0.7568\n",
      "Epoch 40/75\n",
      "10/10 [==============================] - 4s 397ms/step - loss: 0.2021 - accuracy: 0.9153 - val_loss: 0.6970 - val_accuracy: 0.7297\n",
      "Epoch 41/75\n",
      "10/10 [==============================] - 4s 413ms/step - loss: 0.2176 - accuracy: 0.9051 - val_loss: 0.6841 - val_accuracy: 0.7297\n",
      "Epoch 42/75\n",
      "10/10 [==============================] - 4s 427ms/step - loss: 0.1620 - accuracy: 0.9153 - val_loss: 0.9660 - val_accuracy: 0.7297\n",
      "Epoch 43/75\n",
      "10/10 [==============================] - 4s 407ms/step - loss: 0.2605 - accuracy: 0.9017 - val_loss: 1.3806 - val_accuracy: 0.7297\n",
      "Epoch 44/75\n",
      "10/10 [==============================] - 4s 404ms/step - loss: 0.1945 - accuracy: 0.9186 - val_loss: 1.4449 - val_accuracy: 0.7297\n",
      "Epoch 45/75\n",
      "10/10 [==============================] - 4s 395ms/step - loss: 0.2163 - accuracy: 0.8949 - val_loss: 1.1065 - val_accuracy: 0.7297\n",
      "Epoch 46/75\n",
      "10/10 [==============================] - 4s 410ms/step - loss: 0.1920 - accuracy: 0.9220 - val_loss: 0.9976 - val_accuracy: 0.7568\n",
      "Epoch 47/75\n",
      "10/10 [==============================] - 4s 430ms/step - loss: 0.1968 - accuracy: 0.9153 - val_loss: 1.1386 - val_accuracy: 0.7568\n",
      "Epoch 48/75\n",
      "10/10 [==============================] - 4s 413ms/step - loss: 0.2139 - accuracy: 0.8983 - val_loss: 0.7804 - val_accuracy: 0.7568\n",
      "Epoch 49/75\n",
      "10/10 [==============================] - 4s 412ms/step - loss: 0.1894 - accuracy: 0.9085 - val_loss: 0.8062 - val_accuracy: 0.7838\n",
      "Epoch 50/75\n",
      "10/10 [==============================] - 4s 400ms/step - loss: 0.2067 - accuracy: 0.8949 - val_loss: 0.8215 - val_accuracy: 0.8108\n",
      "Epoch 51/75\n",
      "10/10 [==============================] - 4s 410ms/step - loss: 0.2059 - accuracy: 0.9017 - val_loss: 0.7644 - val_accuracy: 0.7568\n",
      "Epoch 52/75\n",
      "10/10 [==============================] - 4s 436ms/step - loss: 0.1688 - accuracy: 0.9220 - val_loss: 0.7889 - val_accuracy: 0.7568\n",
      "Epoch 53/75\n",
      "10/10 [==============================] - 4s 433ms/step - loss: 0.2297 - accuracy: 0.8983 - val_loss: 0.7951 - val_accuracy: 0.6757\n",
      "Epoch 54/75\n",
      "10/10 [==============================] - 4s 436ms/step - loss: 0.1900 - accuracy: 0.9186 - val_loss: 0.8008 - val_accuracy: 0.6757\n",
      "Epoch 55/75\n",
      "10/10 [==============================] - 4s 430ms/step - loss: 0.1611 - accuracy: 0.9220 - val_loss: 0.8174 - val_accuracy: 0.7297\n",
      "Epoch 56/75\n",
      "10/10 [==============================] - 4s 426ms/step - loss: 0.1854 - accuracy: 0.9153 - val_loss: 0.8319 - val_accuracy: 0.7568\n",
      "Epoch 57/75\n",
      "10/10 [==============================] - 4s 413ms/step - loss: 0.2223 - accuracy: 0.8983 - val_loss: 0.8234 - val_accuracy: 0.6486\n",
      "Epoch 58/75\n",
      "10/10 [==============================] - 4s 425ms/step - loss: 0.1428 - accuracy: 0.9458 - val_loss: 0.8940 - val_accuracy: 0.6757\n",
      "Epoch 59/75\n",
      "10/10 [==============================] - 4s 424ms/step - loss: 0.1797 - accuracy: 0.9288 - val_loss: 0.8964 - val_accuracy: 0.6216\n",
      "Epoch 60/75\n",
      "10/10 [==============================] - 4s 427ms/step - loss: 0.1908 - accuracy: 0.9220 - val_loss: 0.9242 - val_accuracy: 0.6216\n",
      "Epoch 61/75\n",
      "10/10 [==============================] - 4s 419ms/step - loss: 0.1683 - accuracy: 0.9288 - val_loss: 0.9405 - val_accuracy: 0.5946\n",
      "Epoch 62/75\n",
      "10/10 [==============================] - 4s 449ms/step - loss: 0.1863 - accuracy: 0.9186 - val_loss: 1.0295 - val_accuracy: 0.5676\n",
      "Epoch 63/75\n",
      "10/10 [==============================] - 4s 420ms/step - loss: 0.2034 - accuracy: 0.9085 - val_loss: 1.1782 - val_accuracy: 0.5946\n",
      "Epoch 64/75\n",
      "10/10 [==============================] - 4s 400ms/step - loss: 0.1979 - accuracy: 0.9119 - val_loss: 1.1428 - val_accuracy: 0.5676\n",
      "Epoch 65/75\n",
      "10/10 [==============================] - 4s 413ms/step - loss: 0.1628 - accuracy: 0.9288 - val_loss: 0.9986 - val_accuracy: 0.5676\n",
      "Epoch 66/75\n",
      "10/10 [==============================] - 4s 426ms/step - loss: 0.1388 - accuracy: 0.9525 - val_loss: 1.0832 - val_accuracy: 0.6216\n",
      "Epoch 67/75\n",
      "10/10 [==============================] - 4s 408ms/step - loss: 0.1902 - accuracy: 0.9186 - val_loss: 0.9670 - val_accuracy: 0.6486\n",
      "Epoch 68/75\n",
      "10/10 [==============================] - 4s 417ms/step - loss: 0.1890 - accuracy: 0.9119 - val_loss: 0.9407 - val_accuracy: 0.6757\n",
      "Epoch 69/75\n",
      "10/10 [==============================] - 4s 398ms/step - loss: 0.1550 - accuracy: 0.9220 - val_loss: 0.9206 - val_accuracy: 0.6486\n",
      "Epoch 70/75\n",
      "10/10 [==============================] - 4s 405ms/step - loss: 0.1885 - accuracy: 0.9119 - val_loss: 1.0507 - val_accuracy: 0.6486\n",
      "Epoch 71/75\n",
      "10/10 [==============================] - 4s 411ms/step - loss: 0.1871 - accuracy: 0.9085 - val_loss: 1.1521 - val_accuracy: 0.6757\n",
      "Epoch 72/75\n",
      "10/10 [==============================] - 5s 479ms/step - loss: 0.1934 - accuracy: 0.9119 - val_loss: 1.0520 - val_accuracy: 0.6486\n",
      "Epoch 73/75\n",
      "10/10 [==============================] - 4s 414ms/step - loss: 0.1507 - accuracy: 0.9254 - val_loss: 1.0598 - val_accuracy: 0.6486\n",
      "Epoch 74/75\n",
      "10/10 [==============================] - 4s 430ms/step - loss: 0.2145 - accuracy: 0.8949 - val_loss: 1.1125 - val_accuracy: 0.6486\n",
      "Epoch 75/75\n",
      "10/10 [==============================] - 4s 416ms/step - loss: 0.1972 - accuracy: 0.9186 - val_loss: 1.0857 - val_accuracy: 0.6757\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7623 - accuracy: 0.7297\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0857 - accuracy: 0.6757\n",
      "LOSS : 1.08571195602417\n",
      "ACCURACY : 0.6756756901741028\n",
      "LOSS : 0.7623189091682434\n",
      "ACCURACY : 0.7297297120094299\n",
      "2/2 [==============================] - 0s 23ms/step\n",
      "Accuracy: 0.729730\n",
      "Precision: 0.712454\n",
      "Recall: 0.726852\n",
      "F1 score: 0.717661\n",
      "Fold:3, Train set: 369, Test set:92\n",
      "====================\n",
      "Fold:  3\n",
      "====================\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_33 (Conv2D)          (None, 248, 48, 32)       320       \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPooli  (None, 124, 24, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_44 (Ba  (None, 124, 24, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 124, 24, 32)       0         \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 122, 22, 32)       9248      \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPooli  (None, 61, 11, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_45 (Ba  (None, 61, 11, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 61, 11, 32)        0         \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 59, 9, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPooli  (None, 29, 4, 32)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_46 (Ba  (None, 29, 4, 32)         128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 29, 4, 32)         0         \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 3712)              0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 512)               1901056   \n",
      "                                                                 \n",
      " batch_normalization_47 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1923843 (7.34 MB)\n",
      "Trainable params: 1922627 (7.33 MB)\n",
      "Non-trainable params: 1216 (4.75 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/75\n",
      "10/10 [==============================] - 7s 434ms/step - loss: 1.5649 - accuracy: 0.5220 - val_loss: 1.0177 - val_accuracy: 0.4054\n",
      "Epoch 2/75\n",
      "10/10 [==============================] - 4s 440ms/step - loss: 1.1016 - accuracy: 0.5898 - val_loss: 1.1531 - val_accuracy: 0.3784\n",
      "Epoch 3/75\n",
      "10/10 [==============================] - 4s 427ms/step - loss: 0.9169 - accuracy: 0.6576 - val_loss: 1.3226 - val_accuracy: 0.3784\n",
      "Epoch 4/75\n",
      "10/10 [==============================] - 4s 428ms/step - loss: 0.8416 - accuracy: 0.7153 - val_loss: 1.3731 - val_accuracy: 0.3784\n",
      "Epoch 5/75\n",
      "10/10 [==============================] - 5s 500ms/step - loss: 0.6767 - accuracy: 0.7424 - val_loss: 1.0679 - val_accuracy: 0.3784\n",
      "Epoch 6/75\n",
      "10/10 [==============================] - 4s 437ms/step - loss: 0.6113 - accuracy: 0.7492 - val_loss: 1.1358 - val_accuracy: 0.3784\n",
      "Epoch 7/75\n",
      "10/10 [==============================] - 4s 404ms/step - loss: 0.6223 - accuracy: 0.7695 - val_loss: 1.1991 - val_accuracy: 0.3784\n",
      "Epoch 8/75\n",
      "10/10 [==============================] - 4s 446ms/step - loss: 0.6942 - accuracy: 0.7695 - val_loss: 1.3017 - val_accuracy: 0.3784\n",
      "Epoch 9/75\n",
      "10/10 [==============================] - 4s 436ms/step - loss: 0.5645 - accuracy: 0.7797 - val_loss: 1.1751 - val_accuracy: 0.3784\n",
      "Epoch 10/75\n",
      "10/10 [==============================] - 4s 419ms/step - loss: 0.4973 - accuracy: 0.8000 - val_loss: 1.0635 - val_accuracy: 0.3784\n",
      "Epoch 11/75\n",
      "10/10 [==============================] - 4s 426ms/step - loss: 0.4819 - accuracy: 0.8136 - val_loss: 1.0932 - val_accuracy: 0.3784\n",
      "Epoch 12/75\n",
      "10/10 [==============================] - 4s 416ms/step - loss: 0.5016 - accuracy: 0.8373 - val_loss: 1.2134 - val_accuracy: 0.3784\n",
      "Epoch 13/75\n",
      "10/10 [==============================] - 4s 443ms/step - loss: 0.5257 - accuracy: 0.7831 - val_loss: 1.1988 - val_accuracy: 0.3784\n",
      "Epoch 14/75\n",
      "10/10 [==============================] - 4s 423ms/step - loss: 0.3892 - accuracy: 0.8610 - val_loss: 1.4430 - val_accuracy: 0.3784\n",
      "Epoch 15/75\n",
      "10/10 [==============================] - 4s 411ms/step - loss: 0.3469 - accuracy: 0.8542 - val_loss: 1.5810 - val_accuracy: 0.3784\n",
      "Epoch 16/75\n",
      "10/10 [==============================] - 4s 420ms/step - loss: 0.3230 - accuracy: 0.8441 - val_loss: 1.7047 - val_accuracy: 0.3784\n",
      "Epoch 17/75\n",
      "10/10 [==============================] - 4s 422ms/step - loss: 0.3079 - accuracy: 0.8847 - val_loss: 1.7809 - val_accuracy: 0.3784\n",
      "Epoch 18/75\n",
      "10/10 [==============================] - 4s 431ms/step - loss: 0.3166 - accuracy: 0.8644 - val_loss: 1.8086 - val_accuracy: 0.3784\n",
      "Epoch 19/75\n",
      "10/10 [==============================] - 4s 434ms/step - loss: 0.3245 - accuracy: 0.8508 - val_loss: 1.6482 - val_accuracy: 0.3784\n",
      "Epoch 20/75\n",
      "10/10 [==============================] - 4s 417ms/step - loss: 0.3662 - accuracy: 0.8576 - val_loss: 1.9189 - val_accuracy: 0.3784\n",
      "Epoch 21/75\n",
      "10/10 [==============================] - 4s 409ms/step - loss: 0.2913 - accuracy: 0.8712 - val_loss: 1.8049 - val_accuracy: 0.3784\n",
      "Epoch 22/75\n",
      "10/10 [==============================] - 4s 414ms/step - loss: 0.3221 - accuracy: 0.8644 - val_loss: 2.0234 - val_accuracy: 0.3784\n",
      "Epoch 23/75\n",
      "10/10 [==============================] - 4s 430ms/step - loss: 0.3668 - accuracy: 0.8373 - val_loss: 1.6386 - val_accuracy: 0.3784\n",
      "Epoch 24/75\n",
      "10/10 [==============================] - 4s 413ms/step - loss: 0.3212 - accuracy: 0.8542 - val_loss: 1.2617 - val_accuracy: 0.3784\n",
      "Epoch 25/75\n",
      "10/10 [==============================] - 4s 414ms/step - loss: 0.2508 - accuracy: 0.9153 - val_loss: 1.0795 - val_accuracy: 0.4054\n",
      "Epoch 26/75\n",
      "10/10 [==============================] - 4s 410ms/step - loss: 0.2326 - accuracy: 0.9051 - val_loss: 0.9067 - val_accuracy: 0.4054\n",
      "Epoch 27/75\n",
      "10/10 [==============================] - 4s 400ms/step - loss: 0.2311 - accuracy: 0.8780 - val_loss: 0.8860 - val_accuracy: 0.4054\n",
      "Epoch 28/75\n",
      "10/10 [==============================] - 4s 419ms/step - loss: 0.2096 - accuracy: 0.9220 - val_loss: 1.2099 - val_accuracy: 0.3784\n",
      "Epoch 29/75\n",
      "10/10 [==============================] - 4s 413ms/step - loss: 0.2267 - accuracy: 0.9254 - val_loss: 1.1075 - val_accuracy: 0.4054\n",
      "Epoch 30/75\n",
      "10/10 [==============================] - 4s 440ms/step - loss: 0.2824 - accuracy: 0.8847 - val_loss: 0.8285 - val_accuracy: 0.5946\n",
      "Epoch 31/75\n",
      "10/10 [==============================] - 4s 416ms/step - loss: 0.2669 - accuracy: 0.8847 - val_loss: 0.6665 - val_accuracy: 0.7568\n",
      "Epoch 32/75\n",
      "10/10 [==============================] - 4s 405ms/step - loss: 0.2149 - accuracy: 0.9119 - val_loss: 0.5926 - val_accuracy: 0.8378\n",
      "Epoch 33/75\n",
      "10/10 [==============================] - 4s 415ms/step - loss: 0.2040 - accuracy: 0.9254 - val_loss: 0.6145 - val_accuracy: 0.7568\n",
      "Epoch 34/75\n",
      "10/10 [==============================] - 4s 407ms/step - loss: 0.2478 - accuracy: 0.8983 - val_loss: 0.6426 - val_accuracy: 0.7297\n",
      "Epoch 35/75\n",
      "10/10 [==============================] - 4s 427ms/step - loss: 0.2450 - accuracy: 0.8847 - val_loss: 0.9838 - val_accuracy: 0.5676\n",
      "Epoch 36/75\n",
      "10/10 [==============================] - 4s 417ms/step - loss: 0.2322 - accuracy: 0.9051 - val_loss: 0.8989 - val_accuracy: 0.5946\n",
      "Epoch 37/75\n",
      "10/10 [==============================] - 4s 420ms/step - loss: 0.2693 - accuracy: 0.8746 - val_loss: 0.5791 - val_accuracy: 0.7838\n",
      "Epoch 38/75\n",
      "10/10 [==============================] - 4s 407ms/step - loss: 0.2279 - accuracy: 0.9119 - val_loss: 0.7997 - val_accuracy: 0.6486\n",
      "Epoch 39/75\n",
      "10/10 [==============================] - 4s 410ms/step - loss: 0.2445 - accuracy: 0.8814 - val_loss: 1.0932 - val_accuracy: 0.5135\n",
      "Epoch 40/75\n",
      "10/10 [==============================] - 4s 420ms/step - loss: 0.2560 - accuracy: 0.8847 - val_loss: 0.6228 - val_accuracy: 0.7297\n",
      "Epoch 41/75\n",
      "10/10 [==============================] - 4s 416ms/step - loss: 0.2584 - accuracy: 0.8881 - val_loss: 0.7106 - val_accuracy: 0.7297\n",
      "Epoch 42/75\n",
      "10/10 [==============================] - 4s 429ms/step - loss: 0.2789 - accuracy: 0.8814 - val_loss: 2.1563 - val_accuracy: 0.3784\n",
      "Epoch 43/75\n",
      "10/10 [==============================] - 4s 419ms/step - loss: 0.1887 - accuracy: 0.9153 - val_loss: 1.2273 - val_accuracy: 0.4595\n",
      "Epoch 44/75\n",
      "10/10 [==============================] - 4s 411ms/step - loss: 0.2288 - accuracy: 0.9017 - val_loss: 1.5389 - val_accuracy: 0.2703\n",
      "Epoch 45/75\n",
      "10/10 [==============================] - 4s 406ms/step - loss: 0.2346 - accuracy: 0.8983 - val_loss: 0.7761 - val_accuracy: 0.6486\n",
      "Epoch 46/75\n",
      "10/10 [==============================] - 4s 412ms/step - loss: 0.3110 - accuracy: 0.8780 - val_loss: 0.9478 - val_accuracy: 0.5946\n",
      "Epoch 47/75\n",
      "10/10 [==============================] - 4s 425ms/step - loss: 0.2146 - accuracy: 0.9220 - val_loss: 0.7412 - val_accuracy: 0.7027\n",
      "Epoch 48/75\n",
      "10/10 [==============================] - 4s 447ms/step - loss: 0.2603 - accuracy: 0.8780 - val_loss: 0.8696 - val_accuracy: 0.6486\n",
      "Epoch 49/75\n",
      "10/10 [==============================] - 4s 430ms/step - loss: 0.1990 - accuracy: 0.9153 - val_loss: 0.6613 - val_accuracy: 0.7027\n",
      "Epoch 50/75\n",
      "10/10 [==============================] - 4s 427ms/step - loss: 0.2534 - accuracy: 0.8847 - val_loss: 0.7489 - val_accuracy: 0.6486\n",
      "Epoch 51/75\n",
      "10/10 [==============================] - 4s 410ms/step - loss: 0.2145 - accuracy: 0.9085 - val_loss: 1.2434 - val_accuracy: 0.4865\n",
      "Epoch 52/75\n",
      "10/10 [==============================] - 4s 423ms/step - loss: 0.2724 - accuracy: 0.8847 - val_loss: 0.6446 - val_accuracy: 0.6216\n",
      "Epoch 53/75\n",
      "10/10 [==============================] - 4s 419ms/step - loss: 0.2441 - accuracy: 0.8915 - val_loss: 0.5872 - val_accuracy: 0.7027\n",
      "Epoch 54/75\n",
      "10/10 [==============================] - 4s 440ms/step - loss: 0.2211 - accuracy: 0.9017 - val_loss: 0.6659 - val_accuracy: 0.7568\n",
      "Epoch 55/75\n",
      "10/10 [==============================] - 4s 420ms/step - loss: 0.1812 - accuracy: 0.9119 - val_loss: 0.7529 - val_accuracy: 0.7297\n",
      "Epoch 56/75\n",
      "10/10 [==============================] - 4s 419ms/step - loss: 0.2043 - accuracy: 0.9119 - val_loss: 0.6993 - val_accuracy: 0.7297\n",
      "Epoch 57/75\n",
      "10/10 [==============================] - 5s 458ms/step - loss: 0.1745 - accuracy: 0.9254 - val_loss: 0.6355 - val_accuracy: 0.8108\n",
      "Epoch 58/75\n",
      "10/10 [==============================] - 4s 410ms/step - loss: 0.1947 - accuracy: 0.9051 - val_loss: 0.5419 - val_accuracy: 0.7838\n",
      "Epoch 59/75\n",
      "10/10 [==============================] - 4s 436ms/step - loss: 0.1915 - accuracy: 0.8949 - val_loss: 0.5054 - val_accuracy: 0.8378\n",
      "Epoch 60/75\n",
      "10/10 [==============================] - 4s 418ms/step - loss: 0.2172 - accuracy: 0.8881 - val_loss: 0.4562 - val_accuracy: 0.7838\n",
      "Epoch 61/75\n",
      "10/10 [==============================] - 5s 477ms/step - loss: 0.2154 - accuracy: 0.8915 - val_loss: 0.4492 - val_accuracy: 0.7568\n",
      "Epoch 62/75\n",
      "10/10 [==============================] - 5s 498ms/step - loss: 0.1536 - accuracy: 0.9288 - val_loss: 0.4700 - val_accuracy: 0.7297\n",
      "Epoch 63/75\n",
      "10/10 [==============================] - 5s 523ms/step - loss: 0.1824 - accuracy: 0.9288 - val_loss: 0.5566 - val_accuracy: 0.7297\n",
      "Epoch 64/75\n",
      "10/10 [==============================] - 5s 458ms/step - loss: 0.1635 - accuracy: 0.9288 - val_loss: 0.5744 - val_accuracy: 0.7027\n",
      "Epoch 65/75\n",
      "10/10 [==============================] - 5s 496ms/step - loss: 0.1745 - accuracy: 0.9322 - val_loss: 0.5918 - val_accuracy: 0.7027\n",
      "Epoch 66/75\n",
      "10/10 [==============================] - 4s 425ms/step - loss: 0.1461 - accuracy: 0.9254 - val_loss: 0.5184 - val_accuracy: 0.7027\n",
      "Epoch 67/75\n",
      "10/10 [==============================] - 4s 395ms/step - loss: 0.2233 - accuracy: 0.8814 - val_loss: 0.5112 - val_accuracy: 0.7297\n",
      "Epoch 68/75\n",
      "10/10 [==============================] - 4s 416ms/step - loss: 0.2290 - accuracy: 0.9017 - val_loss: 0.4284 - val_accuracy: 0.7568\n",
      "Epoch 69/75\n",
      "10/10 [==============================] - 4s 367ms/step - loss: 0.2029 - accuracy: 0.9017 - val_loss: 0.3711 - val_accuracy: 0.8378\n",
      "Epoch 70/75\n",
      "10/10 [==============================] - 4s 402ms/step - loss: 0.1487 - accuracy: 0.9390 - val_loss: 0.4241 - val_accuracy: 0.8108\n",
      "Epoch 71/75\n",
      "10/10 [==============================] - 4s 363ms/step - loss: 0.1570 - accuracy: 0.9288 - val_loss: 0.4489 - val_accuracy: 0.8378\n",
      "Epoch 72/75\n",
      "10/10 [==============================] - 3s 342ms/step - loss: 0.1800 - accuracy: 0.9186 - val_loss: 0.5006 - val_accuracy: 0.8108\n",
      "Epoch 73/75\n",
      "10/10 [==============================] - 4s 354ms/step - loss: 0.1554 - accuracy: 0.9254 - val_loss: 0.4309 - val_accuracy: 0.8649\n",
      "Epoch 74/75\n",
      "10/10 [==============================] - 4s 357ms/step - loss: 0.1594 - accuracy: 0.9288 - val_loss: 0.4268 - val_accuracy: 0.8649\n",
      "Epoch 75/75\n",
      "10/10 [==============================] - 3s 345ms/step - loss: 0.1339 - accuracy: 0.9390 - val_loss: 0.4217 - val_accuracy: 0.8378\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.6478 - accuracy: 0.8108\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.4217 - accuracy: 0.8378\n",
      "LOSS : 0.42171141505241394\n",
      "ACCURACY : 0.837837815284729\n",
      "LOSS : 0.647819995880127\n",
      "ACCURACY : 0.8108108043670654\n",
      "2/2 [==============================] - 0s 23ms/step\n",
      "Accuracy: 0.810811\n",
      "Precision: 0.744444\n",
      "Recall: 0.738095\n",
      "F1 score: 0.740053\n",
      "Fold:4, Train set: 369, Test set:92\n",
      "====================\n",
      "Fold:  4\n",
      "====================\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_36 (Conv2D)          (None, 248, 48, 32)       320       \n",
      "                                                                 \n",
      " max_pooling2d_36 (MaxPooli  (None, 124, 24, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_48 (Ba  (None, 124, 24, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 124, 24, 32)       0         \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 122, 22, 32)       9248      \n",
      "                                                                 \n",
      " max_pooling2d_37 (MaxPooli  (None, 61, 11, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_49 (Ba  (None, 61, 11, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 61, 11, 32)        0         \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 59, 9, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_38 (MaxPooli  (None, 29, 4, 32)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_50 (Ba  (None, 29, 4, 32)         128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 29, 4, 32)         0         \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 3712)              0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 512)               1901056   \n",
      "                                                                 \n",
      " batch_normalization_51 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1923843 (7.34 MB)\n",
      "Trainable params: 1922627 (7.33 MB)\n",
      "Non-trainable params: 1216 (4.75 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/75\n",
      "10/10 [==============================] - 6s 362ms/step - loss: 1.4955 - accuracy: 0.4847 - val_loss: 1.0133 - val_accuracy: 0.3784\n",
      "Epoch 2/75\n",
      "10/10 [==============================] - 3s 347ms/step - loss: 0.9923 - accuracy: 0.6508 - val_loss: 0.9522 - val_accuracy: 0.5676\n",
      "Epoch 3/75\n",
      "10/10 [==============================] - 4s 359ms/step - loss: 0.9012 - accuracy: 0.6610 - val_loss: 1.0737 - val_accuracy: 0.4865\n",
      "Epoch 4/75\n",
      "10/10 [==============================] - 4s 353ms/step - loss: 0.7240 - accuracy: 0.7254 - val_loss: 1.2902 - val_accuracy: 0.4865\n",
      "Epoch 5/75\n",
      "10/10 [==============================] - 4s 354ms/step - loss: 0.8090 - accuracy: 0.7085 - val_loss: 1.4173 - val_accuracy: 0.4865\n",
      "Epoch 6/75\n",
      "10/10 [==============================] - 3s 343ms/step - loss: 0.7154 - accuracy: 0.7390 - val_loss: 1.5838 - val_accuracy: 0.4865\n",
      "Epoch 7/75\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 0.6097 - accuracy: 0.7695 - val_loss: 1.6169 - val_accuracy: 0.4865\n",
      "Epoch 8/75\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 0.6026 - accuracy: 0.7966 - val_loss: 1.8051 - val_accuracy: 0.4865\n",
      "Epoch 9/75\n",
      "10/10 [==============================] - 3s 340ms/step - loss: 0.4550 - accuracy: 0.8305 - val_loss: 2.1439 - val_accuracy: 0.4865\n",
      "Epoch 10/75\n",
      "10/10 [==============================] - 3s 342ms/step - loss: 0.5021 - accuracy: 0.8339 - val_loss: 1.8949 - val_accuracy: 0.4865\n",
      "Epoch 11/75\n",
      "10/10 [==============================] - 4s 352ms/step - loss: 0.5106 - accuracy: 0.8169 - val_loss: 1.6155 - val_accuracy: 0.4865\n",
      "Epoch 12/75\n",
      "10/10 [==============================] - 4s 366ms/step - loss: 0.4769 - accuracy: 0.8339 - val_loss: 1.6908 - val_accuracy: 0.4865\n",
      "Epoch 13/75\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 0.4376 - accuracy: 0.8475 - val_loss: 1.4973 - val_accuracy: 0.4865\n",
      "Epoch 14/75\n",
      "10/10 [==============================] - 4s 356ms/step - loss: 0.4082 - accuracy: 0.8373 - val_loss: 1.1921 - val_accuracy: 0.4865\n",
      "Epoch 15/75\n",
      "10/10 [==============================] - 3s 349ms/step - loss: 0.4582 - accuracy: 0.8000 - val_loss: 0.9391 - val_accuracy: 0.5676\n",
      "Epoch 16/75\n",
      "10/10 [==============================] - 4s 360ms/step - loss: 0.3651 - accuracy: 0.8576 - val_loss: 1.0489 - val_accuracy: 0.4865\n",
      "Epoch 17/75\n",
      "10/10 [==============================] - 4s 354ms/step - loss: 0.3426 - accuracy: 0.8678 - val_loss: 1.6495 - val_accuracy: 0.4865\n",
      "Epoch 18/75\n",
      "10/10 [==============================] - 4s 363ms/step - loss: 0.3366 - accuracy: 0.8983 - val_loss: 2.2769 - val_accuracy: 0.4865\n",
      "Epoch 19/75\n",
      "10/10 [==============================] - 3s 342ms/step - loss: 0.3498 - accuracy: 0.8576 - val_loss: 2.7078 - val_accuracy: 0.4865\n",
      "Epoch 20/75\n",
      "10/10 [==============================] - 3s 337ms/step - loss: 0.2499 - accuracy: 0.9051 - val_loss: 2.7012 - val_accuracy: 0.4865\n",
      "Epoch 21/75\n",
      "10/10 [==============================] - 4s 351ms/step - loss: 0.3778 - accuracy: 0.8373 - val_loss: 2.5195 - val_accuracy: 0.4865\n",
      "Epoch 22/75\n",
      "10/10 [==============================] - 4s 350ms/step - loss: 0.3528 - accuracy: 0.8712 - val_loss: 2.4193 - val_accuracy: 0.4865\n",
      "Epoch 23/75\n",
      "10/10 [==============================] - 3s 336ms/step - loss: 0.3213 - accuracy: 0.8610 - val_loss: 2.6535 - val_accuracy: 0.4865\n",
      "Epoch 24/75\n",
      "10/10 [==============================] - 4s 361ms/step - loss: 0.2193 - accuracy: 0.8949 - val_loss: 2.5613 - val_accuracy: 0.4865\n",
      "Epoch 25/75\n",
      "10/10 [==============================] - 4s 356ms/step - loss: 0.2264 - accuracy: 0.9017 - val_loss: 2.0843 - val_accuracy: 0.4865\n",
      "Epoch 26/75\n",
      "10/10 [==============================] - 3s 343ms/step - loss: 0.2604 - accuracy: 0.8746 - val_loss: 1.6664 - val_accuracy: 0.4865\n",
      "Epoch 27/75\n",
      "10/10 [==============================] - 4s 352ms/step - loss: 0.2690 - accuracy: 0.8915 - val_loss: 1.7204 - val_accuracy: 0.4865\n",
      "Epoch 28/75\n",
      "10/10 [==============================] - 4s 361ms/step - loss: 0.2646 - accuracy: 0.8780 - val_loss: 2.1678 - val_accuracy: 0.4865\n",
      "Epoch 29/75\n",
      "10/10 [==============================] - 3s 348ms/step - loss: 0.2444 - accuracy: 0.8949 - val_loss: 1.9672 - val_accuracy: 0.4865\n",
      "Epoch 30/75\n",
      "10/10 [==============================] - 3s 342ms/step - loss: 0.3073 - accuracy: 0.8644 - val_loss: 1.7717 - val_accuracy: 0.4865\n",
      "Epoch 31/75\n",
      "10/10 [==============================] - 4s 364ms/step - loss: 0.2337 - accuracy: 0.9119 - val_loss: 1.5024 - val_accuracy: 0.4865\n",
      "Epoch 32/75\n",
      "10/10 [==============================] - 4s 355ms/step - loss: 0.2624 - accuracy: 0.8881 - val_loss: 1.5315 - val_accuracy: 0.4865\n",
      "Epoch 33/75\n",
      "10/10 [==============================] - 4s 349ms/step - loss: 0.1712 - accuracy: 0.9322 - val_loss: 1.3299 - val_accuracy: 0.4865\n",
      "Epoch 34/75\n",
      "10/10 [==============================] - 4s 358ms/step - loss: 0.2778 - accuracy: 0.8746 - val_loss: 1.4636 - val_accuracy: 0.4865\n",
      "Epoch 35/75\n",
      "10/10 [==============================] - 4s 360ms/step - loss: 0.2165 - accuracy: 0.8949 - val_loss: 1.2044 - val_accuracy: 0.5135\n",
      "Epoch 36/75\n",
      "10/10 [==============================] - 3s 341ms/step - loss: 0.2150 - accuracy: 0.9017 - val_loss: 1.2964 - val_accuracy: 0.4865\n",
      "Epoch 37/75\n",
      "10/10 [==============================] - 3s 341ms/step - loss: 0.2481 - accuracy: 0.8814 - val_loss: 1.4138 - val_accuracy: 0.5135\n",
      "Epoch 38/75\n",
      "10/10 [==============================] - 4s 364ms/step - loss: 0.2432 - accuracy: 0.8814 - val_loss: 1.4492 - val_accuracy: 0.4865\n",
      "Epoch 39/75\n",
      "10/10 [==============================] - 4s 346ms/step - loss: 0.2018 - accuracy: 0.9220 - val_loss: 1.4647 - val_accuracy: 0.4865\n",
      "Epoch 40/75\n",
      "10/10 [==============================] - 3s 338ms/step - loss: 0.2421 - accuracy: 0.8847 - val_loss: 1.4418 - val_accuracy: 0.4865\n",
      "Epoch 41/75\n",
      "10/10 [==============================] - 3s 346ms/step - loss: 0.2413 - accuracy: 0.9085 - val_loss: 1.3837 - val_accuracy: 0.5405\n",
      "Epoch 42/75\n",
      "10/10 [==============================] - 3s 346ms/step - loss: 0.2325 - accuracy: 0.8983 - val_loss: 1.3861 - val_accuracy: 0.5135\n",
      "Epoch 43/75\n",
      "10/10 [==============================] - 3s 337ms/step - loss: 0.1894 - accuracy: 0.9119 - val_loss: 1.4731 - val_accuracy: 0.5135\n",
      "Epoch 44/75\n",
      "10/10 [==============================] - 4s 359ms/step - loss: 0.2181 - accuracy: 0.9051 - val_loss: 1.1544 - val_accuracy: 0.5946\n",
      "Epoch 45/75\n",
      "10/10 [==============================] - 3s 346ms/step - loss: 0.2045 - accuracy: 0.9153 - val_loss: 0.7756 - val_accuracy: 0.7027\n",
      "Epoch 46/75\n",
      "10/10 [==============================] - 3s 346ms/step - loss: 0.2120 - accuracy: 0.9085 - val_loss: 0.6438 - val_accuracy: 0.7027\n",
      "Epoch 47/75\n",
      "10/10 [==============================] - 4s 350ms/step - loss: 0.1592 - accuracy: 0.9458 - val_loss: 0.9133 - val_accuracy: 0.7027\n",
      "Epoch 48/75\n",
      "10/10 [==============================] - 4s 358ms/step - loss: 0.2628 - accuracy: 0.8983 - val_loss: 0.8455 - val_accuracy: 0.7297\n",
      "Epoch 49/75\n",
      "10/10 [==============================] - 3s 343ms/step - loss: 0.2367 - accuracy: 0.8983 - val_loss: 0.8691 - val_accuracy: 0.7297\n",
      "Epoch 50/75\n",
      "10/10 [==============================] - 3s 341ms/step - loss: 0.2309 - accuracy: 0.8949 - val_loss: 1.4714 - val_accuracy: 0.5946\n",
      "Epoch 51/75\n",
      "10/10 [==============================] - 4s 360ms/step - loss: 0.2037 - accuracy: 0.8983 - val_loss: 3.2291 - val_accuracy: 0.4865\n",
      "Epoch 52/75\n",
      "10/10 [==============================] - 4s 376ms/step - loss: 0.2260 - accuracy: 0.8847 - val_loss: 2.6822 - val_accuracy: 0.5405\n",
      "Epoch 53/75\n",
      "10/10 [==============================] - 4s 356ms/step - loss: 0.2031 - accuracy: 0.9153 - val_loss: 1.8845 - val_accuracy: 0.5946\n",
      "Epoch 54/75\n",
      "10/10 [==============================] - 4s 359ms/step - loss: 0.1967 - accuracy: 0.9017 - val_loss: 1.3088 - val_accuracy: 0.6757\n",
      "Epoch 55/75\n",
      "10/10 [==============================] - 4s 362ms/step - loss: 0.1735 - accuracy: 0.9186 - val_loss: 1.0944 - val_accuracy: 0.7027\n",
      "Epoch 56/75\n",
      "10/10 [==============================] - 3s 341ms/step - loss: 0.1747 - accuracy: 0.9186 - val_loss: 0.9515 - val_accuracy: 0.7297\n",
      "Epoch 57/75\n",
      "10/10 [==============================] - 4s 346ms/step - loss: 0.1828 - accuracy: 0.9186 - val_loss: 1.0281 - val_accuracy: 0.7027\n",
      "Epoch 58/75\n",
      "10/10 [==============================] - 4s 363ms/step - loss: 0.1929 - accuracy: 0.9153 - val_loss: 1.0089 - val_accuracy: 0.7027\n",
      "Epoch 59/75\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 0.2212 - accuracy: 0.9119 - val_loss: 0.8906 - val_accuracy: 0.6757\n",
      "Epoch 60/75\n",
      "10/10 [==============================] - 3s 343ms/step - loss: 0.2065 - accuracy: 0.9186 - val_loss: 0.7902 - val_accuracy: 0.6757\n",
      "Epoch 61/75\n",
      "10/10 [==============================] - 4s 355ms/step - loss: 0.1773 - accuracy: 0.9186 - val_loss: 0.8043 - val_accuracy: 0.6757\n",
      "Epoch 62/75\n",
      "10/10 [==============================] - 3s 346ms/step - loss: 0.1673 - accuracy: 0.9051 - val_loss: 0.8148 - val_accuracy: 0.6757\n",
      "Epoch 63/75\n",
      "10/10 [==============================] - 3s 342ms/step - loss: 0.1414 - accuracy: 0.9390 - val_loss: 0.8017 - val_accuracy: 0.6757\n",
      "Epoch 64/75\n",
      "10/10 [==============================] - 4s 351ms/step - loss: 0.1719 - accuracy: 0.9119 - val_loss: 0.8088 - val_accuracy: 0.6757\n",
      "Epoch 65/75\n",
      "10/10 [==============================] - 4s 357ms/step - loss: 0.1869 - accuracy: 0.9153 - val_loss: 0.8368 - val_accuracy: 0.7297\n",
      "Epoch 66/75\n",
      "10/10 [==============================] - 4s 365ms/step - loss: 0.1711 - accuracy: 0.9220 - val_loss: 0.8765 - val_accuracy: 0.7027\n",
      "Epoch 67/75\n",
      "10/10 [==============================] - 4s 347ms/step - loss: 0.1823 - accuracy: 0.9186 - val_loss: 0.8660 - val_accuracy: 0.7027\n",
      "Epoch 68/75\n",
      "10/10 [==============================] - 4s 358ms/step - loss: 0.1390 - accuracy: 0.9525 - val_loss: 0.8377 - val_accuracy: 0.7027\n",
      "Epoch 69/75\n",
      "10/10 [==============================] - 4s 350ms/step - loss: 0.1919 - accuracy: 0.9017 - val_loss: 0.7717 - val_accuracy: 0.6757\n",
      "Epoch 70/75\n",
      "10/10 [==============================] - 3s 342ms/step - loss: 0.1947 - accuracy: 0.9085 - val_loss: 0.6945 - val_accuracy: 0.7297\n",
      "Epoch 71/75\n",
      "10/10 [==============================] - 4s 351ms/step - loss: 0.2206 - accuracy: 0.8915 - val_loss: 0.6806 - val_accuracy: 0.7297\n",
      "Epoch 72/75\n",
      "10/10 [==============================] - 4s 363ms/step - loss: 0.1587 - accuracy: 0.9153 - val_loss: 0.7449 - val_accuracy: 0.7027\n",
      "Epoch 73/75\n",
      "10/10 [==============================] - 4s 353ms/step - loss: 0.1626 - accuracy: 0.9288 - val_loss: 0.7846 - val_accuracy: 0.7027\n",
      "Epoch 74/75\n",
      "10/10 [==============================] - 4s 349ms/step - loss: 0.1963 - accuracy: 0.9085 - val_loss: 0.8307 - val_accuracy: 0.6757\n",
      "Epoch 75/75\n",
      "10/10 [==============================] - 4s 359ms/step - loss: 0.1992 - accuracy: 0.8949 - val_loss: 0.9001 - val_accuracy: 0.7027\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7377 - accuracy: 0.7027\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.9001 - accuracy: 0.7027\n",
      "LOSS : 0.9001001119613647\n",
      "ACCURACY : 0.7027027010917664\n",
      "LOSS : 0.7376989126205444\n",
      "ACCURACY : 0.7027027010917664\n",
      "2/2 [==============================] - 0s 31ms/step\n",
      "Accuracy: 0.702703\n",
      "Precision: 0.663690\n",
      "Recall: 0.656695\n",
      "F1 score: 0.652409\n",
      "Fold:5, Train set: 369, Test set:92\n",
      "====================\n",
      "Fold:  5\n",
      "====================\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_39 (Conv2D)          (None, 248, 48, 32)       320       \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPooli  (None, 124, 24, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_52 (Ba  (None, 124, 24, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 124, 24, 32)       0         \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 122, 22, 32)       9248      \n",
      "                                                                 \n",
      " max_pooling2d_40 (MaxPooli  (None, 61, 11, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_53 (Ba  (None, 61, 11, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 61, 11, 32)        0         \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 59, 9, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_41 (MaxPooli  (None, 29, 4, 32)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_54 (Ba  (None, 29, 4, 32)         128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 29, 4, 32)         0         \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 3712)              0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 512)               1901056   \n",
      "                                                                 \n",
      " batch_normalization_55 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1923843 (7.34 MB)\n",
      "Trainable params: 1922627 (7.33 MB)\n",
      "Non-trainable params: 1216 (4.75 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/75\n",
      "10/10 [==============================] - 6s 367ms/step - loss: 1.4386 - accuracy: 0.5220 - val_loss: 0.9883 - val_accuracy: 0.6486\n",
      "Epoch 2/75\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 1.0475 - accuracy: 0.6407 - val_loss: 0.8614 - val_accuracy: 0.6486\n",
      "Epoch 3/75\n",
      "10/10 [==============================] - 4s 391ms/step - loss: 0.8126 - accuracy: 0.7051 - val_loss: 0.8471 - val_accuracy: 0.6486\n",
      "Epoch 4/75\n",
      "10/10 [==============================] - 4s 368ms/step - loss: 0.7607 - accuracy: 0.7288 - val_loss: 1.1476 - val_accuracy: 0.6486\n",
      "Epoch 5/75\n",
      "10/10 [==============================] - 4s 350ms/step - loss: 0.7580 - accuracy: 0.7525 - val_loss: 1.4893 - val_accuracy: 0.6486\n",
      "Epoch 6/75\n",
      "10/10 [==============================] - 4s 368ms/step - loss: 0.6775 - accuracy: 0.7661 - val_loss: 1.6892 - val_accuracy: 0.6486\n",
      "Epoch 7/75\n",
      "10/10 [==============================] - 4s 360ms/step - loss: 0.6191 - accuracy: 0.7729 - val_loss: 1.8221 - val_accuracy: 0.6486\n",
      "Epoch 8/75\n",
      "10/10 [==============================] - 3s 343ms/step - loss: 0.5493 - accuracy: 0.7864 - val_loss: 1.9250 - val_accuracy: 0.6486\n",
      "Epoch 9/75\n",
      "10/10 [==============================] - 4s 352ms/step - loss: 0.4779 - accuracy: 0.8034 - val_loss: 2.1780 - val_accuracy: 0.6486\n",
      "Epoch 10/75\n",
      "10/10 [==============================] - 4s 362ms/step - loss: 0.4506 - accuracy: 0.8203 - val_loss: 2.3530 - val_accuracy: 0.6486\n",
      "Epoch 11/75\n",
      "10/10 [==============================] - 4s 354ms/step - loss: 0.3879 - accuracy: 0.8475 - val_loss: 2.4203 - val_accuracy: 0.6486\n",
      "Epoch 12/75\n",
      "10/10 [==============================] - 4s 351ms/step - loss: 0.4088 - accuracy: 0.8475 - val_loss: 2.3571 - val_accuracy: 0.6486\n",
      "Epoch 13/75\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 0.3396 - accuracy: 0.8610 - val_loss: 2.1209 - val_accuracy: 0.6486\n",
      "Epoch 14/75\n",
      "10/10 [==============================] - 4s 355ms/step - loss: 0.4452 - accuracy: 0.8305 - val_loss: 1.9383 - val_accuracy: 0.6486\n",
      "Epoch 15/75\n",
      "10/10 [==============================] - 3s 343ms/step - loss: 0.4100 - accuracy: 0.8339 - val_loss: 2.1403 - val_accuracy: 0.6486\n",
      "Epoch 16/75\n",
      "10/10 [==============================] - 4s 357ms/step - loss: 0.3633 - accuracy: 0.8644 - val_loss: 2.5812 - val_accuracy: 0.6486\n",
      "Epoch 17/75\n",
      "10/10 [==============================] - 4s 367ms/step - loss: 0.3230 - accuracy: 0.8712 - val_loss: 3.1110 - val_accuracy: 0.6486\n",
      "Epoch 18/75\n",
      "10/10 [==============================] - 4s 417ms/step - loss: 0.3148 - accuracy: 0.8780 - val_loss: 3.1687 - val_accuracy: 0.6486\n",
      "Epoch 19/75\n",
      "10/10 [==============================] - 4s 343ms/step - loss: 0.3260 - accuracy: 0.8780 - val_loss: 2.5550 - val_accuracy: 0.6486\n",
      "Epoch 20/75\n",
      "10/10 [==============================] - 4s 354ms/step - loss: 0.3783 - accuracy: 0.8610 - val_loss: 2.3865 - val_accuracy: 0.6486\n",
      "Epoch 21/75\n",
      "10/10 [==============================] - 4s 356ms/step - loss: 0.3592 - accuracy: 0.8542 - val_loss: 2.6393 - val_accuracy: 0.6486\n",
      "Epoch 22/75\n",
      "10/10 [==============================] - 3s 341ms/step - loss: 0.2340 - accuracy: 0.9017 - val_loss: 2.6844 - val_accuracy: 0.6486\n",
      "Epoch 23/75\n",
      "10/10 [==============================] - 3s 346ms/step - loss: 0.2807 - accuracy: 0.8881 - val_loss: 2.9034 - val_accuracy: 0.6486\n",
      "Epoch 24/75\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 0.2909 - accuracy: 0.8542 - val_loss: 2.9402 - val_accuracy: 0.6486\n",
      "Epoch 25/75\n",
      "10/10 [==============================] - 4s 364ms/step - loss: 0.2378 - accuracy: 0.8915 - val_loss: 2.9986 - val_accuracy: 0.6486\n",
      "Epoch 26/75\n",
      "10/10 [==============================] - 4s 350ms/step - loss: 0.2144 - accuracy: 0.9153 - val_loss: 2.9813 - val_accuracy: 0.6486\n",
      "Epoch 27/75\n",
      "10/10 [==============================] - 4s 356ms/step - loss: 0.2907 - accuracy: 0.8576 - val_loss: 2.8224 - val_accuracy: 0.6486\n",
      "Epoch 28/75\n",
      "10/10 [==============================] - 4s 353ms/step - loss: 0.2854 - accuracy: 0.9017 - val_loss: 2.7791 - val_accuracy: 0.6486\n",
      "Epoch 29/75\n",
      "10/10 [==============================] - 3s 346ms/step - loss: 0.2725 - accuracy: 0.9017 - val_loss: 2.7594 - val_accuracy: 0.6486\n",
      "Epoch 30/75\n",
      "10/10 [==============================] - 4s 361ms/step - loss: 0.2402 - accuracy: 0.8915 - val_loss: 2.7611 - val_accuracy: 0.6486\n",
      "Epoch 31/75\n",
      "10/10 [==============================] - 4s 354ms/step - loss: 0.2486 - accuracy: 0.8814 - val_loss: 2.7448 - val_accuracy: 0.6486\n",
      "Epoch 32/75\n",
      "10/10 [==============================] - 4s 348ms/step - loss: 0.2616 - accuracy: 0.8814 - val_loss: 2.5196 - val_accuracy: 0.6486\n",
      "Epoch 33/75\n",
      "10/10 [==============================] - 4s 352ms/step - loss: 0.2609 - accuracy: 0.8678 - val_loss: 2.3247 - val_accuracy: 0.6486\n",
      "Epoch 34/75\n",
      "10/10 [==============================] - 4s 361ms/step - loss: 0.2440 - accuracy: 0.8881 - val_loss: 2.2289 - val_accuracy: 0.6486\n",
      "Epoch 35/75\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 0.2710 - accuracy: 0.8949 - val_loss: 2.4176 - val_accuracy: 0.6486\n",
      "Epoch 36/75\n",
      "10/10 [==============================] - 4s 353ms/step - loss: 0.2637 - accuracy: 0.8847 - val_loss: 2.5801 - val_accuracy: 0.6486\n",
      "Epoch 37/75\n",
      "10/10 [==============================] - 4s 361ms/step - loss: 0.3053 - accuracy: 0.8644 - val_loss: 2.5025 - val_accuracy: 0.6486\n",
      "Epoch 38/75\n",
      "10/10 [==============================] - 4s 358ms/step - loss: 0.2392 - accuracy: 0.8915 - val_loss: 2.2674 - val_accuracy: 0.6486\n",
      "Epoch 39/75\n",
      "10/10 [==============================] - 4s 353ms/step - loss: 0.3078 - accuracy: 0.8712 - val_loss: 1.9793 - val_accuracy: 0.6486\n",
      "Epoch 40/75\n",
      "10/10 [==============================] - 3s 342ms/step - loss: 0.2434 - accuracy: 0.8915 - val_loss: 2.5561 - val_accuracy: 0.6486\n",
      "Epoch 41/75\n",
      "10/10 [==============================] - 4s 365ms/step - loss: 0.2282 - accuracy: 0.8814 - val_loss: 2.1541 - val_accuracy: 0.5676\n",
      "Epoch 42/75\n",
      "10/10 [==============================] - 4s 352ms/step - loss: 0.1874 - accuracy: 0.9119 - val_loss: 1.7502 - val_accuracy: 0.5676\n",
      "Epoch 43/75\n",
      "10/10 [==============================] - 3s 345ms/step - loss: 0.2176 - accuracy: 0.9017 - val_loss: 1.2770 - val_accuracy: 0.5676\n",
      "Epoch 44/75\n",
      "10/10 [==============================] - 4s 355ms/step - loss: 0.2450 - accuracy: 0.9017 - val_loss: 1.2248 - val_accuracy: 0.5676\n",
      "Epoch 45/75\n",
      "10/10 [==============================] - 4s 352ms/step - loss: 0.1562 - accuracy: 0.9288 - val_loss: 1.0863 - val_accuracy: 0.6486\n",
      "Epoch 46/75\n",
      "10/10 [==============================] - 4s 350ms/step - loss: 0.1624 - accuracy: 0.9322 - val_loss: 1.1454 - val_accuracy: 0.5676\n",
      "Epoch 47/75\n",
      "10/10 [==============================] - 4s 355ms/step - loss: 0.1864 - accuracy: 0.9153 - val_loss: 0.9178 - val_accuracy: 0.5946\n",
      "Epoch 48/75\n",
      "10/10 [==============================] - 4s 358ms/step - loss: 0.1765 - accuracy: 0.9153 - val_loss: 0.7990 - val_accuracy: 0.6486\n",
      "Epoch 49/75\n",
      "10/10 [==============================] - 4s 350ms/step - loss: 0.1802 - accuracy: 0.9186 - val_loss: 0.7687 - val_accuracy: 0.6486\n",
      "Epoch 50/75\n",
      "10/10 [==============================] - 4s 355ms/step - loss: 0.1988 - accuracy: 0.9254 - val_loss: 0.8892 - val_accuracy: 0.6216\n",
      "Epoch 51/75\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 0.1675 - accuracy: 0.9288 - val_loss: 1.1342 - val_accuracy: 0.5676\n",
      "Epoch 52/75\n",
      "10/10 [==============================] - 4s 359ms/step - loss: 0.2247 - accuracy: 0.8881 - val_loss: 1.0814 - val_accuracy: 0.7027\n",
      "Epoch 53/75\n",
      "10/10 [==============================] - 3s 344ms/step - loss: 0.2117 - accuracy: 0.9119 - val_loss: 0.9234 - val_accuracy: 0.6757\n",
      "Epoch 54/75\n",
      "10/10 [==============================] - 4s 348ms/step - loss: 0.1939 - accuracy: 0.9085 - val_loss: 0.8347 - val_accuracy: 0.6486\n",
      "Epoch 55/75\n",
      "10/10 [==============================] - 4s 352ms/step - loss: 0.1870 - accuracy: 0.9153 - val_loss: 1.0467 - val_accuracy: 0.7568\n",
      "Epoch 56/75\n",
      "10/10 [==============================] - 4s 364ms/step - loss: 0.1767 - accuracy: 0.8983 - val_loss: 0.9920 - val_accuracy: 0.6486\n",
      "Epoch 57/75\n",
      "10/10 [==============================] - 3s 344ms/step - loss: 0.1851 - accuracy: 0.9051 - val_loss: 1.0737 - val_accuracy: 0.7568\n",
      "Epoch 58/75\n",
      "10/10 [==============================] - 4s 359ms/step - loss: 0.1583 - accuracy: 0.9288 - val_loss: 0.8316 - val_accuracy: 0.6757\n",
      "Epoch 59/75\n",
      "10/10 [==============================] - 4s 359ms/step - loss: 0.1806 - accuracy: 0.9051 - val_loss: 0.7613 - val_accuracy: 0.6216\n",
      "Epoch 60/75\n",
      "10/10 [==============================] - 3s 347ms/step - loss: 0.1767 - accuracy: 0.9186 - val_loss: 0.8169 - val_accuracy: 0.6216\n",
      "Epoch 61/75\n",
      "10/10 [==============================] - 4s 376ms/step - loss: 0.1314 - accuracy: 0.9356 - val_loss: 0.8455 - val_accuracy: 0.6216\n",
      "Epoch 62/75\n",
      "10/10 [==============================] - 4s 358ms/step - loss: 0.1742 - accuracy: 0.9153 - val_loss: 0.8643 - val_accuracy: 0.6216\n",
      "Epoch 63/75\n",
      "10/10 [==============================] - 3s 340ms/step - loss: 0.1889 - accuracy: 0.9085 - val_loss: 0.8930 - val_accuracy: 0.5946\n",
      "Epoch 64/75\n",
      "10/10 [==============================] - 4s 345ms/step - loss: 0.1942 - accuracy: 0.9186 - val_loss: 0.9083 - val_accuracy: 0.6216\n",
      "Epoch 65/75\n",
      "10/10 [==============================] - 4s 355ms/step - loss: 0.1505 - accuracy: 0.9254 - val_loss: 0.9179 - val_accuracy: 0.6216\n",
      "Epoch 66/75\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 0.1653 - accuracy: 0.9220 - val_loss: 0.9750 - val_accuracy: 0.7297\n",
      "Epoch 67/75\n",
      "10/10 [==============================] - 4s 349ms/step - loss: 0.2156 - accuracy: 0.8983 - val_loss: 0.7633 - val_accuracy: 0.7568\n",
      "Epoch 68/75\n",
      "10/10 [==============================] - 4s 362ms/step - loss: 0.1644 - accuracy: 0.9119 - val_loss: 0.7847 - val_accuracy: 0.6486\n",
      "Epoch 69/75\n",
      "10/10 [==============================] - 4s 362ms/step - loss: 0.1567 - accuracy: 0.9254 - val_loss: 0.8749 - val_accuracy: 0.6486\n",
      "Epoch 70/75\n",
      "10/10 [==============================] - 4s 348ms/step - loss: 0.1505 - accuracy: 0.9220 - val_loss: 0.9556 - val_accuracy: 0.6486\n",
      "Epoch 71/75\n",
      "10/10 [==============================] - 4s 366ms/step - loss: 0.1873 - accuracy: 0.9186 - val_loss: 0.9554 - val_accuracy: 0.6757\n",
      "Epoch 72/75\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 0.1358 - accuracy: 0.9356 - val_loss: 0.8346 - val_accuracy: 0.6757\n",
      "Epoch 73/75\n",
      " 3/10 [========>.....................] - ETA: 2s - loss: 0.1416 - accuracy: 0.9375"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/75\n",
      "9/9 [==============================] - 1s 119ms/step - loss: 0.0835 - accuracy: 0.9656 - val_loss: 1.9844 - val_accuracy: 0.4848\n",
      "Epoch 42/75\n",
      "9/9 [==============================] - 1s 155ms/step - loss: 0.0892 - accuracy: 0.9656 - val_loss: 1.7336 - val_accuracy: 0.4848\n",
      "Epoch 43/75\n",
      "9/9 [==============================] - 1s 100ms/step - loss: 0.1043 - accuracy: 0.9656 - val_loss: 1.2445 - val_accuracy: 0.5152\n",
      "Epoch 44/75\n",
      "9/9 [==============================] - 1s 105ms/step - loss: 0.1041 - accuracy: 0.9656 - val_loss: 0.9052 - val_accuracy: 0.6061\n",
      "Epoch 45/75\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.1088 - accuracy: 0.9656 - val_loss: 0.9474 - val_accuracy: 0.6667\n",
      "Epoch 46/75\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.0809 - accuracy: 0.9656 - val_loss: 0.9826 - val_accuracy: 0.6667\n",
      "Epoch 47/75\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 0.1206 - accuracy: 0.9695 - val_loss: 0.8742 - val_accuracy: 0.6970\n",
      "Epoch 48/75\n",
      "9/9 [==============================] - 1s 98ms/step - loss: 0.0745 - accuracy: 0.9771 - val_loss: 0.7763 - val_accuracy: 0.7273\n",
      "Epoch 49/75\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.0842 - accuracy: 0.9618 - val_loss: 0.6951 - val_accuracy: 0.6970\n",
      "Epoch 50/75\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.0905 - accuracy: 0.9580 - val_loss: 0.5865 - val_accuracy: 0.7879\n",
      "Epoch 51/75\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.1051 - accuracy: 0.9618 - val_loss: 0.5372 - val_accuracy: 0.7879\n",
      "Epoch 52/75\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.0700 - accuracy: 0.9771 - val_loss: 0.4461 - val_accuracy: 0.8485\n",
      "Epoch 53/75\n",
      "9/9 [==============================] - 1s 124ms/step - loss: 0.0853 - accuracy: 0.9656 - val_loss: 0.4251 - val_accuracy: 0.8485\n",
      "Epoch 54/75\n",
      "9/9 [==============================] - 1s 114ms/step - loss: 0.0745 - accuracy: 0.9618 - val_loss: 0.4042 - val_accuracy: 0.8182\n",
      "Epoch 55/75\n",
      "9/9 [==============================] - 1s 125ms/step - loss: 0.0730 - accuracy: 0.9733 - val_loss: 0.4013 - val_accuracy: 0.7879\n",
      "Epoch 56/75\n",
      "9/9 [==============================] - 1s 123ms/step - loss: 0.0349 - accuracy: 0.9847 - val_loss: 0.3857 - val_accuracy: 0.7879\n",
      "Epoch 57/75\n",
      "9/9 [==============================] - 2s 177ms/step - loss: 0.0464 - accuracy: 0.9847 - val_loss: 0.3659 - val_accuracy: 0.8485\n",
      "Epoch 58/75\n",
      "9/9 [==============================] - 2s 174ms/step - loss: 0.0299 - accuracy: 0.9885 - val_loss: 0.4562 - val_accuracy: 0.8485\n",
      "Epoch 59/75\n",
      "9/9 [==============================] - 1s 132ms/step - loss: 0.1042 - accuracy: 0.9466 - val_loss: 0.4431 - val_accuracy: 0.8182\n",
      "Epoch 60/75\n",
      "9/9 [==============================] - 1s 114ms/step - loss: 0.0381 - accuracy: 0.9885 - val_loss: 0.4601 - val_accuracy: 0.8182\n",
      "Epoch 61/75\n",
      "9/9 [==============================] - 1s 136ms/step - loss: 0.0248 - accuracy: 0.9962 - val_loss: 0.4565 - val_accuracy: 0.8182\n",
      "Epoch 62/75\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 0.0321 - accuracy: 0.9809 - val_loss: 0.4274 - val_accuracy: 0.7879\n",
      "Epoch 63/75\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.0421 - accuracy: 0.9771 - val_loss: 0.3726 - val_accuracy: 0.8485\n",
      "Epoch 64/75\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 0.0272 - accuracy: 0.9924 - val_loss: 0.3231 - val_accuracy: 0.8485\n",
      "Epoch 65/75\n",
      "9/9 [==============================] - 1s 161ms/step - loss: 0.0629 - accuracy: 0.9695 - val_loss: 0.2944 - val_accuracy: 0.8485\n",
      "Epoch 66/75\n",
      "9/9 [==============================] - 1s 127ms/step - loss: 0.0516 - accuracy: 0.9847 - val_loss: 0.2684 - val_accuracy: 0.8485\n",
      "Epoch 67/75\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.0399 - accuracy: 0.9847 - val_loss: 0.2318 - val_accuracy: 0.8485\n",
      "Epoch 68/75\n",
      "9/9 [==============================] - 1s 163ms/step - loss: 0.0623 - accuracy: 0.9847 - val_loss: 0.1900 - val_accuracy: 0.8788\n",
      "Epoch 69/75\n",
      "9/9 [==============================] - 1s 124ms/step - loss: 0.0713 - accuracy: 0.9695 - val_loss: 0.1920 - val_accuracy: 0.9091\n",
      "Epoch 70/75\n",
      "9/9 [==============================] - 1s 129ms/step - loss: 0.0311 - accuracy: 0.9885 - val_loss: 0.2180 - val_accuracy: 0.9091\n",
      "Epoch 71/75\n",
      "9/9 [==============================] - 1s 153ms/step - loss: 0.0288 - accuracy: 0.9847 - val_loss: 0.2370 - val_accuracy: 0.8788\n",
      "Epoch 72/75\n",
      "9/9 [==============================] - 1s 133ms/step - loss: 0.0341 - accuracy: 0.9847 - val_loss: 0.2261 - val_accuracy: 0.8788\n",
      "Epoch 73/75\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.8788\n",
      "Epoch 74/75\n",
      "9/9 [==============================] - 1s 143ms/step - loss: 0.0380 - accuracy: 0.9847 - val_loss: 0.2059 - val_accuracy: 0.8788\n",
      "Epoch 75/75\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 0.0326 - accuracy: 0.9885 - val_loss: 0.1922 - val_accuracy: 0.9091\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2715 - accuracy: 0.8788\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1922 - accuracy: 0.9091\n",
      "LOSS : 0.19217830896377563\n",
      "ACCURACY : 0.9090909361839294\n",
      "LOSS : 0.2715187668800354\n",
      "ACCURACY : 0.8787878751754761\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001622C8DBEE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 7ms/step\n",
      "Accuracy: 0.878788\n",
      "Precision: 0.895833\n",
      "Recall: 0.876190\n",
      "F1 score: 0.881481\n"
     ]
    }
   ],
   "source": [
    "kf =KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cnt = 1\n",
    "# split()  method generate indices to split data into training and test set.\n",
    "for train_index, test_index in kf.split(cells, labels):\n",
    "    print(f'Fold:{cnt}, Train set: {len(train_index)}, Test set:{len(test_index)}')\n",
    "    print(\"=\"*20)\n",
    "    print(\"Fold: \", cnt)\n",
    "    print(\"=\"*20)\n",
    "    cnt +=1\n",
    "\n",
    "    x_train , x , y_train , y = train_test_split(cells[train_index] , labels[train_index] , \n",
    "                                                test_size = 0.2 ,\n",
    "                                                random_state = 11)\n",
    "\n",
    "    x_eval ,x_test ,y_eval , y_test = train_test_split(x , y , \n",
    "                                                        test_size = 0.5 , \n",
    "                                                        random_state = 11)\n",
    "\n",
    "    y_train = to_categorical(y_train, num_classes = 3)\n",
    "    y_eval = to_categorical(y_eval, num_classes = 3)\n",
    "    y_test = to_categorical(y_test, num_classes = 3)\n",
    "\n",
    "    #instantiate the model\n",
    "    height = 250\n",
    "    width = 50\n",
    "    classes = 3\n",
    "    channels = 1\n",
    "    epoch = 75\n",
    "    model = CNNbuild(height = height, width = width, classes = classes, channels = channels)\n",
    "    model.summary()\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])\n",
    "\n",
    "    #fit the model onto the dataset\n",
    "    # x_train = np.array (x_train)\n",
    "\n",
    "    h = model.fit(x_train, y_train, epochs = epoch, batch_size = 32,validation_data=(x_eval,y_eval),shuffle=True)\n",
    "\n",
    "    #evaluate the model on test data\n",
    "    predictions = model.evaluate(x_test, y_test)\n",
    "    evaluation = model.evaluate(x_eval, y_eval)\n",
    "\n",
    "    print(f'LOSS : {evaluation[0]}')\n",
    "    print(f'ACCURACY : {evaluation[1]}')\n",
    "    print(f'LOSS : {predictions[0]}')\n",
    "    print(f'ACCURACY : {predictions[1]}')\n",
    "\n",
    "    predict_x=model.predict(x_test) \n",
    "    yhat_classes=np.argmax(predict_x,axis=1)\n",
    "    yhat_classes = to_categorical(yhat_classes, num_classes = 3)\n",
    "\n",
    "    # print(\"Precision Score : \",precision_score(y_test, y_pred, \n",
    "    #                                            pos_label='positive'\n",
    "    #                                            average='micro'))\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = accuracy_score(y_test, yhat_classes)\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "    totalaccuracy.append(accuracy)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(y_test, yhat_classes, average='macro')\n",
    "    print('Precision: %f' % precision)\n",
    "    totalprecision.append(precision)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(y_test, yhat_classes, average='macro')\n",
    "    print('Recall: %f' % recall)\n",
    "    totalrecall.append(recall)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(y_test, yhat_classes, average='macro')\n",
    "    print('F1 score: %f' % f1)\n",
    "    totalf1.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dfb098",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 20)\n",
    "print(\"rata-rata Akurasi: \",sum(totalaccuracy)/len(totalaccuracy))\n",
    "print(\"rata-rata Presisi: \",sum(totalprecision)/len(totalprecision))\n",
    "print(\"rata-rata Recall: \",sum(totalrecall)/len(totalrecall))\n",
    "print(\"rata-rata F1: \",sum(totalf1)/len(totalf1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afe1265",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (18,8))\n",
    "plt.plot(range(epoch), h.history['loss'], label = 'Taining Loss')\n",
    "plt.plot(range(epoch), h.history['val_loss'], label = 'Validation Loss')\n",
    "plt.xlabel(\"Number of Epoch's\")\n",
    "plt.ylabel('Loss Value')\n",
    "plt.title('Training Training & Validation Loss')\n",
    "plt.legend(loc = \"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea332d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (18,8))\n",
    "plt.plot(range(epoch), h.history['accuracy'], label = 'Taining Accuracy')\n",
    "plt.plot(range(epoch), h.history['val_accuracy'], label = 'Validation Accuracy')\n",
    "plt.xlabel(\"Number of Epoch's\")\n",
    "plt.ylabel('Loss Value')\n",
    "plt.title('Training Training & Validation Loss')\n",
    "plt.legend(loc = \"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b605ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
